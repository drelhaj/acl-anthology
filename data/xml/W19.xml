<?xml version='1.0' encoding='UTF-8'?>
<collection id="W19">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the Society for Computation in Linguistics (<fixed-case>SC</fixed-case>i<fixed-case>L</fixed-case>) 2019</booktitle>
      <editor><first>Gaja</first><last>Jarosz</last></editor>
      <editor><first>Max</first><last>Nelson</last></editor>
      <editor><first>Brendan</first><last>O’Connor</last></editor>
      <editor><first>Joe</first><last>Pater</last></editor>
    </meta>
    <frontmatter>
      <pages>i-ii</pages>
      <doi>10.7275/ntf6-xx21</doi>
      <url>W19-0100</url>
    </frontmatter>
    <paper id="1">
      <title>Can Entropy Explain Successor Surprisal Effects in Reading?</title>
      <author><first>Marten</first><last>van Schijndel</last></author>
      <author><first>Tal</first><last>Linzen</last></author>
      <pages>1-7</pages>
      <doi>10.7275/qtbb-9d05</doi>
      <url>W19-0101</url>
    </paper>
    <paper id="2">
      <title><fixed-case>R</fixed-case>ed<fixed-case>T</fixed-case>yp: A Database of Reduplication with Computational Models</title>
      <author><first>Hossep</first><last>Dolatian</last></author>
      <author><first>Jeffrey</first><last>Heinz</last></author>
      <pages>8-18</pages>
      <doi>10.7275/ckx7-s770</doi>
      <url>W19-0102</url>
    </paper>
    <paper id="3">
      <title>Unsupervised Learning of Cross-Lingual Symbol Embeddings Without Parallel Data</title>
      <author><first>Mark</first><last>Granroth-Wilding</last></author>
      <author><first>Hannu</first><last>Toivonen</last></author>
      <pages>19-28</pages>
      <doi>10.7275/wx64-ea83</doi>
      <url>W19-0103</url>
    </paper>
    <paper id="4">
      <title>Q-Theory Representations are Logically Equivalent to Autosegmental Representations</title>
      <author><first>Nick</first><last>Danis</last></author>
      <author><first>Adam</first><last>Jardine</last></author>
      <pages>29-38</pages>
      <doi>10.7275/tvj1-k306</doi>
      <url>W19-0104</url>
    </paper>
    <paper id="5">
      <title>Modeling Clausal Complementation for a Grammar Engineering Resource</title>
      <author><first>Olga</first><last>Zamaraeva</last></author>
      <author><first>Kristen</first><last>Howell</last></author>
      <author><first>Emily M.</first><last>Bender</last></author>
      <pages>39-49</pages>
      <doi>10.7275/dygn-c796</doi>
      <url>W19-0105</url>
    </paper>
    <paper id="6">
      <title>Do <fixed-case>RNN</fixed-case>s learn human-like abstract word order preferences?</title>
      <author><first>Richard</first><last>Futrell</last></author>
      <author><first>Roger P.</first><last>Levy</last></author>
      <pages>50-59</pages>
      <doi>10.7275/jb34-9986</doi>
      <url>W19-0106</url>
    </paper>
    <paper id="7">
      <title>Segmentation and <fixed-case>UR</fixed-case> Acquisition with <fixed-case>UR</fixed-case> Constraints</title>
      <author><first>Max</first><last>Nelson</last></author>
      <pages>60-68</pages>
      <doi>10.7275/zc9d-pn56</doi>
      <url>W19-0107</url>
    </paper>
    <paper id="8">
      <title>Constraint breeding during on-line incremental learning</title>
      <author><first>Elliot</first><last>Moreton</last></author>
      <pages>69-80</pages>
      <doi>10.7275/6f9x-6411</doi>
      <url>W19-0108</url>
    </paper>
    <paper id="9">
      <title>An Incremental Iterated Response Model of Pragmatics</title>
      <author><first>Reuben</first><last>Cohn-Gordon</last></author>
      <author><first>Noah</first><last>Goodman</last></author>
      <author><first>Christopher</first><last>Potts</last></author>
      <pages>81-90</pages>
      <doi>10.7275/cprc-8x17</doi>
      <url>W19-0109</url>
    </paper>
    <paper id="10">
      <title>Learning Exceptionality and Variation with Lexically Scaled <fixed-case>M</fixed-case>ax<fixed-case>E</fixed-case>nt</title>
      <author><first>Coral</first><last>Hughto</last></author>
      <author><first>Andrew</first><last>Lamont</last></author>
      <author><first>Brandon</first><last>Prickett</last></author>
      <author><first>Gaja</first><last>Jarosz</last></author>
      <pages>91-101</pages>
      <doi>10.7275/y68s-kh12</doi>
      <url>W19-0110</url>
    </paper>
    <paper id="11">
      <title>Learning complex inflectional paradigms through blended gradient inputs</title>
      <author><first>Eric R.</first><last>Rosen</last></author>
      <pages>102-112</pages>
      <doi>10.7275/ccwf-j606</doi>
      <url>W19-0111</url>
    </paper>
    <paper id="12">
      <title>Jabberwocky Parsing: Dependency Parsing with Lexical Noise</title>
      <author><first>Jungo</first><last>Kasai</last></author>
      <author><first>Robert</first><last>Frank</last></author>
      <pages>113-123</pages>
      <doi>10.7275/h12q-k754</doi>
      <url>W19-0112</url>
    </paper>
    <paper id="13">
      <title>Learnability and Overgeneration in Computational Syntax</title>
      <author><first>Yiding</first><last>Hao</last></author>
      <pages>124-134</pages>
      <doi>10.7275/1qmz-bg76</doi>
      <url>W19-0113</url>
    </paper>
    <paper id="14">
      <title>A Conceptual Spaces Model of Socially Motivated Language Change</title>
      <author><first>Heather</first><last>Burnett</last></author>
      <author><first>Olivier</first><last>Bonami</last></author>
      <pages>135-145</pages>
      <doi>10.7275/5vmp-cs05</doi>
      <url>W19-0114</url>
    </paper>
    <paper id="15">
      <title>Identifying Participation of Individual Verbs or <fixed-case>V</fixed-case>erb<fixed-case>N</fixed-case>et Classes in the Causative Alternation</title>
      <author><first>Esther</first><last>Seyffarth</last></author>
      <pages>146-155</pages>
      <doi>10.7275/efvz-jy59</doi>
      <url>W19-0115</url>
    </paper>
    <paper id="16">
      <title>Using Sentiment Induction to Understand Variation in Gendered Online Communities</title>
      <author><first>Lucy</first><last>Li</last></author>
      <author><first>Julia</first><last>Mendelsohn</last></author>
      <pages>156-166</pages>
      <doi>10.7275/11wq-ep51</doi>
      <url>W19-0116</url>
    </paper>
    <paper id="17">
      <title>On the difficulty of a distributional semantics of spoken language</title>
      <author><first>Grzegorz</first><last>Chrupała</last></author>
      <author><first>Lieke</first><last>Gelderloos</last></author>
      <author><first>Ákos</first><last>Kádár</last></author>
      <author><first>Afra</first><last>Alishahi</last></author>
      <pages>167-173</pages>
      <doi>10.7275/extq-7546</doi>
      <url>W19-0117</url>
    </paper>
    <paper id="18">
      <title>Distributional Effects of Gender Contrasts Across Categories</title>
      <author><first>Timothee</first><last>Mickus</last></author>
      <author><first>Olivier</first><last>Bonami</last></author>
      <author><first>Denis</first><last>Paperno</last></author>
      <pages>174-184</pages>
      <doi>10.7275/g11b-3s25</doi>
      <url>W19-0118</url>
    </paper>
    <paper id="19">
      <title>Guess Who’s Coming (and Who’s Going): Bringing Perspective to the Rational Speech Acts Framework</title>
      <author><first>Carolyn Jane</first><last>Anderson</last></author>
      <author><first>Brian W.</first><last>Dillon</last></author>
      <pages>185-194</pages>
      <doi>10.7275/9bn3-8x38</doi>
      <url>W19-0119</url>
    </paper>
    <paper id="20">
      <title>The organization of sound inventories: A study on obstruent gaps</title>
      <author><first>Sheng-Fu</first><last>Wang</last></author>
      <pages>195-204</pages>
      <doi>10.7275/pbe8-zf60</doi>
      <url>W19-0120</url>
    </paper>
    <paper id="21">
      <title>C-Command Dependencies as <fixed-case>TSL</fixed-case> String Constraints</title>
      <author><first>Thomas</first><last>Graf</last></author>
      <author><first>Nazila</first><last>Shafiei</last></author>
      <pages>205-215</pages>
      <doi>10.7275/4rrx-x488</doi>
      <url>W19-0121</url>
    </paper>
    <paper id="22">
      <title>Modeling the Acquisition of Words with Multiple Meanings</title>
      <author><first>Libby</first><last>Barak</last></author>
      <author><first>Sammy</first><last>Floyd</last></author>
      <author><first>Adele</first><last>Goldberg</last></author>
      <pages>216-225</pages>
      <doi>10.7275/tr21-m273</doi>
      <url>W19-0122</url>
    </paper>
    <paper id="23">
      <title>Evaluation Order Effects in Dynamic Continuized <fixed-case>CCG</fixed-case>: From Negative Polarity Items to Balanced Punctuation</title>
      <author><first>Michael</first><last>White</last></author>
      <pages>226-235</pages>
      <doi>10.7275/kpch-rk05</doi>
      <url>W19-0123</url>
    </paper>
    <paper id="24">
      <title>Abstract Meaning Representation for Human-Robot Dialogue</title>
      <author><first>Claire N.</first><last>Bonial</last></author>
      <author><first>Lucia</first><last>Donatelli</last></author>
      <author><first>Jessica</first><last>Ervin</last></author>
      <author><first>Clare R.</first><last>Voss</last></author>
      <pages>236-246</pages>
      <doi>10.7275/v3c5-yd35</doi>
      <url>W19-0124</url>
    </paper>
    <paper id="25">
      <title>A Logical and Computational Methodology for Exploring Systems of Phonotactic Constraints</title>
      <author><first>Dakotah</first><last>Lambert</last></author>
      <author><first>James</first><last>Rogers</last></author>
      <pages>247-256</pages>
      <doi>10.7275/t0dv-9t05</doi>
      <url>W19-0125</url>
    </paper>
    <paper id="26">
      <title>Augmentic Compositional Models for Knowledge Base Completion Using Gradient Representations</title>
      <author><first>Matthias R.</first><last>Lalisse</last></author>
      <author><first>Paul</first><last>Smolensky</last></author>
      <pages>257-266</pages>
      <doi>10.7275/8et8-qd83</doi>
      <url>W19-0126</url>
    </paper>
    <paper id="27">
      <title>Case assignment in <fixed-case>TSL</fixed-case> syntax: a case study</title>
      <author><first>Mai Ha</first><last>Vu</last></author>
      <author><first>Nazila</first><last>Shafiei</last></author>
      <author><first>Thomas</first><last>Graf</last></author>
      <pages>267-276</pages>
      <doi>10.7275/sywz-xw23</doi>
      <url>W19-0127</url>
    </paper>
    <paper id="28">
      <title>On Evaluating the Generalization of <fixed-case>LSTM</fixed-case> Models in Formal Languages</title>
      <author><first>Mirac</first><last>Suzgun</last></author>
      <author><first>Yonatan</first><last>Belinkov</last></author>
      <author><first>Stuart M.</first><last>Shieber</last></author>
      <pages>277-286</pages>
      <doi>10.7275/s02b-4d91</doi>
      <url>W19-0128</url>
    </paper>
    <paper id="29">
      <title>Verb Argument Structure Alternations in Word and Sentence Embeddings</title>
      <author><first>Katharina</first><last>Kann</last></author>
      <author><first>Alex</first><last>Warstadt</last></author>
      <author><first>Adina</first><last>Williams</last></author>
      <author><first>Samuel R.</first><last>Bowman</last></author>
      <pages>287-297</pages>
      <doi>10.7275/q5js-4y86</doi>
      <url>W19-0129</url>
    </paper>
  </volume>
  <volume id="3">
    <meta>
      <booktitle>Proceedings of the Fifth International Workshop on Computational Linguistics for Uralic Languages</booktitle>
      <url>W19-03</url>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Tartu, Estonia</address>
      <month>January</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-0300</url>
    </frontmatter>
    <paper id="1">
      <title>Data-Driven Morphological Analysis for Uralic Languages</title>
      <author><first>Miikka</first><last>Silfverberg</last></author>
      <author><first>Francis</first><last>Tyers</last></author>
      <pages>1–14</pages>
      <url>W19-0301</url>
    </paper>
    <paper id="2">
      <title>North Sámi morphological segmentation with low-resource semi-supervised sequence labeling</title>
      <author><first>Stig-Arne</first><last>Grönroos</last></author>
      <author><first>Sámi</first><last>Virpioja</last></author>
      <author><first>Mikko</first><last>Kurimo</last></author>
      <pages>15–26</pages>
      <url>W19-0302</url>
    </paper>
    <paper id="3">
      <title>What does the Nom say? An algorithm for case disambiguation in <fixed-case>H</fixed-case>ungarian</title>
      <author><first>Noémi</first><last>Ligeti-Nagy</last></author>
      <author><first>Andrea</first><last>Dömötör</last></author>
      <author><first>Noémi</first><last>Vadász</last></author>
      <pages>27–41</pages>
      <url>W19-0303</url>
    </paper>
    <paper id="4">
      <title>A Contrastive Evaluation of Word Sense Disambiguation Systems for <fixed-case>F</fixed-case>innish</title>
      <author><first>Frankie</first><last>Robertson</last></author>
      <pages>42–54</pages>
      <url>W19-0304</url>
    </paper>
    <paper id="5">
      <title>Elliptical Constructions in <fixed-case>E</fixed-case>stonian <fixed-case>UD</fixed-case> Treebank</title>
      <author><first>Kadri</first><last>Muischnek</last></author>
      <author><first>Liisi</first><last>Torga</last></author>
      <pages>55–65</pages>
      <url>W19-0305</url>
    </paper>
    <paper id="6">
      <title><fixed-case>F</fixed-case>i<fixed-case>ST</fixed-case> – towards a free Semantic Tagger of modern standard <fixed-case>F</fixed-case>innish</title>
      <author><first>Kimmo</first><last>Kettunen</last></author>
      <pages>66–76</pages>
      <url>W19-0306</url>
    </paper>
    <paper id="7">
      <title>An <fixed-case>OCR</fixed-case> system for the Unified Northern Alphabet</title>
      <author><first>Niko</first><last>Partanen</last></author>
      <author><first>Michael</first><last>Rießler</last></author>
      <pages>77–89</pages>
      <url>W19-0307</url>
    </paper>
    <paper id="8">
      <title><fixed-case>ELAN</fixed-case> as a search engine for hierarchically structured, tagged corpora</title>
      <author><first>Joshua</first><last>Wilbur</last></author>
      <pages>90–103</pages>
      <url>W19-0308</url>
    </paper>
    <paper id="9">
      <title>Neural and rule-based <fixed-case>F</fixed-case>innish <fixed-case>NLP</fixed-case> models—expectations, experiments and experiences</title>
      <author><first>Tommi A</first><last>Pirinen</last></author>
      <pages>104–114</pages>
      <url>W19-0309</url>
    </paper>
    <paper id="10">
      <title>Uralic multimedia corpora: <fixed-case>ISO</fixed-case>/<fixed-case>TEI</fixed-case> corpus data in the project <fixed-case>INEL</fixed-case></title>
      <author><first>Timofey</first><last>Arkhangelskiy</last></author>
      <author><first>Anne</first><last>Ferger</last></author>
      <author><first>Hanna</first><last>Hedeland</last></author>
      <pages>115–124</pages>
      <url>W19-0310</url>
    </paper>
    <paper id="11">
      <title>Corpora of social media in minority Uralic languages</title>
      <author><first>Timofey</first><last>Arkhangelskiy</last></author>
      <pages>125–140</pages>
      <url>W19-0311</url>
    </paper>
    <paper id="12">
      <title>Is this the end? Two-step tokenization of sentence boundaries</title>
      <author><first>Linda</first><last>Wiechetek</last></author>
      <author><first>Sjur Nørstebø</first><last>Moshagen</last></author>
      <author><first>Thomas</first><last>Omma</last></author>
      <pages>141–153</pages>
      <url>W19-0312</url>
    </paper>
    <paper id="13">
      <title>Learning multilingual topics through aspect extraction from monolingual texts</title>
      <author><first>Johannes</first><last>Huber</last></author>
      <author><first>Myra</first><last>Spiliopoulou</last></author>
      <pages>154–183</pages>
      <url>W19-0313</url>
    </paper>
    <paper id="14">
      <title>Electronical resources for Livonian</title>
      <author><first>Valts</first><last>Ernštreits</last></author>
      <pages>184–191</pages>
      <url>W19-0314</url>
    </paper>
    <paper id="15">
      <title>The use of Extract Morphology for Automatic Generation of Language Technology for Votic</title>
      <author><first>Kristian</first><last>Kankainen</last></author>
      <pages>192–204</pages>
      <url>W19-0315</url>
    </paper>
  </volume>
  <volume id="4">
    <meta>
      <booktitle>Proceedings of the 13th International Conference on Computational Semantics - Long Papers</booktitle>
      <url>W19-04</url>
      <editor><first>Simon</first><last>Dobnik</last></editor>
      <editor><first>Stergios</first><last>Chatzikyriakidis</last></editor>
      <editor><first>Vera</first><last>Demberg</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Gothenburg, Sweden</address>
      <month>23–27 May</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-0400</url>
    </frontmatter>
    <paper id="1">
      <title>Projecting Temporal Properties, Events and Actions</title>
      <author><first>Tim</first><last>Fernando</last></author>
      <pages>1–12</pages>
      <abstract>Temporal notions based on a finite set <tex-math>A</tex-math> of properties are represented in strings, on which projections are defined that vary the granularity <tex-math>A</tex-math>. The structure of properties in <tex-math>A</tex-math> is elaborated to describe statives, events and actions, subject to a distinction in meaning (advocated by Levin and Rappaport Hovav) between what the lexicon prescribes and what a context of use supplies. The projections proposed are deployed as labels for records and record types amenable to finite-state methods.</abstract>
      <url>W19-0401</url>
    </paper>
    <paper id="2">
      <title>A Type-coherent, Expressive Representation as an Initial Step to Language Understanding</title>
      <author><first>Gene Louis</first><last>Kim</last></author>
      <author><first>Lenhart</first><last>Schubert</last></author>
      <pages>13–30</pages>
      <abstract>A growing interest in tasks involving language understanding by the NLP community has led to the need for effective semantic parsing and inference. Modern NLP systems use semantic representations that do not quite fulfill the nuanced needs for language understanding: adequately modeling language semantics, enabling general inferences, and being accurately recoverable. This document describes underspecified logical forms~(ULF) for Episodic Logic~(EL), which is an initial form for a semantic representation that balances these needs. ULFs fully resolve the semantic type structure while leaving issues such as quantifier scope, word sense, and anaphora unresolved; they provide a starting point for further resolution into EL, and enable certain structural inferences without further resolution. This document also presents preliminary results of creating a hand-annotated corpus of ULFs for the purpose of training a precise ULF parser, showing a three-person pairwise interannotator agreement of 0.88 on confident annotations. We hypothesize that a divide-and-conquer approach to semantic parsing starting with derivation of ULFs will lead to semantic analyses that do justice to subtle aspects of linguistic meaning, and will enable construction of more accurate semantic parsers.</abstract>
      <url>W19-0402</url>
    </paper>
    <paper id="3">
      <title>A Semantic Annotation Scheme for Quantification</title>
      <author><first>Harry</first><last>Bunt</last></author>
      <pages>31–42</pages>
      <abstract>This paper describes in brief the proposal called ‘QuantML’ which was accepted by the International Organisation for Standards (ISO) last February as a starting point for developing a standard for the interoperable annotation of quantification phenomena in natural language, as part of the ISO 24617 Semantic Annotation Framework. The proposal, firmly rooted in the theory of generalised quantifiers, neo-Davidsonian semantics, and DRT, covers a wide range of quantification phenomena. The QuantML scheme consists of (1) an abstract syntax which defines ‘annotation structures’ as triples and other set-theoretic constructs; (b) a compositional semantics of annotation structures; (3) an XML representation of annotation structures.</abstract>
      <url>W19-0403</url>
    </paper>
    <paper id="4">
      <title>Re-Ranking Words to Improve Interpretability of Automatically Generated Topics</title>
      <author><first>Areej</first><last>Alokaili</last></author>
      <author><first>Nikolaos</first><last>Aletras</last></author>
      <author><first>Mark</first><last>Stevenson</last></author>
      <pages>43–54</pages>
      <abstract>Topics models, such as LDA, are widely used in Natural Language Processing. Making their output interpretable is an important area of research with applications to areas such as the enhancement of exploratory search interfaces and the development of interpretable machine learning models. Conventionally, topics are represented by their n most probable words, however, these representations are often difficult for humans to interpret. This paper explores the re-ranking of topic words to generate more interpretable topic representations. A range of approaches are compared and evaluated in two experiments. The first uses crowdworkers to associate topics represented by different word rankings with related documents. The second experiment is an automatic approach based on a document retrieval task applied on multiple domains. Results in both experiments demonstrate that re-ranking words improves topic interpretability and that the most effective re-ranking schemes were those which combine information about the importance of words both within topics and their relative frequency in the entire corpus. In addition, close correlation between the results of the two evaluation approaches suggests that the automatic method proposed here could be used to evaluate re-ranking methods without the need for human judgements.</abstract>
      <url>W19-0404</url>
    </paper>
    <paper id="5">
      <title>An Improved Approach for Semantic Graph Composition with <fixed-case>CCG</fixed-case></title>
      <author><first>Austin</first><last>Blodgett</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>55–70</pages>
      <abstract>This paper builds on previous work using Combinatory Categorial Grammar (CCG) to derive a transparent syntax-semantics interface for Abstract Meaning Representation (AMR) parsing. We define new semantics for the CCG combinators that is better suited to deriving AMR graphs. In particular, we define relation-wise alternatives for the application and composition combinators: these require that the two constituents being combined overlap in one AMR relation. We also provide a new semantics for type raising, which is necessary for certain constructions. Using these mechanisms, we suggest an analysis of eventive nouns, which present a challenge for deriving AMR graphs. Our theoretical analysis will facilitate future work on robust and transparent AMR parsing using CCG.</abstract>
      <url>W19-0405</url>
    </paper>
    <paper id="6">
      <title>A Semantic Ontology of <fixed-case>D</fixed-case>anish Adjectives</title>
      <author><first>Eckhard</first><last>Bick</last></author>
      <pages>71–78</pages>
      <abstract>This paper presents a semantic annotation scheme for Danish adjectives, focusing both on prototypical semantic content and semantic collocational restrictions on an adjective’s head noun. The core type set comprises about 110 categories ordered in a shallow hierarchy with 14 primary and 25 secondary umbrella categories. In addition, domain information and binary sentiment tags are provided, as well as VerbNet-derived frames and semantic roles for those adjectives governing arguments. The scheme has been almost fully implemented on the lexicon of the Danish VISL parser, DanGram, containing 14,000 adjectives. We discuss the annotation scheme and its applicational perspectives, and present a statistical breakdown and coverage evaluation for three Danish reference corpora.</abstract>
      <url>W19-0406</url>
    </paper>
    <paper id="7">
      <title>Towards a Compositional Analysis of <fixed-case>G</fixed-case>erman Light Verb Constructions (<fixed-case>LVC</fixed-case>s) Combining Lexicalized Tree Adjoining Grammar (<fixed-case>LTAG</fixed-case>) with Frame Semantics</title>
      <author><first>Jens</first><last>Fleischhauer</last></author>
      <author><first>Thomas</first><last>Gamerschlag</last></author>
      <author><first>Laura</first><last>Kallmeyer</last></author>
      <author><first>Simon</first><last>Petitjean</last></author>
      <pages>79–90</pages>
      <abstract>Complex predicates formed of a semantically ‘light’ verbal head and a noun or verb which contributes the major part of the meaning are frequently referred to as ‘light verb constructions’ (LVCs). In the paper, we present a case study of LVCs with the German posture verb stehen ‘stand’. In our account, we model the syntactic as well as semantic composition of such LVCs by combining Lexicalized Tree Adjoining Grammar (LTAG) with frames. Starting from the analysis of the literal uses of posture verbs, we show how the meaning components of the literal uses are systematically exploited in the interpretation of stehen-LVCs. The paper constitutes an important step towards a compositional and computational analysis of LVCs. We show that LTAG allows us to separate constructional from lexical meaning components and that frames enable elegant generalizations over event types and related constraints.</abstract>
      <url>W19-0407</url>
    </paper>
    <paper id="8">
      <title>Words are Vectors, Dependencies are Matrices: Learning Word Embeddings from Dependency Graphs</title>
      <author><first>Paula</first><last>Czarnowska</last></author>
      <author><first>Guy</first><last>Emerson</last></author>
      <author><first>Ann</first><last>Copestake</last></author>
      <pages>91–102</pages>
      <abstract>Distributional Semantic Models (DSMs) construct vector representations of word meanings based on their contexts. Typically, the contexts of a word are defined as its closest neighbours, but they can also be retrieved from its syntactic dependency relations. In this work, we propose a new dependency-based DSM. The novelty of our model lies in associating an independent meaning representation, a matrix, with each dependency-label. This allows it to capture specifics of the relations between words and contexts, leading to good performance on both intrinsic and extrinsic evaluation tasks. In addition to that, our model has an inherent ability to represent dependency chains as products of matrices which provides a straightforward way of handling further contexts of a word.</abstract>
      <url>W19-0408</url>
    </paper>
    <paper id="9">
      <title>Temporal and Aspectual Entailment</title>
      <author><first>Thomas</first><last>Kober</last></author>
      <author><first>Sander Bijl</first><last>de Vroe</last></author>
      <author><first>Mark</first><last>Steedman</last></author>
      <pages>103–119</pages>
      <abstract>Inferences regarding “Jane’s arrival in London” from predications such as “Jane is going to London” or “Jane has gone to London” depend on tense and aspect of the predications. Tense determines the temporal location of the predication in the past, present or future of the time of utterance. The aspectual auxiliaries on the other hand specify the internal constituency of the event, i.e. whether the event of “going to London” is completed and whether its consequences hold at that time or not. While tense and aspect are among the most important factors for determining natural language inference, there has been very little work to show whether modern embedding models capture these semantic concepts. In this paper we propose a novel entailment dataset and analyse the ability of contextualised word representations to perform inference on predications across aspectual types and tenses. We show that they encode a substantial amount of information relating to tense and aspect, but fail to consistently model inferences that require reasoning with these semantic properties.</abstract>
      <url>W19-0409</url>
    </paper>
    <paper id="10">
      <title>Don’t Blame Distributional Semantics if it can’t do Entailment</title>
      <author><first>Matthijs</first><last>Westera</last></author>
      <author><first>Gemma</first><last>Boleda</last></author>
      <pages>120–133</pages>
      <abstract>Distributional semantics has had enormous empirical success in Computational Linguistics and Cognitive Science in modeling various semantic phenomena, such as semantic similarity, and distributional models are widely used in state-of-the-art Natural Language Processing systems. However, the theoretical status of distributional semantics within a broader theory of language and cognition is still unclear: What does distributional semantics model? Can it be, on its own, a fully adequate model of the meanings of linguistic expressions? The standard answer is that distributional semantics is not fully adequate in this regard, because it falls short on some of the central aspects of formal semantic approaches: truth conditions, entailment, reference, and certain aspects of compositionality. We argue that this standard answer rests on a misconception: These aspects do not belong in a theory of expression meaning, they are instead aspects of speaker meaning, i.e., communicative intentions in a particular context. In a slogan: words do not refer, speakers do. Clearing this up enables us to argue that distributional semantics on its own is an adequate model of expression meaning. Our proposal sheds light on the role of distributional semantics in a broader theory of language and cognition, its relationship to formal semantics, and its place in computational models.</abstract>
      <url>W19-0410</url>
    </paper>
    <paper id="11">
      <title>Ambiguity in Explicit Discourse Connectives</title>
      <author><first>Bonnie</first><last>Webber</last></author>
      <author><first>Rashmi</first><last>Prasad</last></author>
      <author><first>Alan</first><last>Lee</last></author>
      <pages>134–141</pages>
      <abstract>Discourse connectives are known to be subject to both usage and sense ambiguity, as has already been discussed in the literature. But discourse connectives are no different from other linguistic expressions in being subject to other types of ambiguity as well. Four are illustrated and discussed here.</abstract>
      <url>W19-0411</url>
    </paper>
    <paper id="12">
      <title>Aligning Open <fixed-case>IE</fixed-case> Relations and <fixed-case>KB</fixed-case> Relations using a <fixed-case>S</fixed-case>iamese Network Based on Word Embedding</title>
      <author><first>Rifki Afina</first><last>Putri</last></author>
      <author><first>Giwon</first><last>Hong</last></author>
      <author><first>Sung-Hyon</first><last>Myaeng</last></author>
      <pages>142–153</pages>
      <abstract>Open Information Extraction (Open IE) aims at generating entity-relation-entity triples from a large amount of text, aiming at capturing key semantics of the text. Given a triple, the relation expresses the type of semantic relation between the entities. Although relations from an Open IE system are more extensible than those used in a traditional Information Extraction system and a Knowledge Base (KB) such as Knowledge Graphs, the former lacks in semantics; an Open IE relation is simply a sequence of words, whereas a KB relation has a predefined meaning. As a way to provide a meaning to an Open IE relation, we attempt to align it with one of the predefined set of relations used in a KB. Our approach is to use a Siamese network that compares two sequences of word embeddings representing an Open IE relation and a predefined KB relation. In order to make the approach practical, we automatically generate a training dataset using a distant supervision approach instead of relying on a hand-labeled dataset. Our experiment shows that the proposed method can capture the relational semantics better than the recent approaches.</abstract>
      <url>W19-0412</url>
    </paper>
    <paper id="13">
      <title>Language-Agnostic Model for Aspect-Based Sentiment Analysis</title>
      <author><first>Md Shad</first><last>Akhtar</last></author>
      <author><first>Abhishek</first><last>Kumar</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>154–164</pages>
      <abstract>In this paper, we propose a language-agnostic deep neural network architecture for aspect-based sentiment analysis. The proposed approach is based on Bidirectional Long Short-Term Memory (Bi-LSTM) network, which is further assisted with extra hand-crafted features. We define three different architectures for the successful combination of word embeddings and hand-crafted features. We evaluate the proposed approach for six languages (i.e. English, Spanish, French, Dutch, German and Hindi) and two problems (i.e. aspect term extraction and aspect sentiment classification). Experiments show that the proposed model attains state-of-the-art performance in most of the settings.</abstract>
      <url>W19-0413</url>
    </paper>
    <paper id="14">
      <title>The Effect of Context on Metaphor Paraphrase Aptness Judgments</title>
      <author><first>Yuri</first><last>Bizzoni</last></author>
      <author><first>Shalom</first><last>Lappin</last></author>
      <pages>165–175</pages>
      <abstract>We conduct two experiments to study the effect of context on metaphor paraphrase aptness judgments. The first is an AMT crowd source task in which speakers rank metaphor-paraphrase candidate sentence pairs in short document contexts for paraphrase aptness. In the second we train a composite DNN to predict these human judgments, first in binary classifier mode, and then as gradient ratings. We found that for both mean human judgments and our DNN’s predictions, adding document context compresses the aptness scores towards the center of the scale, raising low out-of-context ratings and decreasing high out-of-context scores. We offer a provisional explanation for this compression effect.</abstract>
      <url>W19-0414</url>
    </paper>
    <paper id="15">
      <title>Predicting Word Concreteness and Imagery</title>
      <author><first>Jean</first><last>Charbonnier</last></author>
      <author><first>Christian</first><last>Wartena</last></author>
      <pages>176–187</pages>
      <abstract>Concreteness of words has been studied extensively in psycholinguistic literature. A number of datasets have been created with average values for perceived concreteness of words. We show that we can train a regression model on these data, using word embeddings and morphological features, that can predict these concreteness values with high accuracy. We evaluate the model on 7 publicly available datasets. Only for a few small subsets of these datasets prediction of concreteness values are found in the literature. Our results clearly outperform the reported results for these datasets.</abstract>
      <url>W19-0415</url>
    </paper>
    <paper id="16">
      <title>Learning to Explicitate Connectives with <fixed-case>S</fixed-case>eq2<fixed-case>S</fixed-case>eq Network for Implicit Discourse Relation Classification</title>
      <author><first>Wei</first><last>Shi</last></author>
      <author><first>Vera</first><last>Demberg</last></author>
      <pages>188–199</pages>
      <abstract>Implicit discourse relation classification is one of the most difficult steps in discourse parsing. The difficulty stems from the fact that the coherence relation must be inferred based on the content of the discourse relational arguments. Therefore, an effective encoding of the relational arguments is of crucial importance. We here propose a new model for implicit discourse relation classification, which consists of a classifier, and a sequence-to-sequence model which is trained to generate a representation of the discourse relational arguments by trying to predict the relational arguments including a suitable implicit connective. Training is possible because such implicit connectives have been annotated as part of the PDTB corpus. Along with a memory network, our model could generate more refined representations for the task. And on the now standard 11-way classification, our method outperforms the previous state of the art systems on the PDTB benchmark on multiple settings including cross validation.</abstract>
      <url>W19-0416</url>
    </paper>
    <paper id="17">
      <title>Cross-Lingual Transfer of Semantic Roles: From Raw Text to Semantic Roles</title>
      <author><first>Maryam</first><last>Aminian</last></author>
      <author><first>Mohammad Sadegh</first><last>Rasooli</last></author>
      <author><first>Mona</first><last>Diab</last></author>
      <pages>200–210</pages>
      <abstract>We describe a transfer method based on annotation projection to develop a dependency-based semantic role labeling system for languages for which no supervised linguistic information other than parallel data is available. Unlike previous work that presumes the availability of supervised features such as lemmas, part-of-speech tags, and dependency parse trees, we only make use of word and character features. Our deep model considers using character-based representations as well as unsupervised stem embeddings to alleviate the need for supervised features. Our experiments outperform a state-of-the-art method that uses supervised lexico-syntactic features on 6 out of 7 languages in the Universal Proposition Bank.</abstract>
      <url>W19-0417</url>
    </paper>
    <paper id="18">
      <title>Evaluating the Representational Hub of Language and Vision Models</title>
      <author><first>Ravi</first><last>Shekhar</last></author>
      <author><first>Ece</first><last>Takmaz</last></author>
      <author><first>Raquel</first><last>Fernández</last></author>
      <author><first>Raffaella</first><last>Bernardi</last></author>
      <pages>211–222</pages>
      <abstract>The multimodal models used in the emerging field at the intersection of computational linguistics and computer vision implement the bottom-up processing of the “Hub and Spoke” architecture proposed in cognitive science to represent how the brain processes and combines multi-sensory inputs. In particular, the Hub is implemented as a neural network encoder. We investigate the effect on this encoder of various vision-and-language tasks proposed in the literature: visual question answering, visual reference resolution, and visually grounded dialogue. To measure the quality of the representations learned by the encoder, we use two kinds of analyses. First, we evaluate the encoder pre-trained on the different vision-and-language tasks on an existing “diagnostic task” designed to assess multimodal semantic understanding. Second, we carry out a battery of analyses aimed at studying how the encoder merges and exploits the two modalities.</abstract>
      <url>W19-0418</url>
    </paper>
    <paper id="19">
      <title>The Fast and the Flexible: Training Neural Networks to Learn to Follow Instructions from Small Data</title>
      <author><first>Rezka</first><last>Leonandya</last></author>
      <author><first>Dieuwke</first><last>Hupkes</last></author>
      <author><first>Elia</first><last>Bruni</last></author>
      <author><first>Germán</first><last>Kruszewski</last></author>
      <pages>223–234</pages>
      <abstract>Learning to follow human instructions is a long-pursued goal in artificial intelligence. The task becomes particularly challenging if no prior knowledge of the employed language is assumed while relying only on a handful of examples to learn from. Work in the past has relied on hand-coded components or manually engineered features to provide strong inductive biases that make learning in such situations possible. In contrast, here we seek to establish whether this knowledge can be acquired automatically by a neural network system through a two phase training procedure: A (slow) offline learning stage where the network learns about the general structure of the task and a (fast) online adaptation phase where the network learns the language of a new given speaker. Controlled experiments show that when the network is exposed to familiar instructions but containing novel words, the model adapts very efficiently to the new vocabulary. Moreover, even for human speakers whose language usage can depart significantly from our artificial training language, our network can still make use of its automatically acquired inductive bias to learn to follow instructions more effectively.</abstract>
      <url>W19-0419</url>
    </paper>
    <paper id="20">
      <title>Fast and Discriminative Semantic Embedding</title>
      <author><first>Rob</first><last>Koopman</last></author>
      <author><first>Shenghui</first><last>Wang</last></author>
      <author><first>Gwenn</first><last>Englebienne</last></author>
      <pages>235–246</pages>
      <abstract>The embedding of words and documents in compact, semantically meaningful vector spaces is a crucial part of modern information systems. Deep Learning models are powerful but their hyperparameter selection is often complex and they are expensive to train, and while pre-trained models are available, embeddings trained on general corpora are not necessarily well-suited to domain specific tasks. We propose a novel embedding method which extends random projection by weighting and projecting raw term embeddings orthogonally to an average language vector, thus improving the discriminating power of resulting term embeddings, and build more meaningful document embeddings by assigning appropriate weights to individual terms. We describe how updating the term embeddings online as we process the training data results in an extremely efficient method, in terms of both computational and memory requirements. Our experiments show highly competitive results with various state-of-the-art embedding methods on different tasks, including the standard STS benchmark and a subject prediction task, at a fraction of the computational cost.</abstract>
      <url>W19-0420</url>
    </paper>
    <paper id="21">
      <title>Using Multi-Sense Vector Embeddings for Reverse Dictionaries</title>
      <author><first>Michael A.</first><last>Hedderich</last></author>
      <author><first>Andrew</first><last>Yates</last></author>
      <author><first>Dietrich</first><last>Klakow</last></author>
      <author><first>Gerard</first><last>de Melo</last></author>
      <pages>247–258</pages>
      <abstract>Popular word embedding methods such as word2vec and GloVe assign a single vector representation to each word, even if a word has multiple distinct meanings. Multi-sense embeddings instead provide different vectors for each sense of a word. However, they typically cannot serve as a drop-in replacement for conventional single-sense embeddings, because the correct sense vector needs to be selected for each word. In this work, we study the effect of multi-sense embeddings on the task of reverse dictionaries. We propose a technique to easily integrate them into an existing neural network architecture using an attention mechanism. Our experiments demonstrate that large improvements can be obtained when employing multi-sense embeddings both in the input sequence as well as for the target representation. An analysis of the sense distributions and of the learned attention is provided as well.</abstract>
      <url>W19-0421</url>
    </paper>
    <paper id="22">
      <title>Using <fixed-case>W</fixed-case>iktionary as a resource for <fixed-case>WSD</fixed-case> : the case of <fixed-case>F</fixed-case>rench verbs</title>
      <author><first>Vincent</first><last>Segonne</last></author>
      <author><first>Marie</first><last>Candito</last></author>
      <author><first>Benoît</first><last>Crabbé</last></author>
      <pages>259–270</pages>
      <abstract>As opposed to word sense induction, word sense disambiguation (WSD) has the advantage of us-ing interpretable senses, but requires annotated data, which are quite rare for most languages except English (Miller et al. 1993; Fellbaum, 1998). In this paper, we investigate which strategy to adopt to achieve WSD for languages lacking data that was annotated specifically for the task, focusing on the particular case of verb disambiguation in French. We first study the usability of Eurosense (Bovi et al. 2017) , a multilingual corpus extracted from Europarl (Kohen, 2005) and automatically annotated with BabelNet (Navigli and Ponzetto, 2010) senses. Such a resource opened up the way to supervised and semi-supervised WSD for resourceless languages like French. While this perspective looked promising, our evaluation on French verbs was inconclusive and showed the annotated senses’ quality was not sufficient for supervised WSD on French verbs. Instead, we propose to use Wiktionary, a collaboratively edited, multilingual online dictionary, as a resource for WSD. Wiktionary provides both sense inventory and manually sense tagged examples which can be used to train supervised and semi-supervised WSD systems. Yet, because senses’ distribution differ in lexicographic examples found in Wiktionary with respect to natural text, we then focus on studying the impact on WSD of the training data size and senses’ distribution. Using state-of-the art semi-supervised systems, we report experiments of Wiktionary-based WSD for French verbs, evaluated on FrenchSemEval (FSE), a new dataset of French verbs manually annotated with wiktionary senses.</abstract>
      <url>W19-0422</url>
    </paper>
    <paper id="23">
      <title>A Comparison of Context-sensitive Models for Lexical Substitution</title>
      <author><first>Aina Garí</first><last>Soler</last></author>
      <author><first>Anne</first><last>Cocos</last></author>
      <author><first>Marianna</first><last>Apidianaki</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <pages>271–282</pages>
      <abstract>Word embedding representations provide good estimates of word meaning and give state-of-the art performance in semantic tasks. Embedding approaches differ as to whether and how they account for the context surrounding a word. We present a comparison of different word and context representations on the task of proposing substitutes for a target word in context (lexical substitution). We also experiment with tuning contextualized word embeddings on a dataset of sense-specific instances for each target word. We show that powerful contextualized word representations, which give high performance in several semantics-related tasks, deal less well with the subtle in-context similarity relationships needed for substitution. This is better handled by models trained with this objective in mind, where the inter-dependence between word and context representations is explicitly modeled during training.</abstract>
      <url>W19-0423</url>
    </paper>
    <paper id="24">
      <title>Natural Language Semantics With Pictures: Some Language &amp; Vision Datasets and Potential Uses for Computational Semantics</title>
      <author><first>David</first><last>Schlangen</last></author>
      <pages>283–294</pages>
      <abstract>Propelling, and propelled by, the “deep learning revolution”, recent years have seen the introduction of ever larger corpora of images annotated with natural language expressions. We survey some of these corpora, taking a perspective that reverses the usual directionality, as it were, by viewing the images as semantic annotation of the natural language expressions. We discuss datasets that can be derived from the corpora, and tasks of potential interest for computational semanticists that can be defined on those. In this, we make use of relations provided by the corpora (namely, the link between expression and image, and that between two expressions linked to the same image) and relations that we can add (similarity relations between expressions, or between images). Specifically, we show that in this way we can create data that can be used to learn and evaluate lexical and compositional grounded semantics, and we show that the “linked to same image” relation tracks a semantic implication relation that is recognisable to annotators even in the absence of the linking image as evidence. Finally, as an example of possible benefits of this approach, we show that an exemplar-model-based approach to implication beats a (simple) distributional space-based one on some derived datasets, while lending itself to explainability.</abstract>
      <url>W19-0424</url>
    </paper>
    <paper id="25">
      <title>Frame Identification as Categorization: Exemplars vs Prototypes in Embeddingland</title>
      <author><first>Jennifer</first><last>Sikos</last></author>
      <author><first>Sebastian</first><last>Padó</last></author>
      <pages>295–306</pages>
      <abstract>Categorization is a central capability of human cognition, and a number of theories have been developed to account for properties of categorization. Even though many tasks in semantics also involve categorization of some kind, theories of categorization do not play a major role in contemporary research in computational linguistics. This paper follows the idea that embedding-based models of semantics lend themselves well to being formulated in terms of classical categorization theories. The benefit is a space of model families that enables (a) the formulation of hypotheses about the impact of major design decisions, and (b) a transparent assessment of these decisions. We instantiate this idea on the task of frame-semantic frame identification. We define four models that cross two design variables: (a) the choice of prototype vs. exemplar categorization, corresponding to different degrees of generalization applied to the input; and (b) the presence vs. absence of a fine-tuning step, corresponding to generic vs. task-adaptive categorization. We find that for frame identification, generalization and task-adaptive categorization both yield substantial benefits. Our prototype-based, fine-tuned model, which combines the best choices for these variables, establishes a new state of the art in frame identification.</abstract>
      <url>W19-0425</url>
    </paper>
  </volume>
  <volume id="5">
    <meta>
      <booktitle>Proceedings of the 13th International Conference on Computational Semantics - Short Papers</booktitle>
      <url>W19-05</url>
      <editor><first>Simon</first><last>Dobnik</last></editor>
      <editor><first>Stergios</first><last>Chatzikyriakidis</last></editor>
      <editor><first>Vera</first><last>Demberg</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Gothenburg, Sweden</address>
      <month>23–27 May</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-0500</url>
    </frontmatter>
    <paper id="1">
      <title>A Distributional Model of Affordances in Semantic Type Coercion</title>
      <author><first>Stephen</first><last>McGregor</last></author>
      <author><first>Elisabetta</first><last>Jezek</last></author>
      <pages>1–7</pages>
      <abstract>We explore a novel application for interpreting semantic type coercions, motivated by insight into the role that perceptual affordances play in the selection of the semantic roles of artefactual nouns which are observed as arguments for verbs which would stereotypically select for objects of a different type. In order to simulate affordances, which we take to be direct perceptions of context-specific opportunities for action, we preform a distributional analysis dependency relationships between target words and their modifiers and adjuncts. We use these relationships as the basis for generating on-line transformations which project semantic subspaces in which the interpretations of coercive compositions are expected to emerge as salient word-vectors. We offer some preliminary examples of how this model operates on a dataset of sentences involving coercive interactions between verbs and objects specifically designed to evaluate this work.</abstract>
      <url>W19-0501</url>
    </paper>
    <paper id="2">
      <title>Natural Language Inference with Monotonicity</title>
      <author><first>Hai</first><last>Hu</last></author>
      <author><first>Qi</first><last>Chen</last></author>
      <author><first>Larry</first><last>Moss</last></author>
      <pages>8–15</pages>
      <abstract>This paper describes a working system which performs natural language inference using polarity-marked parse trees. The system handles all of the instances of monotonicity inference in the FraCaS data set. Except for the initial parse, it is entirely deterministic. It handles multi-premise arguments, and the kind of inference performed is essentially “logical”, but it goes beyond what is representable in first-order logic. In any case, the system works on surface forms rather than on representations of any kind.</abstract>
      <url>W19-0502</url>
    </paper>
    <paper id="3">
      <title>Distributional Semantics in the Real World: Building Word Vector Representations from a Truth-Theoretic Model</title>
      <author><first>Elizaveta</first><last>Kuzmenko</last></author>
      <author><first>Aurélie</first><last>Herbelot</last></author>
      <pages>16–23</pages>
      <abstract>Distributional semantics models (DSMs) are known to produce excellent representations of word meaning, which correlate with a range of behavioural data. As lexical representations, they have been said to be fundamentally different from truth-theoretic models of semantics, where meaning is defined as a correspondence relation to the world. There are two main aspects to this difference: a) DSMs are built over corpus data which may or may not reflect ‘what is in the world’; b) they are built from word co-occurrences, that is, from lexical types rather than entities and sets. In this paper, we inspect the properties of a distributional model built over a set-theoretic approximation of ‘the real world’. To achieve this, we take the annotation a large database of images marked with objects, attributes and relations, convert the data into a representation akin to first-order logic and build several distributional models using various combinations of features. We evaluate those models over both relatedness and similarity datasets, demonstrating their effectiveness in standard evaluations. This allows us to conclude that, despite prior claims, truth-theoretic models are good candidates for building graded lexical representations of meaning.</abstract>
      <url>W19-0503</url>
    </paper>
    <paper id="4">
      <title>Linguistic Information in Neural Semantic Parsing with Multiple Encoders</title>
      <author><first>Rik</first><last>van Noord</last></author>
      <author><first>Antonio</first><last>Toral</last></author>
      <author><first>Johan</first><last>Bos</last></author>
      <pages>24–31</pages>
      <abstract>Recently, sequence-to-sequence models have achieved impressive performance on a number of semantic parsing tasks. However, they often do not exploit available linguistic resources, while these, when employed correctly, are likely to increase performance even further. Research in neural machine translation has shown that employing this information has a lot of potential, especially when using a multi-encoder setup. We employ a range of semantic and syntactic resources to improve performance for the task of Discourse Representation Structure Parsing. We show that (i) linguistic features can be beneficial for neural semantic parsing and (ii) the best method of adding these features is by using multiple encoders.</abstract>
      <url>W19-0504</url>
    </paper>
    <paper id="5">
      <title>Making Sense of Conflicting (Defeasible) Rules in the Controlled Natural Language <fixed-case>ACE</fixed-case>: Design of a System with Support for Existential Quantification Using Skolemization</title>
      <author><first>Martin</first><last>Diller</last></author>
      <author><first>Adam</first><last>Wyner</last></author>
      <author><first>Hannes</first><last>Strass</last></author>
      <pages>32–37</pages>
      <abstract>We present the design of a system for making sense of conflicting rules expressed in a fragment of the prominent controlled natural language ACE, yet extended with means of expressing defeasible rules in the form of normality assumptions. The approach we describe is ultimately based on answer-set-programming (ASP); simulating existential quantification by using skolemization in a manner resembling a translation for ASP recently formalized in the context of ∃-ASP. We discuss the advantages of this approach to building on the existing ACE interface to rule-systems, ACERules.</abstract>
      <url>W19-0505</url>
    </paper>
    <paper id="6">
      <title>Distributional Interaction of Concreteness and Abstractness in Verb–Noun Subcategorisation</title>
      <author><first>Diego</first><last>Frassinelli</last></author>
      <author><first>Sabine</first><last>Schulte im Walde</last></author>
      <pages>38–43</pages>
      <abstract>In recent years, both cognitive and computational research has provided empirical analyses of contextual co-occurrence of concrete and abstract words, partially resulting in inconsistent pictures. In this work we provide a more fine-grained description of the distributional nature in the corpus- based interaction of verbs and nouns within subcategorisation, by investigating the concreteness of verbs and nouns that are in a specific syntactic relationship with each other, i.e., subject, direct object, and prepositional object. Overall, our experiments show consistent patterns in the distributional representation of subcategorising and subcategorised concrete and abstract words. At the same time, the studies reveal empirical evidence why contextual abstractness represents a valuable indicator for automatic non-literal language identification.</abstract>
      <url>W19-0506</url>
    </paper>
    <paper id="7">
      <title>Generating a Novel Dataset of Multimodal Referring Expressions</title>
      <author><first>Nikhil</first><last>Krishnaswamy</last></author>
      <author><first>James</first><last>Pustejovsky</last></author>
      <pages>44–51</pages>
      <abstract>Referring expressions and definite descriptions of objects in space exploit information both about object characteristics and locations. To resolve potential ambiguity, referencing strategies in language can rely on increasingly abstract concepts to distinguish an object in a given location from similar ones elsewhere, yet the description of the intended location may still be imprecise or difficult to interpret. Meanwhile, modalities such as gesture may communicate spatial information such as locations in a more concise manner. In real peer-to-peer communication, humans use language and gesture together to reference entities, with a capacity for mixing and changing modalities where needed. While recent progress in AI and human-computer interaction has created systems where a human can interact with a computer multimodally, computers often lack the capacity to intelligently mix modalities when generating referring expressions. We present a novel dataset of referring expressions combining natural language and gesture, describe its creation and evaluation, and its uses to train computational models for generating and interpreting multimodal referring expressions.</abstract>
      <url>W19-0507</url>
    </paper>
    <paper id="8">
      <title>On Learning Word Embeddings From Linguistically Augmented Text Corpora</title>
      <author><first>Amila</first><last>Silva</last></author>
      <author><first>Chathurika</first><last>Amarathunga</last></author>
      <pages>52–58</pages>
      <abstract>Word embedding is a technique in Natural Language Processing (NLP) to map words into vector space representations. Since it has boosted the performance of many NLP downstream tasks, the task of learning word embeddings has been addressing significantly. Nevertheless, most of the underlying word embedding methods such as word2vec and GloVe fail to produce high-quality embeddings if the text corpus is small and sparse. This paper proposes a method to generate effective word embeddings from limited data. Through experiments, we show that our proposed model outperforms existing works for the classical word similarity task and for a domain-specific application.</abstract>
      <url>W19-0508</url>
    </paper>
    <paper id="9">
      <title>Sentiment Independent Topic Detection in Rated Hospital Reviews</title>
      <author><first>Christian</first><last>Wartena</last></author>
      <author><first>Uwe</first><last>Sander</last></author>
      <author><first>Christiane</first><last>Patzelt</last></author>
      <pages>59–64</pages>
      <abstract>We present a simple method to find topics in user reviews that accompany ratings for products or services. Standard topic analysis will perform sub-optimal on such data since the word distributions in the documents are not only determined by the topics but by the sentiment as well. We reduce the influence of the sentiment on the topic selection by adding two explicit topics, representing positive and negative sentiment. We evaluate the proposed method on a set of over 15,000 hospital reviews. We show that the proposed method, Latent Semantic Analysis with explicit word features, finds topics with a much smaller bias for sentiments than other similar methods.</abstract>
      <url>W19-0509</url>
    </paper>
    <paper id="10">
      <title>Investigating the Stability of Concrete Nouns in Word Embeddings</title>
      <author><first>Bénédicte</first><last>Pierrejean</last></author>
      <author><first>Ludovic</first><last>Tanguy</last></author>
      <pages>65–70</pages>
      <abstract>We know that word embeddings trained using neural-based methods (such as word2vec SGNS) are sensitive to stability problems and that across two models trained using the exact same set of parameters, the nearest neighbors of a word are likely to change. All words are not equally impacted by this internal instability and recent studies have investigated features influencing the stability of word embeddings. This stability can be seen as a clue for the reliability of the semantic representation of a word. In this work, we investigate the influence of the degree of concreteness of nouns on the stability of their semantic representation. We show that for English generic corpora, abstract words are more affected by stability problems than concrete words. We also found that to a certain extent, the difference between the degree of concreteness of a noun and its nearest neighbors can partly explain the stability or instability of its neighbors.</abstract>
      <url>W19-0510</url>
    </paper>
  </volume>
  <volume id="6">
    <meta>
      <booktitle>Proceedings of the 13th International Conference on Computational Semantics - Student Papers</booktitle>
      <url>W19-06</url>
      <editor><first>Simon</first><last>Dobnik</last></editor>
      <editor><first>Stergios</first><last>Chatzikyriakidis</last></editor>
      <editor><first>Vera</first><last>Demberg</last></editor>
      <editor><first>Kathrein</first><last>Abu Kwaik</last></editor>
      <editor><first>Vladislav</first><last>Maraev</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Gothenburg, Sweden</address>
      <month>23–27 May</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-0600</url>
    </frontmatter>
    <paper id="1">
      <title>A Dynamic Semantics for Causal Counterfactuals</title>
      <author><first>Kenneth</first><last>Lai</last></author>
      <author><first>James</first><last>Pustejovsky</last></author>
      <pages>1–8</pages>
      <abstract>Under the standard approach to counterfactuals, to determine the meaning of a counterfactual sentence, we consider the “closest” possible world(s) where the antecedent is true, and evaluate the consequent. Building on the standard approach, some researchers have found that the set of worlds to be considered is dependent on context; it evolves with the discourse. Others have focused on how to define the “distance” between possible worlds, using ideas from causal modeling. This paper integrates the two ideas. We present a semantics for counterfactuals that uses a distance measure based on causal laws, that can also change over time. We show how our semantics can be implemented in the Haskell programming language.</abstract>
      <url>W19-0601</url>
    </paper>
    <paper id="2">
      <title>Visual <fixed-case>TTR</fixed-case> - Modelling Visual Question Answering in Type Theory with Records</title>
      <author><first>Ronja</first><last>Utescher</last></author>
      <pages>9–14</pages>
      <abstract>In this paper, I will describe a system that was developed for the task of Visual Question Answering. The system uses the rich type universe of Type Theory with Records (TTR) to model both the utterances about the image, the image itself and classifications made related to the two. At its most basic, the decision of whether any given predicate can be assigned to an object in the image is delegated to a CNN. Consequently, images can be judged as evidence for propositions. The end result is a model whose application of perceptual classifiers to a given image is guided by the accompanying utterance.</abstract>
      <url>W19-0602</url>
    </paper>
    <paper id="3">
      <title>The Lexical Gap: An Improved Measure of Automated Image Description Quality</title>
      <author><first>Austin</first><last>Kershaw</last></author>
      <author><first>Miroslaw</first><last>Bober</last></author>
      <pages>15–23</pages>
      <abstract>The challenge of automatically describing images and videos has stimulated much research in Computer Vision and Natural Language Processing. In order to test the semantic abilities of new algorithms, we need reliable and objective ways of measuring progress. We show that standard evaluation measures do not take into account the semantic richness of a description, and give the impression that sparse machine descriptions outperform rich human descriptions. We introduce and test a new measure of semantic ability based on relative lexical diversity. We show how our measure can work alongside existing measures to achieve state of the art correlation with human judgement of quality. We also introduce a new dataset: Rich-Sparse Descriptions, which provides 2K human and machine descriptions to stimulate interest into the semantic evaluation of machine descriptions.</abstract>
      <url>W19-0603</url>
    </paper>
    <paper id="4">
      <title>Modeling language constructs with fuzzy sets: some approaches, examples and interpretations</title>
      <author><first>Pavlo</first><last>Kapustin</last></author>
      <author><first>Michael</first><last>Kapustin</last></author>
      <pages>24–33</pages>
      <abstract>We present and discuss a couple of approaches, including different types of projections, and some examples, discussing the use of fuzzy sets for modeling meaning of certain types of language constructs. We are mostly focusing on words other than adjectives and linguistic hedges as these categories are the most studied from before. We discuss logical and linguistic interpretations of membership functions. We argue that using fuzzy sets for modeling meaning of words and other natural language constructs, along with situations described with natural language is interesting both from purely linguistic perspective, and also as a knowledge representation for problems of computational linguistics and natural language processing.</abstract>
      <url>W19-0604</url>
    </paper>
    <paper id="5">
      <title>Topological Data Analysis for Discourse Semantics?</title>
      <author><first>Ketki</first><last>Savle</last></author>
      <author><first>Wlodek</first><last>Zadrozny</last></author>
      <author><first>Minwoo</first><last>Lee</last></author>
      <pages>34–43</pages>
      <abstract>In this paper we present new results on applying topological data analysis to discourse structures. We show that topological information, extracted from the relationships between sentences can be used in inference, namely it can be applied to the very difficult legal entailment given in the COLIEE 2018 data set. Previous results of Doshi and Zadrozny (2018) and Gholizadeh et al. (2018) show that topological features are useful for classification. The applications of computational topology to entailment are novel in our view provide a new set of tools for discourse semantics: computational topology can perhaps provide a bridge between the brittleness of logic and the regression of neural networks. We discuss the advantages and disadvantages of using topological information, and some open problems such as explainability of the classifier decisions.</abstract>
      <url>W19-0605</url>
    </paper>
    <paper id="6">
      <title>Semantic Frame Embeddings for Detecting Relations between Software Requirements</title>
      <author><first>Waad</first><last>Alhoshan</last></author>
      <author><first>Riza</first><last>Batista-Navarro</last></author>
      <author><first>Liping</first><last>Zhao</last></author>
      <pages>44–51</pages>
      <abstract>The early phases of requirements engineering (RE) deal with a vast amount of software requirements (i.e., requirements that define characteristics of software systems), which are typically expressed in natural language. Analysing such unstructured requirements, usually obtained from users’ inputs, is considered a challenging task due to the inherent ambiguity and inconsistency of natural language. To support such a task, methods based on natural language processing (NLP) can be employed. One of the more recent advances in NLP is the use of word embeddings for capturing contextual information, which can then be applied in word analogy tasks. In this paper, we describe a new resource, i.e., embedding-based representations of semantic frames in FrameNet, which was developed to support the detection of relations between software requirements. Our embeddings, which encapsulate contextual information at the semantic frame level, were trained on a large corpus of requirements (i.e., a collection of more than three million mobile application reviews). The similarity between these frame embeddings is then used as a basis for detecting semantic relatedness between software requirements. Compared with existing resources underpinned by word-level embeddings alone, and frame embeddings built upon pre-trained vectors, our proposed frame embeddings obtained better performance against judgements of an RE expert. These encouraging results demonstrate the strong potential of the resource in supporting RE analysis tasks (e.g., traceability), which we plan to investigate as part of our future work.</abstract>
      <url>W19-0606</url>
    </paper>
    <paper id="7">
      <title>R-grams: Unsupervised Learning of Semantic Units in Natural Language</title>
      <author><first>Amaru Cuba</first><last>Gyllensten</last></author>
      <author><first>Ariel</first><last>Ekgren</last></author>
      <author><first>Magnus</first><last>Sahlgren</last></author>
      <pages>52–62</pages>
      <abstract>This paper investigates data-driven segmentation using Re-Pair or Byte Pair Encoding-techniques. In contrast to previous work which has primarily been focused on subword units for machine translation, we are interested in the general properties of such segments above the word level. We call these segments r-grams, and discuss their properties and the effect they have on the token frequency distribution. The proposed approach is evaluated by demonstrating its viability in embedding techniques, both in monolingual and multilingual test settings. We also provide a number of qualitative examples of the proposed methodology, demonstrating its viability as a language-invariant segmentation procedure.</abstract>
      <url>W19-0607</url>
    </paper>
  </volume>
  <volume id="8">
    <meta>
      <booktitle><fixed-case>RELATIONS</fixed-case> - Workshop on meaning relations between phrases and sentences</booktitle>
      <url>W19-08</url>
      <editor><first>Venelin</first><last>Kovatchev</last></editor>
      <editor><first>Darina</first><last>Gold</last></editor>
      <editor><first>Torsten</first><last>Zesch</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Gothenburg, Sweden</address>
      <month>23 May</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-0800</url>
    </frontmatter>
    <paper id="1">
      <title>Assessing the Difficulty of Classifying <fixed-case>C</fixed-case>oncept<fixed-case>N</fixed-case>et Relations in a Multi-Label Classification Setting</title>
      <author><first>Maria</first><last>Becker</last></author>
      <author><first>Michael</first><last>Staniek</last></author>
      <author><first>Vivi</first><last>Nastase</last></author>
      <author><first>Anette</first><last>Frank</last></author>
      <abstract>Commonsense knowledge relations are crucial for advanced NLU tasks. We examine the learnability of such relations as represented in ConceptNet, taking into account their specific properties, which can make relation classification difficult: a given concept pair can be linked by multiple relation types, and relations can have multi-word arguments of diverse semantic types. We explore a neural open world multi-label classification approach that focuses on the evaluation of classification accuracy for individual relations. Based on an in-depth study of the specific properties of the ConceptNet resource, we investigate the impact of different relation representations and model variations. Our analysis reveals that the complexity of argument types and relation ambiguity are the most important challenges to address. We design a customized evaluation method to address the incompleteness of the resource that can be expanded in future work.</abstract>
      <url>W19-0801</url>
    </paper>
    <paper id="2">
      <title>Detecting Collocations Similarity via Logical-Linguistic Model</title>
      <author><first>Nina</first><last>Khairova</last></author>
      <author><first>Svitlana</first><last>Petrasova</last></author>
      <author><first>Orken</first><last>Mamyrbayev</last></author>
      <author><first>Kuralay</first><last>Mukhsina</last></author>
      <abstract>Semantic similarity between collocations, along with words similarity, is one of the main issues of NLP, which must be addressed, in particular, in order to facilitate the automatic thesaurus generation. In the paper, we consider the logical-linguistic model that allows defining the relation of semantic similarity of collocations via the logical-algebraic equations. We provide the model for English, Ukrainian and Russian text corpora. The implementation for each language is slightly different in the equations of the finite predicates algebra and used linguistic resources. As a dataset for our experiment, we use 5801 pairs of sentences of Microsoft Research Paraphrase Corpus for English and more than 1 000 texts of scientific papers for Russian and Ukrainian.</abstract>
      <url>W19-0802</url>
    </paper>
    <paper id="3">
      <title>Detecting Paraphrases of Standard Clause Titles in Insurance Contracts</title>
      <author><first>Frieda</first><last>Josi</last></author>
      <author><first>Christian</first><last>Wartena</last></author>
      <author><first>Ulrich</first><last>Heid</last></author>
      <abstract>For the analysis of contract texts, validated model texts, such as model clauses, can be used to identify reused contract clauses. This paper investigates how to calculate the similarity between titles of model clauses and headings extracted from contracts, and which similarity measure is most suitable for this. For the calculation of the similarities between title pairs we tested various variants of string similarity and token based similarity. We also compare two more semantic similarity measures based on word embeddings using pretrained embeddings and word embeddings trained on contract texts. The identification of the model clause title can be used as a starting point for the mapping of clauses found in contracts to verified clauses.</abstract>
      <url>W19-0803</url>
    </paper>
    <paper id="4">
      <title>Semantic Matching of Documents from Heterogeneous Collections: A Simple and Transparent Method for Practical Applications</title>
      <author><first>Mark-Christoph</first><last>Mueller</last></author>
      <abstract>We present a very simple, unsupervised method for the pairwise matching of documents from heterogeneous collections. We demonstrate our method with the Concept-Project matching task, which is a binary classification task involving pairs of documents from heterogeneous collections. Although our method only employs standard resources without any domain- or task-specific modifications, it clearly outperforms the more complex system of the original authors. In addition, our method is transparent, because it provides explicit information about how a similarity score was computed, and efficient, because it is based on the aggregation of (pre-computable) word-level similarities.</abstract>
      <url>W19-0804</url>
    </paper>
  </volume>
  <volume id="9">
    <meta>
      <booktitle>Proceedings of the <fixed-case>IWCS</fixed-case> Workshop Vector Semantics for Discourse and Dialogue</booktitle>
      <url>W19-09</url>
      <editor><first>Mehrnoosh</first><last>Sadrzadeh</last></editor>
      <editor><first>Matthew</first><last>Purver</last></editor>
      <editor><first>Arash</first><last>Eshghi</last></editor>
      <editor><first>Julian</first><last>Hough</last></editor>
      <editor><first>Ruth</first><last>Kempson</last></editor>
      <editor><first>Patrick G. T.</first><last>Healey</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Gothenburg, Sweden</address>
      <month>24 May</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-0900</url>
    </frontmatter>
  </volume>
  <volume id="10">
    <meta>
      <booktitle>Proceedings of the <fixed-case>IWCS</fixed-case> 2019 Workshop on Computing Semantics with Types, Frames and Related Structures</booktitle>
      <url>W19-10</url>
      <editor><first>Rainer</first><last>Osswald</last></editor>
      <editor><first>Christian</first><last>Retoré</last></editor>
      <editor><first>Peter</first><last>Sutton</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Gothenburg, Sweden</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-1000</url>
    </frontmatter>
    <paper id="1">
      <title>Underspecification and interpretive parallelism in Dependent Type Semantics</title>
      <author><first>Yusuke</first><last>Kubota</last></author>
      <author><first>Koji</first><last>Mineshima</last></author>
      <author><first>Robert</first><last>Levine</last></author>
      <author><first>Daisuke</first><last>Bekki</last></author>
      <pages>1–9</pages>
      <url>W19-1001</url>
    </paper>
    <paper id="2">
      <title>Translating a Fragment of Natural Deduction System for Natural Language into Modern Type Theory</title>
      <author><first>Ivo</first><last>Pezlar</last></author>
      <pages>10–18</pages>
      <url>W19-1002</url>
    </paper>
    <paper id="3">
      <title>Modeling the Induced Action Alternation and the Caused-Motion Construction with Tree Adjoining Grammar (<fixed-case>TAG</fixed-case>) and Semantic Frames</title>
      <author><first>Esther</first><last>Seyffarth</last></author>
      <pages>19–27</pages>
      <url>W19-1003</url>
    </paper>
    <paper id="4">
      <title>Complex event representation in a typed feature structure implementation of Role and Reference Grammar</title>
      <author><first>Erika</first><last>Bellingham</last></author>
      <pages>28–36</pages>
      <url>W19-1004</url>
    </paper>
    <paper id="5">
      <title>Computational Syntax-Semantics Interface with Type-Theory of Acyclic Recursion for Underspecified Semantics</title>
      <author><first>Roussanka</first><last>Loukanova</last></author>
      <pages>37–48</pages>
      <url>W19-1005</url>
    </paper>
    <paper id="6">
      <title>Modeling language constructs with compatibility intervals</title>
      <author><first>Pavlo</first><last>Kapustin</last></author>
      <author><first>Michael</first><last>Kapustin</last></author>
      <pages>49–54</pages>
      <url>W19-1006</url>
    </paper>
    <paper id="7">
      <title><fixed-case>I</fixed-case>mage<fixed-case>TTR</fixed-case>: Grounding Type Theory with Records in Image Classification for Visual Question Answering</title>
      <author><first>Arild</first><last>Matsson</last></author>
      <author><first>Simon</first><last>Dobnik</last></author>
      <author><first>Staffan</first><last>Larsson</last></author>
      <pages>55–64</pages>
      <url>W19-1007</url>
    </paper>
    <paper id="8">
      <title>Enthymemetic Conditionals: Topoi as a guide for acceptability</title>
      <author><first>Eimear</first><last>Maguire</last></author>
      <pages>65–74</pages>
      <url>W19-1008</url>
    </paper>
  </volume>
  <volume id="11">
    <meta>
      <booktitle>Proceedings of the Sixth Workshop on Natural Language and Computer Science</booktitle>
      <url>W19-11</url>
      <editor><first>Robin</first><last>Cooper</last></editor>
      <editor><first>Valeria</first><last>de Paiva</last></editor>
      <editor><first>Lawrence S.</first><last>Moss</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Gothenburg, Sweden</address>
      <month>24 May</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-1100</url>
    </frontmatter>
    <paper id="1">
      <title>Distribution is not enough: going Firther</title>
      <author><first>Andy</first><last>Lücking</last></author>
      <author><first>Robin</first><last>Cooper</last></author>
      <author><first>Staffan</first><last>Larsson</last></author>
      <author><first>Jonathan</first><last>Ginzburg</last></author>
      <pages>1–10</pages>
      <abstract>Much work in contemporary computational semantics follows the distributional hypothesis (DH), which is understood as an approach to semantics according to which the meaning of a word is a function of its distribution over contexts which is represented as vectors (word embeddings) within a multi-dimensional semantic space. In practice, use is identified with occurrence in text corpora, though there are some efforts to use corpora containing multi-modal information. In this paper we argue that the distributional hypothesis is intrinsically misguided as a self-supporting basis for semantics, as Firth was entirely aware. We mention philosophical arguments concerning the lack of normativity within DH data. Furthermore, we point out the shortcomings of DH as a model of learning, by discussing a variety of linguistic classes that cannot be learnt on a distributional basis, including indexicals, proper names, and wh-phrases. Instead of pursuing DH, we sketch an account of the problematic learning cases by integrating a rich, Firthian notion of dialogue context with interactive learning in signalling games backed by in probabilistic Type Theory with Records. We conclude that the success of the DH in computational semantics rests on a post hoc effect: DS presupposes a referential semantics on the basis of which utterances can be produced, comprehended and analysed in the first place.</abstract>
      <url>W19-1101</url>
    </paper>
    <paper id="2">
      <title>Towards Natural Language Story Understanding with Rich Logical Schemas</title>
      <author><first>Gene Louis</first><last>Kim</last></author>
      <author><first>Lane</first><last>Lawley</last></author>
      <author><first>Lenhart</first><last>Schubert</last></author>
      <pages>11–22</pages>
      <abstract>Generating “commonsense’’ knowledge for intelligent understanding and reasoning is a difficult, long-standing problem, whose scale challenges the capacity of any approach driven primarily by human input. Furthermore, approaches based on mining statistically repetitive patterns fail to produce the rich representations humans acquire, and fall far short of human efficiency in inducing knowledge from text. The idea of our approach to this problem is to provide a learning system with a “head start” consisting of a semantic parser, some basic ontological knowledge, and most importantly, a small set of very general schemas about the kinds of patterns of events (often purposive, causal, or socially conventional) that even a one- or two-year-old could reasonably be presumed to possess. We match these initial schemas to simple children’s stories, obtaining concrete instances, and combining and abstracting these into new candidate schemas. Both the initial and generated schemas are specified using a rich, expressive logical form. While modern approaches to schema reasoning often only use slot-and-filler structures, this logical form allows us to specify complex relations and constraints over the slots. Though formal, the representations are language-like, and as such readily relatable to NL text. The agents, objects, and other roles in the schemas are represented by typed variables, and the event variables can be related through partial temporal ordering and causal relations. To match natural language stories with existing schemas, we first parse the stories into an underspecified variant of the logical form used by the schemas, which is suitable for most concrete stories. We include a walkthrough of matching a children’s story to these schemas and generating inferences from these matches.</abstract>
      <url>W19-1102</url>
    </paper>
    <paper id="3">
      <title>Questions in Dependent Type Semantics</title>
      <author><first>Kazuki</first><last>Watanabe</last></author>
      <author><first>Koji</first><last>Mineshima</last></author>
      <author><first>Daisuke</first><last>Bekki</last></author>
      <pages>23–33</pages>
      <abstract>Dependent Type Semantics (DTS; Bekki and Mineshima, 2017) is a proof-theoretic compositional dynamic semantics based on Dependent Type Theory. The semantic representations for declarative sentences in DTS are types, based on the propositions-as-types paradigm. While type-theoretic semantics for natural language based on dependent type theory has been developed by many authors, how to assign semantic representations to interrogative sentences has been a non-trivial problem. In this study, we show how to provide the semantics of interrogative sentences in DTS. The basic idea is to assign the same type to both declarative sentences and interrogative sentences, partly building on the recent proposal in Inquisitive Semantics. We use Combinatory Categorial Grammar (CCG) as a syntactic component of DTS and implement our compositional semantics for interrogative sentences using ccg2lambda, a semantic parsing platform based on CCG. Based on the idea that the relationship between questions and answers can be formulated as the task of Recognizing Textual Entailment (RTE), we implement our inference system using proof assistant Coq and show that our system can deal with a wide range of question-answer relationships discussed in the formal semantics literature, including those with polar questions, alternative questions, and wh-questions.</abstract>
      <url>W19-1103</url>
    </paper>
    <paper id="4">
      <title>Monads for hyperintensionality? A situation semantics for hyperintensional side effects</title>
      <author><first>Luke</first><last>Burke</last></author>
      <pages>34–43</pages>
      <abstract>We outline a hyperintensional situation semantics in which hyperintensionality is modelled as a ‘side effect’, as this term has been understood in natural language semantics and in functional programming. We use monads from category theory in order to ‘upgrade’ an ordinary intensional semantics to a possible hyperintensional counterpart.</abstract>
      <url>W19-1104</url>
    </paper>
  </volume>
  <volume id="12">
    <meta>
      <booktitle>Proceedings of the <fixed-case>IWCS</fixed-case> Shared Task on Semantic Parsing</booktitle>
      <url>W19-12</url>
      <editor><first>Lasha</first><last>Abzianidze</last></editor>
      <editor><first>Rik</first><last>van Noord</last></editor>
      <editor><first>Hessel</first><last>Haagsma</last></editor>
      <editor><first>Johan</first><last>Bos</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Gothenburg, Sweden</address>
      <month>23 May</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-1200</url>
    </frontmatter>
    <paper id="1">
      <title>The First Shared Task on Discourse Representation Structure Parsing</title>
      <author><first>Lasha</first><last>Abzianidze</last></author>
      <author><first>Rik</first><last>van Noord</last></author>
      <author><first>Hessel</first><last>Haagsma</last></author>
      <author><first>Johan</first><last>Bos</last></author>
      <abstract>The paper presents the IWCS 2019 shared task on semantic parsing where the goal is to produce Discourse Representation Structures (DRSs) for English sentences. DRSs originate from Discourse Representation Theory and represent scoped meaning representations that capture the semantics of negation, modals, quantification, and presupposition triggers. Additionally, concepts and event-participants in DRSs are described with WordNet synsets and the thematic roles from VerbNet. To measure similarity between two DRSs, they are represented in a clausal form, i.e. as a set of tuples. Participant systems were expected to produce DRSs in this clausal form. Taking into account the rich lexical information, explicit scope marking, a high number of shared variables among clauses, and highly-constrained format of valid DRSs, all these makes the DRS parsing a challenging NLP task. The results of the shared task displayed improvements over the existing state-of-the-art parser.</abstract>
      <url>W19-1201</url>
    </paper>
    <paper id="2">
      <title>Transition-based <fixed-case>DRS</fixed-case> Parsing Using Stack-<fixed-case>LSTM</fixed-case>s</title>
      <author><first>Kilian</first><last>Evang</last></author>
      <abstract>We present our submission to the IWCS 2019 shared task on semantic parsing, a transition-based parser that uses explicit word-meaning pairings, but no explicit representation of syntax. Parsing decisions are made based on vector representations of parser states, encoded via stack-LSTMs (Ballesteros et al., 2017), as well as some heuristic rules. Our system reaches 70.88% f-score in the competition.</abstract>
      <url>W19-1202</url>
    </paper>
    <paper id="3">
      <title>Discourse Representation Structure Parsing with Recurrent Neural Networks and the Transformer Model</title>
      <author><first>Jiangming</first><last>Liu</last></author>
      <author><first>Shay B.</first><last>Cohen</last></author>
      <author><first>Mirella</first><last>Lapata</last></author>
      <abstract>We describe the systems we developed for Discourse Representation Structure (DRS) parsing as part of the IWCS-2019 Shared Task of DRS Parsing.1 Our systems are based on sequence-to- sequence modeling. To implement our model, we use the open-source neural machine translation system implemented in PyTorch, OpenNMT-py. We experimented with a variety of encoder-decoder models based on recurrent neural networks and the Transformer model. We conduct experiments on the standard benchmark of the Parallel Meaning Bank (PMB 2.2). Our best system achieves a score of 84.8% F1 in the DRS parsing shared task.</abstract>
      <url>W19-1203</url>
    </paper>
    <paper id="4">
      <title>Neural Boxer at the <fixed-case>IWCS</fixed-case> Shared Task on <fixed-case>DRS</fixed-case> Parsing</title>
      <author><first>Rik</first><last>van Noord</last></author>
      <abstract>This paper describes our participation in the shared task of Discourse Representation Structure parsing. It follows the work of Van Noord et al. (2018), who employed a neural sequence-to-sequence model to produce DRSs, also exploiting linguistic information with multiple encoders. We provide a detailed look in the performance of this model and show that (i) the benefit of the linguistic features is evident across a number of experiments which vary the amount of training data and (ii) the model can be improved by applying a number of postprocessing methods to fix ill-formed output. Our model ended up in second place in the competition, with an F-score of 84.5.</abstract>
      <url>W19-1204</url>
    </paper>
  </volume>
  <volume id="13">
    <meta>
      <booktitle>Proceedings of the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</booktitle>
      <url>W19-13</url>
      <editor><first>Alexandra</first><last>Balahur</last></editor>
      <editor><first>Roman</first><last>Klinger</last></editor>
      <editor><first>Veronique</first><last>Hoste</last></editor>
      <editor><first>Carlo</first><last>Strapparava</last></editor>
      <editor><first>Orphee De</first><last>Clercq</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, USA</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-1300</url>
    </frontmatter>
    <paper id="1">
      <title>Stance Detection in Code-Mixed <fixed-case>H</fixed-case>indi-<fixed-case>E</fixed-case>nglish Social Media Data using Multi-Task Learning</title>
      <author><first>Sushmitha Reddy</first><last>Sane</last></author>
      <author><first>Suraj</first><last>Tripathi</last></author>
      <author><first>Koushik Reddy</first><last>Sane</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>1–5</pages>
      <abstract>Social media sites like Facebook, Twitter, and other microblogging forums have emerged as a platform for people to express their opinions and views on different issues and events. It is often observed that people tend to take a stance; in favor, against or neutral towards a particular topic. The task of assessing the stance taken by the individual became significantly important with the emergence in the usage of online social platforms. Automatic stance detection system understands the user’s stance by analyzing the standalone texts against a target entity. Due to the limited contextual information a single sentence provides, it is challenging to solve this task effectively. In this paper, we introduce a Multi-Task Learning (MTL) based deep neural network architecture for automatically detecting stance present in the code-mixed corpus. We apply our approach on Hindi-English code-mixed corpus against the target entity - “Demonetisation.” Our best model achieved the result with a stance prediction accuracy of 63.2% which is a 4.5% overall accuracy improvement compared to the current supervised classification systems developed using the benchmark dataset for code-mixed data stance detection.</abstract>
      <url>W19-1301</url>
    </paper>
    <paper id="2">
      <title>A Soft Label Strategy for Target-Level Sentiment Classification</title>
      <author><first>Da</first><last>Yin</last></author>
      <author><first>Xiao</first><last>Liu</last></author>
      <author><first>Xiuyu</first><last>Wu</last></author>
      <author><first>Baobao</first><last>Chang</last></author>
      <pages>6–15</pages>
      <abstract>In this paper, we propose a soft label approach to target-level sentiment classification task, in which a history-based soft labeling model is proposed to measure the possibility of a context word as an opinion word. We also apply a convolution layer to extract local active features, and introduce positional weights to take relative distance information into consideration. In addition, we obtain more informative target representation by training with context tokens together to make deeper interaction between target and context tokens. We conduct experiments on SemEval 2014 datasets and the experimental results show that our approach significantly outperforms previous models and gives state-of-the-art results on these datasets.</abstract>
      <url>W19-1302</url>
    </paper>
    <paper id="3">
      <title>Online abuse detection: the value of preprocessing and neural attention models</title>
      <author><first>Dhruv</first><last>Kumar</last></author>
      <author><first>Robin</first><last>Cohen</last></author>
      <author><first>Lukasz</first><last>Golab</last></author>
      <pages>16–24</pages>
      <abstract>We propose an attention-based neural network approach to detect abusive speech in online social networks. Our approach enables more effective modeling of context and the semantic relationships between words. We also empirically evaluate the value of text pre-processing techniques in addressing the challenge of out-of-vocabulary words in toxic content. Finally, we conduct extensive experiments on the Wikipedia Talk page datasets, showing improved predictive power over the previous state-of-the-art.</abstract>
      <url>W19-1303</url>
    </paper>
    <paper id="4">
      <title>Exploring Fine-Tuned Embeddings that Model Intensifiers for Emotion Analysis</title>
      <author><first>Laura Ana Maria</first><last>Bostan</last></author>
      <author><first>Roman</first><last>Klinger</last></author>
      <pages>25–34</pages>
      <abstract>Adjective phrases like “a little bit surprised”, “completely shocked”, or “not stunned at all” are not handled properly by current state-ofthe- art emotion classification and intensity prediction systems. Based on this finding, we analyze differences between embeddings used by these systems in regard to their capability of handling such cases and argue that intensifiers in context of emotion words need special treatment, as is established for sentiment polarity classification, but not for more fine-grained emotion prediction. To resolve this issue, we analyze different aspects of a post-processing pipeline which enriches the word representations of such phrases. This includes expansion of semantic spaces at the phrase level and sub-word level followed by retrofitting to emotion lexicons. We evaluate the impact of these steps with ‘A La Carte and Bag-of-Substrings extensions based on pretrained GloVe,Word2vec, and fastText embeddings against a crowd-sourced corpus of intensity annotations for tweets containing our focus phrases. We show that the fastText-based models do not gain from handling these specific phrases under inspection. For Word2vec embeddings, we show that our post-processing pipeline improves the results by up to 8% on a novel dataset densly populated with intensifiers while it does not decrease the performance on the established EmoInt dataset.</abstract>
      <url>W19-1304</url>
    </paper>
    <paper id="5">
      <title>Enhancing the Measurement of Social Effects by Capturing Morality</title>
      <author><first>Rezvaneh</first><last>Rezapour</last></author>
      <author><first>Saumil H.</first><last>Shah</last></author>
      <author><first>Jana</first><last>Diesner</last></author>
      <pages>35–45</pages>
      <abstract>We investigate the relationship between basic principles of human morality and the expression of opinions in user-generated text data. We assume that people’s backgrounds, culture, and values are associated with their perceptions and expressions of everyday topics, and that people’s language use reflects these perceptions. While personal values and social effects are abstract and complex concepts, they have practical implications and are relevant for a wide range of NLP applications. To extract human values (in this paper, morality) and measure social effects (morality and stance), we empirically evaluate the usage of a morality lexicon that we expanded via a quality controlled, human in the loop process. As a result, we enhanced the Moral Foundations Dictionary in size (from 324 to 4,636 syntactically disambiguated entries) and scope. We used both lexica for feature-based and deep learning classification (SVM, RF, and LSTM) to test their usefulness for measuring social effects. We find that the enhancement of the original lexicon led to measurable improvements in prediction accuracy for the selected NLP tasks.</abstract>
      <url>W19-1305</url>
    </paper>
    <paper id="6">
      <title>Using Structured Representation and Data: A Hybrid Model for Negation and Sentiment in Customer Service Conversations</title>
      <author><first>Amita</first><last>Misra</last></author>
      <author><first>Mansurul</first><last>Bhuiyan</last></author>
      <author><first>Jalal</first><last>Mahmud</last></author>
      <author><first>Saurabh</first><last>Tripathy</last></author>
      <pages>46–56</pages>
      <abstract>Twitter customer service interactions have recently emerged as an effective platform to respond and engage with customers. In this work, we explore the role of ”negation” in customer service interactions, particularly applied to sentiment analysis. We define rules to identify true negation cues and scope more suited to conversational data than existing general review data. Using semantic knowledge and syntactic structure from constituency parse trees, we propose an algorithm for scope detection that performs comparable to state of the art BiLSTM. We further investigate the results of negation scope detection for the sentiment prediction task on customer service conversation data using both a traditional SVM and a Neural Network. We propose an antonym dictionary based method for negation applied to a combination CNN-LSTM for sentiment analysis. Experimental results show that the antonym-based method outperforms the previous lexicon-based and Neural Network methods.</abstract>
      <url>W19-1306</url>
    </paper>
    <paper id="7">
      <title>Deep Learning Techniques for Humor Detection in <fixed-case>H</fixed-case>indi-<fixed-case>E</fixed-case>nglish Code-Mixed Tweets</title>
      <author><first>Sushmitha Reddy</first><last>Sane</last></author>
      <author><first>Suraj</first><last>Tripathi</last></author>
      <author><first>Koushik Reddy</first><last>Sane</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>57–61</pages>
      <abstract>We propose bilingual word embeddings based on word2vec and fastText models (CBOW and Skip-gram) to address the problem of Humor detection in Hindi-English code-mixed tweets in combination with deep learning architectures. We focus on deep learning approaches which are not widely used on code-mixed data and analyzed their performance by experimenting with three different neural network models. We propose convolution neural network (CNN) and bidirectional long-short term memory (biLSTM) (with and without Attention) models which take the generated bilingual embeddings as input. We make use of Twitter data to create bilingual word embeddings. All our proposed architectures outperform the state-of-the-art results, and Attention-based bidirectional LSTM model achieved an accuracy of 73.6% which is an increment of more than 4% compared to the current state-of-the-art results.</abstract>
      <url>W19-1307</url>
    </paper>
    <paper id="8">
      <title>How do we feel when a robot dies? Emotions expressed on Twitter before and after hitch<fixed-case>BOT</fixed-case>’s destruction</title>
      <author><first>Kathleen C.</first><last>Fraser</last></author>
      <author><first>Frauke</first><last>Zeller</last></author>
      <author><first>David Harris</first><last>Smith</last></author>
      <author><first>Saif</first><last>Mohammad</last></author>
      <author><first>Frank</first><last>Rudzicz</last></author>
      <pages>62–71</pages>
      <abstract>In 2014, a chatty but immobile robot called hitchBOT set out to hitchhike across Canada. It similarly made its way across Germany and the Netherlands, and had begun a trip across the USA when it was destroyed by vandals. In this work, we analyze the emotions and sentiments associated with words in tweets posted before and after hitchBOT’s destruction to answer two questions: Were there any differences in the emotions expressed across the different countries visited by hitchBOT? And how did the public react to the demise of hitchBOT? Our analyses indicate that while there were few cross-cultural differences in sentiment towards hitchBOT, there was a significant negative emotional reaction to its destruction, suggesting that people had formed an emotional connection with hitchBOT and perceived its destruction as morally wrong. We discuss potential implications of anthropomorphism and emotional attachment to robots from the perspective of robot ethics.</abstract>
      <url>W19-1308</url>
    </paper>
    <paper id="9">
      <title>“When Numbers Matter!”: Detecting Sarcasm in Numerical Portions of Text</title>
      <author><first>Abhijeet</first><last>Dubey</last></author>
      <author><first>Lakshya</first><last>Kumar</last></author>
      <author><first>Arpan</first><last>Somani</last></author>
      <author><first>Aditya</first><last>Joshi</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>72–80</pages>
      <abstract>Research in sarcasm detection spans almost a decade. However a particular form of sarcasm remains unexplored: sarcasm expressed through numbers, which we estimate, forms about 11% of the sarcastic tweets in our dataset. The sentence ‘Love waking up at 3 am’ is sarcastic because of the number. In this paper, we focus on detecting sarcasm in tweets arising out of numbers. Initially, to get an insight into the problem, we implement a rule-based and a statistical machine learning-based (ML) classifier. The rule-based classifier conveys the crux of the numerical sarcasm problem, namely, incongruity arising out of numbers. The statistical ML classifier uncovers the indicators i.e., features of such sarcasm. The actual system in place, however, are two deep learning (DL) models, CNN and attention network that obtains an F-score of 0.93 and 0.91 on our dataset of tweets containing numbers. To the best of our knowledge, this is the first line of research investigating the phenomenon of sarcasm arising out of numbers, culminating in a detector thereof.</abstract>
      <url>W19-1309</url>
    </paper>
    <paper id="10">
      <title>Cross-lingual Subjectivity Detection for Resource Lean Languages</title>
      <author><first>Ida</first><last>Amini</last></author>
      <author><first>Samane</first><last>Karimi</last></author>
      <author><first>Azadeh</first><last>Shakery</last></author>
      <pages>81–90</pages>
      <abstract>Wide and universal changes in the web content due to the growth of web 2 applications increase the importance of user-generated content on the web. Therefore, the related research areas such as sentiment analysis, opinion mining and subjectivity detection receives much attention from the research community. Due to the diverse languages that web-users use to express their opinions and sentiments, research areas like subjectivity detection should present methods which are practicable on all languages. An important prerequisite to effectively achieve this aim is considering the limitations in resource-lean languages. In this paper, cross-lingual subjectivity detection on resource lean languages is investigated using two different approaches: a language-model based and a learning-to-rank approach. Experimental results show the impact of different factors on the performance of subjectivity detection methods using English resources to detect the subjectivity score of Persian documents. The experiments demonstrate that the proposed learning-to-rank method outperforms the baseline method in ranking documents based on their subjectivity degree.</abstract>
      <url>W19-1310</url>
    </paper>
    <paper id="11">
      <title>Analyzing Incorporation of Emotion in Emoji Prediction</title>
      <author><first>Shirley Anugrah</first><last>Hayati</last></author>
      <author><first>Aldrian Obaja</first><last>Muis</last></author>
      <pages>91–99</pages>
      <abstract>In this work, we investigate the impact of incorporating emotion classes on the task of predicting emojis from Twitter texts. More specifically, we first show that there is a correlation between the emotion expressed in the text and the emoji choice of Twitter users. Based on this insight we propose a few simple methods to incorporate emotion information in traditional classifiers. Through automatic metrics, human evaluation, and error analysis, we show that the improvement obtained by incorporating emotion is significant and correlate better with human preferences compared to the baseline models. Through the human ratings that we obtained, we also argue for preference metric to better evaluate the usefulness of an emoji prediction system.</abstract>
      <url>W19-1311</url>
    </paper>
  </volume>
  <volume id="14">
    <meta>
      <booktitle>Proceedings of the Sixth Workshop on <fixed-case>NLP</fixed-case> for Similar Languages, Varieties and Dialects</booktitle>
      <url>W19-14</url>
      <editor><first>Marcos</first><last>Zampieri</last></editor>
      <editor><first>Preslav</first><last>Nakov</last></editor>
      <editor><first>Shervin</first><last>Malmasi</last></editor>
      <editor><first>Nikola</first><last>Ljubešić</last></editor>
      <editor><first>Jörg</first><last>Tiedemann</last></editor>
      <editor><first>Ahmed</first><last>Ali</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>TOBEFILLED-Ann Arbor, Michigan</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-1400</url>
    </frontmatter>
    <paper id="1">
      <title>A Report on the Third <fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial Evaluation Campaign</title>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <author><first>Yves</first><last>Scherrer</last></author>
      <author><first>Tanja</first><last>Samardžić</last></author>
      <author><first>Francis</first><last>Tyers</last></author>
      <author><first>Miikka</first><last>Silfverberg</last></author>
      <author><first>Natalia</first><last>Klyueva</last></author>
      <author><first>Tung-Le</first><last>Pan</last></author>
      <author><first>Chu-Ren</first><last>Huang</last></author>
      <author><first>Radu Tudor</first><last>Ionescu</last></author>
      <author><first>Andrei M.</first><last>Butnaru</last></author>
      <author><first>Tommi</first><last>Jauhiainen</last></author>
      <pages>1–16</pages>
      <abstract>In this paper, we present the findings of the Third VarDial Evaluation Campaign organized as part of the sixth edition of the workshop on Natural Language Processing (NLP) for Similar Languages, Varieties and Dialects (VarDial), co-located with NAACL 2019. This year, the campaign included five shared tasks, including one task re-run – German Dialect Identification (GDI) – and four new tasks – Cross-lingual Morphological Analysis (CMA), Discriminating between Mainland and Taiwan variation of Mandarin Chinese (DMT), Moldavian vs. Romanian Cross-dialect Topic identification (MRC), and Cuneiform Language Identification (CLI). A total of 22 teams submitted runs across the five shared tasks. After the end of the competition, we received 14 system description papers, which are published in the VarDial workshop proceedings and referred to in this report.</abstract>
      <url>W19-1401</url>
    </paper>
    <paper id="2">
      <title>Improving Cuneiform Language Identification with <fixed-case>BERT</fixed-case></title>
      <author><first>Gabriel</first><last>Bernier-Colborne</last></author>
      <author><first>Cyril</first><last>Goutte</last></author>
      <author><first>Serge</first><last>Léger</last></author>
      <pages>17–25</pages>
      <abstract>We describe the systems developed by the National Research Council Canada for the Cuneiform Language Identification (CLI) shared task at the 2019 VarDial evaluation campaign. We compare a state-of-the-art baseline relying on character n-grams and a traditional statistical classifier, a voting ensemble of classifiers, and a deep learning approach using a Transformer network. We describe how these systems were trained, and analyze the impact of some preprocessing and model estimation decisions. The deep neural network achieved 77% accuracy on the test data, which turned out to be the best performance at the CLI evaluation, establishing a new state-of-the-art for cuneiform language identification.</abstract>
      <url>W19-1402</url>
    </paper>
    <paper id="3">
      <title>Joint Approach to Deromanization of Code-mixed Texts</title>
      <author><first>Rashed Rubby</first><last>Riyadh</last></author>
      <author><first>Grzegorz</first><last>Kondrak</last></author>
      <pages>26–34</pages>
      <abstract>The conversion of romanized texts back to the native scripts is a challenging task because of the inconsistent romanization conventions and non-standard language use. This problem is compounded by code-mixing, i.e., using words from more than one language within the same discourse. In this paper, we propose a novel approach for handling these two problems together in a single system. Our approach combines three components: language identification, back-transliteration, and sequence prediction. The results of our experiments on Bengali and Hindi datasets establish the state of the art for the task of deromanization of code-mixed texts.</abstract>
      <url>W19-1403</url>
    </paper>
    <paper id="4">
      <title>Char-<fixed-case>RNN</fixed-case> for Word Stress Detection in East <fixed-case>S</fixed-case>lavic Languages</title>
      <author><first>Ekaterina</first><last>Chernyak</last></author>
      <author><first>Maria</first><last>Ponomareva</last></author>
      <author><first>Kirill</first><last>Milintsevich</last></author>
      <pages>35–41</pages>
      <abstract>We explore how well a sequence labeling approach, namely, recurrent neural network, is suited for the task of resource-poor and POS tagging free word stress detection in the Russian, Ukranian, Belarusian languages. We present new datasets, annotated with the word stress, for the three languages and compare several RNN models trained on three languages and explore possible applications of the transfer learning for the task. We show that it is possible to train a model in a cross-lingual setting and that using additional languages improves the quality of the results.</abstract>
      <url>W19-1404</url>
    </paper>
    <paper id="5">
      <title>Modeling Global Syntactic Variation in <fixed-case>E</fixed-case>nglish Using Dialect Classification</title>
      <author><first>Jonathan</first><last>Dunn</last></author>
      <pages>42–53</pages>
      <abstract>This paper evaluates global-scale dialect identification for 14 national varieties of English on both web-crawled data and Twitter data. The paper makes three main contributions: (i) introducing data-driven language mapping as a method for selecting the inventory of national varieties to include in the task; (ii) producing a large and dynamic set of syntactic features using grammar induction rather than focusing on a few hand-selected features such as function words; and (iii) comparing models across both web corpora and social media corpora in order to measure the robustness of syntactic variation across registers.</abstract>
      <url>W19-1405</url>
      <software>W19-1405.Software.zip</software>
    </paper>
    <paper id="6">
      <title>Language Discrimination and Transfer Learning for Similar Languages: Experiments with Feature Combinations and Adaptation</title>
      <author><first>Nianheng</first><last>Wu</last></author>
      <author><first>Eric</first><last>DeMattos</last></author>
      <author><first>Kwok Him</first><last>So</last></author>
      <author><first>Pin-zhen</first><last>Chen</last></author>
      <author><first>Çağrı</first><last>Çöltekin</last></author>
      <pages>54–63</pages>
      <abstract>This paper describes the work done by team tearsofjoy participating in the VarDial 2019 Evaluation Campaign. We developed two systems based on Support Vector Machines: SVM with a flat combination of features and SVM ensembles. We participated in all language/dialect identification tasks, as well as the Moldavian vs. Romanian cross-dialect topic identification (MRC) task. Our team achieved first place in German Dialect identification (GDI) and MRC subtasks 2 and 3, second place in the simplified variant of Discriminating between Mainland and Taiwan variation of Mandarin Chinese (DMT) as well as Cuneiform Language Identification (CLI), and third and fifth place in DMT traditional and MRC subtask 1 respectively. In most cases, the SVM with a flat combination of features performed better than SVM ensembles. Besides describing the systems and the results obtained by them, we provide a tentative comparison between the feature combination methods, and present additional experiments with a method of adaptation to the test set, which may indicate potential pitfalls with some of the data sets.</abstract>
      <url>W19-1406</url>
    </paper>
    <paper id="7">
      <title>Variation between Different Discourse Types: Literate vs. Oral</title>
      <author><first>Katrin</first><last>Ortmann</last></author>
      <author><first>Stefanie</first><last>Dipper</last></author>
      <pages>64–79</pages>
      <abstract>This paper deals with the automatic identification of literate and oral discourse in German texts. A range of linguistic features is selected and their role in distinguishing between literate- and oral-oriented registers is investigated, using a decision-tree classifier. It turns out that all of the investigated features are related in some way to oral conceptuality. Especially simple measures of complexity (average sentence and word length) are prominent indicators of oral and literate discourse. In addition, features of reference and deixis (realized by different types of pronouns) also prove to be very useful in determining the degree of orality of different registers.</abstract>
      <url>W19-1407</url>
    </paper>
    <paper id="8">
      <title>Neural Machine Translation between <fixed-case>M</fixed-case>yanmar (<fixed-case>B</fixed-case>urmese) and Rakhine (Arakanese)</title>
      <author><first>Thazin</first><last>Myint Oo</last></author>
      <author><first>Ye</first><last>Kyaw Thu</last></author>
      <author><first>Khin</first><last>Mar Soe</last></author>
      <pages>80–88</pages>
      <abstract>This work explores neural machine translation between Myanmar (Burmese) and Rakhine (Arakanese). Rakhine is a language closely related to Myanmar, often considered a dialect. We implemented three prominent neural machine translation (NMT) systems: recurrent neural networks (RNN), transformer, and convolutional neural networks (CNN). The systems were evaluated on a Myanmar-Rakhine parallel text corpus developed by us. In addition, two types of word segmentation schemes for word embeddings were studied: Word-BPE and Syllable-BPE segmentation. Our experimental results clearly show that the highest quality NMT and statistical machine translation (SMT) performances are obtained with Syllable-BPE segmentation for both types of translations. If we focus on NMT, we find that the transformer with Word-BPE segmentation outperforms CNN and RNN for both Myanmar-Rakhine and Rakhine-Myanmar translation. However, CNN with Syllable-BPE segmentation obtains a higher score than the RNN and transformer.</abstract>
      <url>W19-1408</url>
    </paper>
    <paper id="9">
      <title>Language and Dialect Identification of Cuneiform Texts</title>
      <author><first>Tommi</first><last>Jauhiainen</last></author>
      <author><first>Heidi</first><last>Jauhiainen</last></author>
      <author><first>Tero</first><last>Alstola</last></author>
      <author><first>Krister</first><last>Lindén</last></author>
      <pages>89–98</pages>
      <abstract>This article introduces a corpus of cuneiform texts from which the dataset for the use of the Cuneiform Language Identification (CLI) 2019 shared task was derived as well as some preliminary language identification experiments conducted using that corpus. We also describe the CLI dataset and how it was derived from the corpus. In addition, we provide some baseline language identification results using the CLI dataset. To the best of our knowledge, the experiments detailed here represent the first time that automatic language identification methods have been used on cuneiform data.</abstract>
      <url>W19-1409</url>
    </paper>
    <paper id="10">
      <title>Leveraging Pretrained Word Embeddings for Part-of-Speech Tagging of Code Switching Data</title>
      <author><first>Fahad</first><last>AlGhamdi</last></author>
      <author><first>Mona</first><last>Diab</last></author>
      <pages>99–109</pages>
      <abstract>Linguistic Code Switching (CS) is a phenomenon that occurs when multilingual speakers alternate between two or more languages/dialects within a single conversation. Processing CS data is especially challenging in intra-sentential data given state-of-the-art monolingual NLP technologies since such technologies are geared toward the processing of one language at a time. In this paper, we address the problem of Part-of-Speech tagging (POS) in the context of linguistic code switching (CS). We explore leveraging multiple neural network architectures to measure the impact of different pre-trained embeddings methods on POS tagging CS data. We investigate the landscape in four CS language pairs, Spanish-English, Hindi-English, Modern Standard Arabic- Egyptian Arabic dialect (MSA-EGY), and Modern Standard Arabic- Levantine Arabic dialect (MSA-LEV). Our results show that multilingual embedding (e.g., MSA-EGY and MSA-LEV) helps closely related languages (EGY/LEV) but adds noise to the languages that are distant (SPA/HIN). Finally, we show that our proposed models outperform state-of-the-art CS taggers for MSA-EGY language pair.</abstract>
      <url>W19-1410</url>
    </paper>
    <paper id="11">
      <title>Toward a deep dialectological representation of <fixed-case>I</fixed-case>ndo-<fixed-case>A</fixed-case>ryan</title>
      <author><first>Chundra</first><last>Cathcart</last></author>
      <pages>110–119</pages>
      <abstract>This paper presents a new approach to disentangling inter-dialectal and intra-dialectal relationships within one such group, the Indo-Aryan subgroup of Indo-European. We draw upon admixture models and deep generative models to tease apart historic language contact and language-specific behavior in the overall patterns of sound change displayed by Indo-Aryan languages. We show that a “deep” model of Indo-Aryan dialectology sheds some light on questions regarding inter-relationships among the Indo-Aryan languages, and performs better than a “shallow” model in terms of certain qualities of the posterior distribution (e.g., entropy of posterior distributions), and outline future pathways for model development.</abstract>
      <url>W19-1411</url>
    </paper>
    <paper id="12">
      <title>Naive <fixed-case>B</fixed-case>ayes and <fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case> Ensemble for Discriminating between Mainland and Taiwan Variation of <fixed-case>M</fixed-case>andarin <fixed-case>C</fixed-case>hinese</title>
      <author><first>Li</first><last>Yang</last></author>
      <author><first>Yang</first><last>Xiang</last></author>
      <pages>120–127</pages>
      <abstract>Automatic dialect identification is a more challengingctask than language identification, as it requires the ability to discriminate between varieties of one language. In this paper, we propose an ensemble based system, which combines traditional machine learning models trained on bag of n-gram fetures, with deep learning models trained on word embeddings, to solve the Discriminating between Mainland and Taiwan Variation of Mandarin Chinese (DMT) shared task at VarDial 2019. Our experiments show that a character bigram-trigram combination based Naive Bayes is a very strong model for identifying varieties of Mandarin Chinense. Through further ensemble of Navie Bayes and BiLSTM, our system (team: itsalexyang) achived an macro-averaged F1 score of 0.8530 and 0.8687 in two tracks.</abstract>
      <url>W19-1412</url>
    </paper>
    <paper id="13">
      <title><fixed-case>BAM</fixed-case>: A combination of deep and shallow models for <fixed-case>G</fixed-case>erman Dialect Identification.</title>
      <author><first>Andrei M.</first><last>Butnaru</last></author>
      <pages>128–137</pages>
      <abstract>*This is a submission for the Third VarDial Evaluation Campaign* In this paper, we present a machine learning approach for the German Dialect Identification (GDI) Closed Shared Task of the DSL 2019 Challenge. The proposed approach combines deep and shallow models, by applying a voting scheme on the outputs resulted from a Character-level Convolutional Neural Networks (Char-CNN), a Long Short-Term Memory (LSTM) network, and a model based on String Kernels. The first model used is the Char-CNN model that merges multiple convolutions computed with kernels of different sizes. The second model is the LSTM network which applies a global max pooling over the returned sequences over time. Both models pass the activation maps to two fully-connected layers. The final model is based on String Kernels, computed on character p-grams extracted from speech transcripts. The model combines two blended kernel functions, one is the presence bits kernel, and the other is the intersection kernel. The empirical results obtained in the shared task prove that the approach can achieve good results. The system proposed in this paper obtained the fourth place with a macro-F1 score of 62.55%</abstract>
      <url>W19-1413</url>
    </paper>
    <paper id="14">
      <title>The <fixed-case>R</fixed-case>2<fixed-case>I</fixed-case>_<fixed-case>LIS</fixed-case> Team Proposes Majority Vote for <fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial’s <fixed-case>MRC</fixed-case> Task</title>
      <author><first>Adrian-Gabriel</first><last>Chifu</last></author>
      <pages>138–143</pages>
      <abstract>This article presents the model that generated the runs submitted by the R2I_LIS team to the VarDial2019 evaluation campaign, more particularly, to the binary classification by dialect sub-task of the Moldavian vs. Romanian Cross-dialect Topic identification (MRC) task. The team proposed a majority vote-based model, between five supervised machine learning models, trained on forty manually-crafted features. One of the three submitted runs was ranked second at the binary classification sub-task, with a performance of 0.7963, in terms of macro-F1 measure. The other two runs were ranked third and fourth, respectively.</abstract>
      <url>W19-1414</url>
    </paper>
    <paper id="15">
      <title>Initial Experiments In Cross-Lingual Morphological Analysis Using Morpheme Segmentation</title>
      <author><first>Vladislav</first><last>Mikhailov</last></author>
      <author><first>Lorenzo</first><last>Tosi</last></author>
      <author><first>Anastasia</first><last>Khorosheva</last></author>
      <author><first>Oleg</first><last>Serikov</last></author>
      <pages>144–152</pages>
      <abstract>The paper describes initial experiments in data-driven cross-lingual morphological analysis of open-category words using a combination of unsupervised morpheme segmentation, annotation projection and an LSTM encoder-decoder model with attention. Our algorithm provides lemmatisation and morphological analysis generation for previously unseen low-resource language surface forms with only annotated data on the related languages given. Despite the inherently lossy annotation projection, we achieved the best lemmatisation F1-score in the VarDial 2019 Shared Task on Cross-Lingual Morphological Analysis for both Karachay-Balkar (Turkic languages, agglutinative morphology) and Sardinian (Romance languages, fusional morphology).</abstract>
      <url>W19-1415</url>
    </paper>
    <paper id="16">
      <title>Neural and Linear Pipeline Approaches to Cross-lingual Morphological Analysis</title>
      <author><first>Çağrı</first><last>Çöltekin</last></author>
      <author><first>Jeremy</first><last>Barnes</last></author>
      <pages>153–164</pages>
      <abstract>This paper describes Tübingen-Oslo team’s participation in the cross-lingual morphological analysis task in the VarDial 2019 evaluation campaign. We participated in the shared task with a standard neural network model. Our model achieved analysis F1-scores of 31.48 and 23.67 on test languages Karachay-Balkar (Turkic) and Sardinian (Romance) respectively. The scores are comparable to the scores obtained by the other participants in both language families, and the analysis score on the Romance data set was also the best result obtained in the shared task. Besides describing the system used in our shared task participation, we describe another, simpler, model based on linear classifiers, and present further analyses using both models. Our analyses, besides revealing some of the difficult cases, also confirm that the usefulness of a source language in this task is highly correlated with the similarity of source and target languages.</abstract>
      <url>W19-1416</url>
    </paper>
    <paper id="17">
      <title>Ensemble Methods to Distinguish Mainland and Taiwan <fixed-case>C</fixed-case>hinese</title>
      <author><first>Hai</first><last>Hu</last></author>
      <author><first>Wen</first><last>Li</last></author>
      <author><first>He</first><last>Zhou</last></author>
      <author><first>Zuoyu</first><last>Tian</last></author>
      <author><first>Yiwen</first><last>Zhang</last></author>
      <author><first>Liang</first><last>Zou</last></author>
      <pages>165–171</pages>
      <abstract>This paper describes the IUCL system at VarDial 2019 evaluation campaign for the task of discriminating between Mainland and Taiwan variation of mandarin Chinese. We first build several base classifiers, including a Naive Bayes classifier with word n-gram as features, SVMs with both character and syntactic features, and neural networks with pre-trained character/word embeddings. Then we adopt ensemble methods to combine output from base classifiers to make final predictions. Our ensemble models achieve the highest F1 score (0.893) in simplified Chinese track and the second highest (0.901) in traditional Chinese track. Our results demonstrate the effectiveness and robustness of the ensemble methods.</abstract>
      <url>W19-1417</url>
    </paper>
    <paper id="18">
      <title><fixed-case>SC</fixed-case>-<fixed-case>UPB</fixed-case> at the <fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial 2019 Evaluation Campaign: Moldavian vs. <fixed-case>R</fixed-case>omanian Cross-Dialect Topic Identification</title>
      <author><first>Cristian</first><last>Onose</last></author>
      <author><first>Dumitru-Clementin</first><last>Cercel</last></author>
      <author><first>Stefan</first><last>Trausan-Matu</last></author>
      <pages>172–177</pages>
      <abstract>This paper describes our models for the Moldavian vs. Romanian Cross-Topic Identification (MRC) evaluation campaign, part of the VarDial 2019 workshop. We focus on the three subtasks for MRC: binary classification between the Moldavian (MD) and the Romanian (RO) dialects and two cross-dialect multi-class classification between six news topics, MD to RO and RO to MD. We propose several deep learning models based on long short-term memory cells, Bidirectional Gated Recurrent Unit (BiGRU) and Hierarchical Attention Networks (HAN). We also employ three word embedding models to represent the text as a low dimensional vector. Our official submission includes two runs of the BiGRU and HAN models for each of the three subtasks. The best submitted model obtained the following macro-averaged F1 scores: 0.708 for subtask 1, 0.481 for subtask 2 and 0.480 for the last one. Due to a read error caused by the quoting behaviour over the test file, our final submissions contained a smaller number of items than expected. More than 50% of the submission files were corrupted. Thus, we also present the results obtained with the corrected labels for which the HAN model achieves the following results: 0.930 for subtask 1, 0.590 for subtask 2 and 0.687 for the third one.</abstract>
      <url>W19-1418</url>
    </paper>
    <paper id="19">
      <title>Discriminating between <fixed-case>M</fixed-case>andarin <fixed-case>C</fixed-case>hinese and Swiss-<fixed-case>G</fixed-case>erman varieties using adaptive language models</title>
      <author><first>Tommi</first><last>Jauhiainen</last></author>
      <author><first>Krister</first><last>Lindén</last></author>
      <author><first>Heidi</first><last>Jauhiainen</last></author>
      <pages>178–187</pages>
      <abstract>This paper describes the language identification systems used by the SUKI team in the Discriminating between the Mainland and Taiwan variation of Mandarin Chinese (DMT) and the German Dialect Identification (GDI) shared tasks which were held as part of the third VarDial Evaluation Campaign. The DMT shared task included two separate tracks, one for the simplified Chinese script and one for the traditional Chinese script. We submitted three runs on both tracks of the DMT task as well as on the GDI task. We won the traditional Chinese track using Naive Bayes with language model adaptation, came second on GDI with an adaptive version of the HeLI 2.0 method, and third on the simplified Chinese track using again the adaptive Naive Bayes.</abstract>
      <url>W19-1419</url>
    </paper>
    <paper id="20">
      <title>Investigating Machine Learning Methods for Language and Dialect Identification of Cuneiform Texts</title>
      <author><first>Ehsan</first><last>Doostmohammadi</last></author>
      <author><first>Minoo</first><last>Nassajian</last></author>
      <pages>188–193</pages>
      <abstract>Identification of the languages written using cuneiform symbols is a difficult task due to the lack of resources and the problem of tokenization. The Cuneiform Language Identification task in VarDial 2019 addresses the problem of identifying seven languages and dialects written in cuneiform; Sumerian and six dialects of Akkadian language: Old Babylonian, Middle Babylonian Peripheral, Standard Babylonian, Neo-Babylonian, Late Babylonian, and Neo-Assyrian. This paper describes the approaches taken by SharifCL team to this problem in VarDial 2019. The best result belongs to an ensemble of Support Vector Machines and a naive Bayes classifier, both working on character-level features, with macro-averaged F1-score of 72.10%.</abstract>
      <url>W19-1420</url>
    </paper>
    <paper id="21">
      <title><fixed-case>T</fixed-case>wist<fixed-case>B</fixed-case>ytes - Identification of Cuneiform Languages and <fixed-case>G</fixed-case>erman Dialects at <fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial 2019</title>
      <author><first>Fernando</first><last>Benites</last></author>
      <author><first>Pius</first><last>von Däniken</last></author>
      <author><first>Mark</first><last>Cieliebak</last></author>
      <pages>194–201</pages>
      <abstract>We describe our approaches for the German Dialect Identification (GDI) and the Cuneiform Language Identification (CLI) tasks at the VarDial Evaluation Campaign 2019. The goal was to identify dialects of Swiss German in GDI and Sumerian and Akkadian in CLI. In GDI, the system should distinguish four dialects from the German-speaking part of Switzerland. Our system for GDI achieved third place out of 6 teams, with a macro averaged F-1 of 74.6%. In CLI, the system should distinguish seven languages written in cuneiform script. Our system achieved third place out of 8 teams, with a macro averaged F-1 of 74.7%.</abstract>
      <url>W19-1421</url>
    </paper>
    <paper id="22">
      <title><fixed-case>DT</fixed-case>eam @ <fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial 2019: Ensemble based on skip-gram and triplet loss neural networks for Moldavian vs. <fixed-case>R</fixed-case>omanian cross-dialect topic identification</title>
      <author><first>Diana</first><last>Tudoreanu</last></author>
      <pages>202–208</pages>
      <abstract>This paper presents the solution proposed by DTeam in the VarDial 2019 Evaluation Campaign for the Moldavian vs. Romanian cross-topic identification task. The solution proposed is a Support Vector Machines (SVM) ensemble composed of a two character-level neural networks. The first network is a skip-gram classification model formed of an embedding layer, three convolutional layers and two fully-connected layers. The second network has a similar architecture, but is trained using the triplet loss function.</abstract>
      <url>W19-1422</url>
    </paper>
    <paper id="23">
      <title>Experiments in Cuneiform Language Identification</title>
      <author><first>Gustavo Henrique</first><last>Paetzold</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <pages>209–213</pages>
      <abstract>This paper presents methods to discriminate between languages and dialects written in Cuneiform script, one of the first writing systems in the world. We report the results obtained by the PZ team in the Cuneiform Language Identification (CLI) shared task organized within the scope of the VarDial Evaluation Campaign 2019. The task included two languages, Sumerian and Akkadian. The latter is divided into six dialects: Old Babylonian, Middle Babylonian peripheral, Standard Babylonian, Neo Babylonian, Late Babylonian, and Neo Assyrian. We approach the task using a meta-classifier trained on various SVM models and we show the effectiveness of the system for this task. Our submission achieved 0.738 F1 score in discriminating between the seven languages and dialects and it was ranked fourth in the competition among eight teams.</abstract>
      <url>W19-1423</url>
    </paper>
    <paper id="24">
      <title>Comparing Pipelined and Integrated Approaches to Dialectal <fixed-case>A</fixed-case>rabic Neural Machine Translation</title>
      <author><first>Pamela</first><last>Shapiro</last></author>
      <author><first>Kevin</first><last>Duh</last></author>
      <pages>214–222</pages>
      <abstract>When translating diglossic languages such as Arabic, situations may arise where we would like to translate a text but do not know which dialect it is. A traditional approach to this problem is to design dialect identification systems and dialect-specific machine translation systems. However, under the recent paradigm of neural machine translation, shared multi-dialectal systems have become a natural alternative. Here we explore under which conditions it is beneficial to perform dialect identification for Arabic neural machine translation versus using a general system for all dialects.</abstract>
      <url>W19-1424</url>
    </paper>
    <paper id="25">
      <title>Cross-lingual Annotation Projection Is Effective for Neural Part-of-Speech Tagging</title>
      <author><first>Matthias</first><last>Huck</last></author>
      <author><first>Diana</first><last>Dutka</last></author>
      <author><first>Alexander</first><last>Fraser</last></author>
      <pages>223–233</pages>
      <abstract>We tackle the important task of part-of-speech tagging using a neural model in the zero-resource scenario, where we have no access to gold-standard POS training data. We compare this scenario with the low-resource scenario, where we have access to a small amount of gold-standard POS training data. Our experiments focus on Ukrainian as a representative of under-resourced languages. Russian is highly related to Ukrainian, so we exploit gold-standard Russian POS tags. We consider four techniques to perform Ukrainian POS tagging: zero-shot tagging and cross-lingual annotation projection (for the zero-resource scenario), and compare these with self-training and multilingual learning (for the low-resource scenario). We find that cross-lingual annotation projection works particularly well in the zero-resource scenario.</abstract>
      <url>W19-1425</url>
    </paper>
  </volume>
  <volume id="15">
    <meta>
      <booktitle>Proceedings of the Third Workshop on Structured Prediction for <fixed-case>NLP</fixed-case></booktitle>
      <url>W19-15</url>
      <editor><first>Andre</first><last>Martins</last></editor>
      <editor><first>Andreas</first><last>Vlachos</last></editor>
      <editor><first>Zornitsa</first><last>Kozareva</last></editor>
      <editor><first>Sujith</first><last>Ravi</last></editor>
      <editor><first>Gerasimos</first><last>Lampouras</last></editor>
      <editor><first>Vlad</first><last>Niculae</last></editor>
      <editor><first>Julia</first><last>Kreutzer</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-1500</url>
    </frontmatter>
    <paper id="1">
      <title>Parallelizable Stack Long Short-Term Memory</title>
      <author><first>Shuoyang</first><last>Ding</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <pages>1–6</pages>
      <abstract>Stack Long Short-Term Memory (StackLSTM) is useful for various applications such as parsing and string-to-tree neural machine translation, but it is also known to be notoriously difficult to parallelize for GPU training due to the fact that the computations are dependent on discrete operations. In this paper, we tackle this problem by utilizing state access patterns of StackLSTM to homogenize computations with regard to different discrete operations. Our parsing experiments show that the method scales up almost linearly with increasing batch size, and our parallelized PyTorch implementation trains significantly faster compared to the Dynet C++ implementation.</abstract>
      <url>W19-1501</url>
      <attachment type="presentation">W19-1501.Presentation.pdf</attachment>
    </paper>
    <paper id="2">
      <title>Tracking Discrete and Continuous Entity State for Process Understanding</title>
      <author><first>Aditya</first><last>Gupta</last></author>
      <author><first>Greg</first><last>Durrett</last></author>
      <pages>7–12</pages>
      <abstract>Procedural text, which describes entities and their interactions as they undergo some process, depicts entities in a uniquely nuanced way. First, each entity may have some observable discrete attributes, such as its state or location; modeling these involves imposing global structure and enforcing consistency. Second, an entity may have properties which are not made explicit but can be effectively induced and tracked by neural networks. In this paper, we propose a structured neural architecture that reflects this dual nature of entity evolution. The model tracks each entity recurrently, updating its hidden continuous representation at each step to contain relevant state information. The global discrete state structure is explicitly modelled with a neural CRF over the changing hidden representation of the entity. This CRF can explicitly capture constraints on entity states over time, enforcing that, for example, an entity cannot move to a location after it is destroyed. We evaluate the performance of our proposed model on QA tasks over process paragraphs in the ProPara dataset and find that our model achieves state-of-the-art results.</abstract>
      <url>W19-1502</url>
    </paper>
    <paper id="3">
      <title><fixed-case>SPARSE</fixed-case>: Structured Prediction using Argument-Relative Structured Encoding</title>
      <author><first>Rishi</first><last>Bommasani</last></author>
      <author><first>Arzoo</first><last>Katiyar</last></author>
      <author><first>Claire</first><last>Cardie</last></author>
      <pages>13–17</pages>
      <abstract>We propose structured encoding as a novel approach to learning representations for relations and events in neural structured prediction. Our approach explicitly leverages the structure of available relation and event metadata to generate these representations, which are parameterized by both the attribute structure of the metadata as well as the learned representation of the arguments of the relations and events. We consider affine, biaffine, and recurrent operators for building hierarchical representations and modelling underlying features. We apply our approach to the second-order structured prediction task studied in the 2016/2017 Belief and Sentiment analysis evaluations (BeSt): given a document and its entities, relations, and events (including metadata and mentions), determine the sentiment of each entity towards every relation and event in the document. Without task-specific knowledge sources or domain engineering, we significantly improve over systems and baselines that neglect the available metadata or its hierarchical structure. We observe across-the-board improvements on the BeSt 2016/2017 sentiment analysis task of at least 2.3 (absolute) and 10.6% (relative) F-measure over the previous state-of-the-art.</abstract>
      <url>W19-1503</url>
      <software>W19-1503.Software.zip</software>
      <attachment type="supplementary">W19-1503.Supplementary.pdf</attachment>
    </paper>
    <paper id="4">
      <title>Lightly-supervised Representation Learning with Global Interpretability</title>
      <author><first>Andrew</first><last>Zupon</last></author>
      <author><first>Maria</first><last>Alexeeva</last></author>
      <author><first>Marco</first><last>Valenzuela-Escárcega</last></author>
      <author><first>Ajay</first><last>Nagesh</last></author>
      <author><first>Mihai</first><last>Surdeanu</last></author>
      <pages>18–28</pages>
      <abstract>We propose a lightly-supervised approach for information extraction, in particular named entity classification, which combines the benefits of traditional bootstrapping, i.e., use of limited annotations and interpretability of extraction patterns, with the robust learning approaches proposed in representation learning. Our algorithm iteratively learns custom embeddings for both the multi-word entities to be extracted and the patterns that match them from a few example entities per category. We demonstrate that this representation-based approach outperforms three other state-of-the-art bootstrapping approaches on two datasets: CoNLL-2003 and OntoNotes. Additionally, using these embeddings, our approach outputs a globally-interpretable model consisting of a decision list, by ranking patterns based on their proximity to the average entity embedding in a given class. We show that this interpretable model performs close to our complete bootstrapping model, proving that representation learning can be used to produce interpretable models with small loss in performance. This decision list can be edited by human experts to mitigate some of that loss and in some cases outperform the original model.</abstract>
      <url>W19-1504</url>
    </paper>
    <paper id="5">
      <title>Semi-Supervised Teacher-Student Architecture for Relation Extraction</title>
      <author><first>Fan</first><last>Luo</last></author>
      <author><first>Ajay</first><last>Nagesh</last></author>
      <author><first>Rebecca</first><last>Sharp</last></author>
      <author><first>Mihai</first><last>Surdeanu</last></author>
      <pages>29–37</pages>
      <abstract>Generating a large amount of training data for information extraction (IE) is either costly (if annotations are created manually), or runs the risk of introducing noisy instances (if distant supervision is used). On the other hand, semi- supervised learning (SSL) is a cost-efficient solution to combat lack of training data. In this paper, we adapt Mean Teacher (Tarvainen and Valpola, 2017), a denoising SSL framework to extract semantic relations between pairs of entities. We explore the sweet spot of amount of supervision required for good performance on this binary relation extraction task. Addition- ally, different syntax representations are incorporated into our models to enhance the learned representation of sentences. We evaluate our approach on the Google-IISc Distant Supervision (GDS) dataset, which removes test data noise present in all previous distance supervision datasets, which makes it a reliable evaluation benchmark (Jat et al., 2017). Our results show that the SSL Mean Teacher approach nears the performance of fully-supervised approaches even with only 10% of the labeled corpus. Further, the syntax-aware model out- performs other syntax-free approaches across all levels of supervision.</abstract>
      <url>W19-1505</url>
    </paper>
  </volume>
  <volume id="16">
    <meta>
      <booktitle>Proceedings of the Combined Workshop on Spatial Language Understanding (<fixed-case>S</fixed-case>p<fixed-case>LU</fixed-case>) and Grounded Communication for Robotics (<fixed-case>R</fixed-case>obo<fixed-case>NLP</fixed-case>)</booktitle>
      <url>W19-16</url>
      <editor><first>Archna</first><last>Bhatia</last></editor>
      <editor><first>Yonatan</first><last>Bisk</last></editor>
      <editor><first>Parisa</first><last>Kordjamshidi</last></editor>
      <editor><first>Jesse</first><last>Thomason</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-1600</url>
    </frontmatter>
    <paper id="1">
      <title>Corpus of Multimodal Interaction for Collaborative Planning</title>
      <author><first>Miltiadis Marios</first><last>Katsakioris</last></author>
      <author><first>Helen</first><last>Hastie</last></author>
      <author><first>Ioannis</first><last>Konstas</last></author>
      <author><first>Atanas</first><last>Laskov</last></author>
      <pages>1–6</pages>
      <abstract>As autonomous systems become more commonplace, we need a way to easily and naturally communicate to them our goals and collaboratively come up with a plan on how to achieve these goals. To this end, we conducted a Wizard of Oz study to gather data and investigate the way operators would collaboratively make plans via a conversational ‘planning assistant’ for remote autonomous systems. We present here a corpus of 22 dialogs from expert operators, which can be used to train such a system. Data analysis shows that multimodality is key to successful interaction, measured both quantitatively and qualitatively via user feedback.</abstract>
      <url>W19-1601</url>
    </paper>
    <paper id="2">
      <title>¿<fixed-case>E</fixed-case>s un plátano? Exploring the Application of a Physically Grounded Language Acquisition System to <fixed-case>S</fixed-case>panish</title>
      <author><first>Caroline</first><last>Kery</last></author>
      <author><first>Francis</first><last>Ferraro</last></author>
      <author><first>Cynthia</first><last>Matuszek</last></author>
      <pages>7–17</pages>
      <abstract>In this paper we describe a multilingual grounded language learning system adapted from an English-only system. This system learns the meaning of words used in crowd-sourced descriptions by grounding them in the physical representations of the objects they are describing. Our work presents a framework to compare the performance of the system when applied to a new language and to identify modifications necessary to attain equal performance, with the goal of enhancing the ability of robots to learn language from a more diverse range of people. We then demonstrate this system with Spanish, through first analyzing the performance of translated Spanish, and then extending this analysis to a new corpus of crowd-sourced Spanish language data. We find that with small modifications, the system is able to learn color, object, and shape words with comparable performance between languages.</abstract>
      <url>W19-1602</url>
    </paper>
    <paper id="3">
      <title>From Virtual to Real: A Framework for Verbal Interaction with Robots</title>
      <author><first>Eugene</first><last>Joseph</last></author>
      <pages>18–28</pages>
      <abstract>A Natural Language Understanding (NLU) pipeline integrated with a 3D physics-based scene is a flexible way to develop and test language-based human-robot interaction, by virtualizing people, robot hardware and the target 3D environment. Here, interaction means both controlling robots using language and conversing with them about the user’s physical environment and her daily life. Such a virtual development framework was initially developed for the Bot Colony videogame launched on Steam in June 2014, and has been undergoing improvements since. The framework is focused of developing intuitive verbal interaction with various types of robots. Key robot functions (robot vision and object recognition, path planning and obstacle avoidance, task planning and constraints, grabbing and inverse kinematics), the human participants in the interaction, and the impact of gravity and other forces on the environment are all simulated using commercial 3D tools. The framework can be used as a robotics testbed: the results of our simulations can be compared with the output of algorithms in real robots, to validate such algorithms. A novelty of our framework is support for social interaction with robots - enabling robots to converse about people and objects in the user’s environment, as well as learning about human needs and everyday life topics from their owner.</abstract>
      <url>W19-1603</url>
    </paper>
    <paper id="4">
      <title>Learning from Implicit Information in Natural Language Instructions for Robotic Manipulations</title>
      <author><first>Ozan Arkan</first><last>Can</last></author>
      <author><first>Pedro</first><last>Zuidberg Dos Martires</last></author>
      <author><first>Andreas</first><last>Persson</last></author>
      <author><first>Julian</first><last>Gaal</last></author>
      <author><first>Amy</first><last>Loutfi</last></author>
      <author><first>Luc</first><last>De Raedt</last></author>
      <author><first>Deniz</first><last>Yuret</last></author>
      <author><first>Alessandro</first><last>Saffiotti</last></author>
      <pages>29–39</pages>
      <abstract>Human-robot interaction often occurs in the form of instructions given from a human to a robot. For a robot to successfully follow instructions, a common representation of the world and objects in it should be shared between humans and the robot so that the instructions can be grounded. Achieving this representation can be done via learning, where both the world representation and the language grounding are learned simultaneously. However, in robotics this can be a difficult task due to the cost and scarcity of data. In this paper, we tackle the problem by separately learning the world representation of the robot and the language grounding. While this approach can address the challenges in getting sufficient data, it may give rise to inconsistencies between both learned components. Therefore, we further propose Bayesian learning to resolve such inconsistencies between the natural language grounding and a robot’s world representation by exploiting spatio-relational information that is implicitly present in instructions given by a human. Moreover, we demonstrate the feasibility of our approach on a scenario involving a robotic arm in the physical world.</abstract>
      <url>W19-1604</url>
    </paper>
    <paper id="5">
      <title>Multi-modal Discriminative Model for Vision-and-Language Navigation</title>
      <author><first>Haoshuo</first><last>Huang</last></author>
      <author><first>Vihan</first><last>Jain</last></author>
      <author><first>Harsh</first><last>Mehta</last></author>
      <author><first>Jason</first><last>Baldridge</last></author>
      <author><first>Eugene</first><last>Ie</last></author>
      <pages>40–49</pages>
      <abstract>Vision-and-Language Navigation (VLN) is a natural language grounding task where agents have to interpret natural language instructions in the context of visual scenes in a dynamic environment to achieve prescribed navigation goals. Successful agents must have the ability to parse natural language of varying linguistic styles, ground them in potentially unfamiliar scenes, plan and react with ambiguous environmental feedback. Generalization ability is limited by the amount of human annotated data. In particular, paired vision-language sequence data is expensive to collect. We develop a discriminator that evaluates how well an instruction explains a given path in VLN task using multi-modal alignment. Our study reveals that only a small fraction of the high-quality augmented data from Fried et al., as scored by our discriminator, is useful for training VLN agents with similar performance. We also show that a VLN agent warm-started with pre-trained components from the discriminator outperforms the benchmark success rates of 35.5 by 10% relative measure.</abstract>
      <url>W19-1605</url>
    </paper>
    <paper id="6">
      <title>Semantic Spatial Representation: a unique representation of an environment based on an ontology for robotic applications</title>
      <author><first>Guillaume</first><last>Sarthou</last></author>
      <author><first>Aurélie</first><last>Clodic</last></author>
      <author><first>Rachid</first><last>Alami</last></author>
      <pages>50–60</pages>
      <abstract>It is important, for human-robot interaction, to endow the robot with the knowledge necessary to understand human needs and to be able to respond to them. We present a formalized and unified representation for indoor environments using an ontology devised for a route description task in which a robot must provide explanations to a person. We show that this representation can be used to choose a route to explain to a human as well as to verbalize it using a route perspective. Based on ontology, this representation has a strong possibility of evolution to adapt to many other applications. With it, we get the semantics of the environment elements while keeping a description of the known connectivity of the environment. This representation and the illustration algorithms, to find and verbalize a route, have been tested in two environments of different scales.</abstract>
      <url>W19-1606</url>
    </paper>
    <paper id="7">
      <title><fixed-case>S</fixed-case>patial<fixed-case>N</fixed-case>et: A Declarative Resource for Spatial Relations</title>
      <author><first>Morgan</first><last>Ulinski</last></author>
      <author><first>Bob</first><last>Coyne</last></author>
      <author><first>Julia</first><last>Hirschberg</last></author>
      <pages>61–70</pages>
      <abstract>This paper introduces SpatialNet, a novel resource which links linguistic expressions to actual spatial configurations. SpatialNet is based on FrameNet (Ruppenhofer et al., 2016) and VigNet (Coyne et al., 2011), two resources which use frame semantics to encode lexical meaning. SpatialNet uses a deep semantic representation of spatial relations to provide a formal description of how a language expresses spatial information. This formal representation of the lexical semantics of spatial language also provides a consistent way to represent spatial meaning across multiple languages. In this paper, we describe the structure of SpatialNet, with examples from English and German. We also show how SpatialNet can be combined with other existing NLP tools to create a text-to-scene system for a language.</abstract>
      <url>W19-1607</url>
    </paper>
    <paper id="8">
      <title>What a neural language model tells us about spatial relations</title>
      <author><first>Mehdi</first><last>Ghanimifard</last></author>
      <author><first>Simon</first><last>Dobnik</last></author>
      <pages>71–81</pages>
      <abstract>Understanding and generating spatial descriptions requires knowledge about what objects are related, their functional interactions, and where the objects are geometrically located. Different spatial relations have different functional and geometric bias. The wide usage of neural language models in different areas including generation of image description motivates the study of what kind of knowledge is encoded in neural language models about individual spatial relations. With the premise that the functional bias of relations is expressed in their word distributions, we construct multi-word distributional vector representations and show that these representations perform well on intrinsic semantic reasoning tasks, thus confirming our premise. A comparison of our vector representations to human semantic judgments indicates that different bias (functional or geometric) is captured in different data collection tasks which suggests that the contribution of the two meaning modalities is dynamic, related to the context of the task.</abstract>
      <url>W19-1608</url>
      <attachment type="supplementary">W19-1608.Supplementary.pdf</attachment>
    </paper>
  </volume>
  <volume id="17">
    <meta>
      <booktitle>Proceedings of the Eighth Workshop on Speech and Language Processing for Assistive Technologies</booktitle>
      <url>W19-17</url>
      <editor><first>University of Sheffield</first><last>Heidi Christensen</last></editor>
      <editor><first>Florida Institute for Human</first><last>Kristy Hollingshead</last></editor>
      <editor><first>Machine</first><last>Cognition</last></editor>
      <editor><first>Boston College</first><last>Emily Prud’hommeaux</last></editor>
      <editor><first>University of Toronto</first><last>Frank Rudzicz</last></editor>
      <editor><first>Michigan Technological University</first><last>Keith Vertanen</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-1700</url>
    </frontmatter>
    <paper id="1">
      <title>A user study to compare two conversational assistants designed for people with hearing impairments</title>
      <author><first>Anja</first><last>Virkkunen</last></author>
      <author><first>Juri</first><last>Lukkarila</last></author>
      <author><first>Kalle</first><last>Palomäki</last></author>
      <author><first>Mikko</first><last>Kurimo</last></author>
      <pages>1–8</pages>
      <abstract>Participating in conversations can be difficult for people with hearing loss, especially in acoustically challenging environments. We studied the preferences the hearing impaired have for a personal conversation assistant based on automatic speech recognition (ASR) technology. We created two prototypes which were evaluated by hearing impaired test users. This paper qualitatively compares the two based on the feedback obtained from the tests. The first prototype was a proof-of-concept system running real-time ASR on a laptop. The second prototype was developed for a mobile device with the recognizer running on a separate server. In the mobile device, augmented reality (AR) was used to help the hearing impaired observe gestures and lip movements of the speaker simultaneously with the transcriptions. Several testers found the systems useful enough to use in their daily lives, with majority preferring the mobile AR version. The biggest concern of the testers was the accuracy of the transcriptions and the lack of speaker identification.</abstract>
      <url>W19-1701</url>
    </paper>
    <paper id="2">
      <title>Modeling Acoustic-Prosodic Cues for Word Importance Prediction in Spoken Dialogues</title>
      <author><first>Sushant</first><last>Kafle</last></author>
      <author><first>Cissi Ovesdotter</first><last>Alm</last></author>
      <author><first>Matt</first><last>Huenerfauth</last></author>
      <pages>9–16</pages>
      <abstract>Prosodic cues in conversational speech aid listeners in discerning a message. We investigate whether acoustic cues in spoken dialogue can be used to identify the importance of individual words to the meaning of a conversation turn. Individuals who are Deaf and Hard of Hearing often rely on real-time captions in live meetings. Word error rate, a traditional metric for evaluating automatic speech recognition (ASR), fails to capture that some words are more important for a system to transcribe correctly than others. We present and evaluate neural architectures that use acoustic features for 3-class word importance prediction. Our model performs competitively against state-of-the-art text-based word-importance prediction models, and it demonstrates particular benefits when operating on imperfect ASR output.</abstract>
      <url>W19-1702</url>
    </paper>
    <paper id="3">
      <title>Permanent Magnetic Articulograph (<fixed-case>PMA</fixed-case>) vs Electromagnetic Articulograph (<fixed-case>EMA</fixed-case>) in Articulation-to-Speech Synthesis for Silent Speech Interface</title>
      <author><first>Beiming</first><last>Cao</last></author>
      <author><first>Nordine</first><last>Sebkhi</last></author>
      <author><first>Ted</first><last>Mau</last></author>
      <author><first>Omer T.</first><last>Inan</last></author>
      <author><first>Jun</first><last>Wang</last></author>
      <pages>17–23</pages>
      <abstract>Silent speech interfaces (SSIs) are devices that enable speech communication when audible speech is unavailable. Articulation-to-speech (ATS) synthesis is a software design in SSI that directly converts articulatory movement information into audible speech signals. Permanent magnetic articulograph (PMA) is a wireless articulator motion tracking technology that is similar to commercial, wired Electromagnetic Articulograph (EMA). PMA has shown great potential for practical SSI applications, because it is wireless. The ATS performance of PMA, however, is unknown when compared with current EMA. In this study, we compared the performance of ATS using a PMA we recently developed and a commercially available EMA (NDI Wave system). Datasets with same stimuli and size that were collected from tongue tip were used in the comparison. The experimental results indicated the performance of PMA was close to, although not as equally good as that of EMA. Furthermore, in PMA, converting the raw magnetic signals to positional signals did not significantly affect the performance of ATS, which support the future direction in PMA-based ATS can be focused on the use of positional signals to maximize the benefit of spatial analysis.</abstract>
      <url>W19-1703</url>
    </paper>
    <paper id="4">
      <title>Speech-based Estimation of Bulbar Regression in Amyotrophic Lateral Sclerosis</title>
      <author><first>Alan</first><last>Wisler</last></author>
      <author><first>Kristin</first><last>Teplansky</last></author>
      <author><first>Jordan</first><last>Green</last></author>
      <author><first>Yana</first><last>Yunusova</last></author>
      <author><first>Thomas</first><last>Campbell</last></author>
      <author><first>Daragh</first><last>Heitzman</last></author>
      <author><first>Jun</first><last>Wang</last></author>
      <pages>24–31</pages>
      <abstract>Amyotrophic Lateral Sclerosis (ALS) is a progressive neurological disease that leads to degeneration of motor neurons and, as a result, inhibits the ability of the brain to control muscle movements. Monitoring the progression of ALS is of fundamental importance due to the wide variability in disease outlook that exists across patients. This progression is typically tracked using the ALS functional rating scale - revised (ALSFRS-R), which is the current clinical assessment of a patient’s level of functional impairment including speech and other motor tasks. In this paper, we investigated automatic estimation of the ALSFRS-R bulbar subscore from acoustic and articulatory movement samples. Experimental results demonstrated the AFSFRS-R bulbar subscore can be predicted from speech samples, which has clinical implication for automatic monitoring of the disease progression of ALS using speech information.</abstract>
      <url>W19-1704</url>
    </paper>
    <paper id="5">
      <title>A Blissymbolics Translation System</title>
      <author><first>Usman</first><last>Sohail</last></author>
      <author><first>David</first><last>Traum</last></author>
      <pages>32–36</pages>
      <abstract>Blissymbolics (Bliss) is a pictographic writing system that is used by people with communication disorders. Bliss attempts to create a writing system that makes words easier to distinguish by using pictographic symbols that encapsulate meaning rather than sound, as the English alphabet does for example. Users of Bliss rely on human interpreters to use Bliss. We created a translation system from Bliss to natural English with the hopes of decreasing the reliance on human interpreters by the Bliss community. We first discuss the basic rules of Blissymbolics. Then we point out some of the challenges associated with developing computer assisted tools for Blissymbolics. Next we talk about our ongoing work in developing a translation system, including current limitations, and future work. We conclude with a set of examples showing the current capabilities of our translation system.</abstract>
      <url>W19-1705</url>
    </paper>
    <paper id="6">
      <title>Investigating Speech Recognition for Improving Predictive <fixed-case>AAC</fixed-case></title>
      <author><first>Jiban</first><last>Adhikary</last></author>
      <author><first>Robbie</first><last>Watling</last></author>
      <author><first>Crystal</first><last>Fletcher</last></author>
      <author><first>Alex</first><last>Stanage</last></author>
      <author><first>Keith</first><last>Vertanen</last></author>
      <pages>37–43</pages>
      <abstract>Making good letter or word predictions can help accelerate the communication of users of high-tech AAC devices. This is particularly important for real-time person-to-person conversations. We investigate whether per forming speech recognition on the speaking-side of a conversation can improve language model based predictions. We compare the accuracy of three plausible microphone deployment options and the accuracy of two commercial speech recognition engines (Google and IBM Watson). We found that despite recognition word error rates of 7-16%, our ensemble of N-gram and recurrent neural network language models made predictions nearly as good as when they used the reference transcripts.</abstract>
      <url>W19-1706</url>
    </paper>
    <paper id="7">
      <title>Noisy Neural Language Modeling for Typing Prediction in <fixed-case>BCI</fixed-case> Communication</title>
      <author><first>Rui</first><last>Dong</last></author>
      <author><first>David</first><last>Smith</last></author>
      <author><first>Shiran</first><last>Dudy</last></author>
      <author><first>Steven</first><last>Bedrick</last></author>
      <pages>44–51</pages>
      <abstract>Language models have broad adoption in predictive typing tasks. When the typing history contains numerous errors, as in open-vocabulary predictive typing with brain-computer interface (BCI) systems, we observe significant performance degradation in both n-gram and recurrent neural network language models trained on clean text. In evaluations of ranking character predictions, training recurrent LMs on noisy text makes them much more robust to noisy histories, even when the error model is misspecified. We also propose an effective strategy for combining evidence from multiple ambiguous histories of BCI electroencephalogram measurements.</abstract>
      <url>W19-1707</url>
    </paper>
  </volume>
  <volume id="18">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Shortcomings in Vision and Language</booktitle>
      <url>W19-18</url>
      <editor><first>Raffaella</first><last>Bernardi</last></editor>
      <editor><first>Raquel</first><last>Fernandez</last></editor>
      <editor><first>Spandana</first><last>Gella</last></editor>
      <editor><first>Kushal</first><last>Kafle</last></editor>
      <editor><first>Christopher</first><last>Kanan</last></editor>
      <editor><first>Stefan</first><last>Lee</last></editor>
      <editor><first>Moin</first><last>Nabi</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-1800</url>
    </frontmatter>
    <paper id="1">
      <title>Adversarial Regularization for Visual Question Answering: Strengths, Shortcomings, and Side Effects</title>
      <author><first>Gabriel</first><last>Grand</last></author>
      <author><first>Yonatan</first><last>Belinkov</last></author>
      <pages>1–13</pages>
      <abstract>Visual question answering (VQA) models have been shown to over-rely on linguistic biases in VQA datasets, answering questions “blindly” without considering visual context. Adversarial regularization (AdvReg) aims to address this issue via an adversary sub-network that encourages the main model to learn a bias-free representation of the question. In this work, we investigate the strengths and shortcomings of AdvReg with the goal of better understanding how it affects inference in VQA models. Despite achieving a new state-of-the-art on VQA-CP, we find that AdvReg yields several undesirable side-effects, including unstable gradients and sharply reduced performance on in-domain examples. We demonstrate that gradual introduction of regularization during training helps to alleviate, but not completely solve, these issues. Through error analyses, we observe that AdvReg improves generalization to binary questions, but impairs performance on questions with heterogeneous answer distributions. Qualitatively, we also find that regularized models tend to over-rely on visual features, while ignoring important linguistic cues in the question. Our results suggest that AdvReg requires further refinement before it can be considered a viable bias mitigation technique for VQA.</abstract>
      <url>W19-1801</url>
    </paper>
    <paper id="2">
      <title>Referring to Objects in Videos Using Spatio-Temporal Identifying Descriptions</title>
      <author><first>Peratham</first><last>Wiriyathammabhum</last></author>
      <author><first>Abhinav</first><last>Shrivastava</last></author>
      <author><first>Vlad</first><last>Morariu</last></author>
      <author><first>Larry</first><last>Davis</last></author>
      <pages>14–25</pages>
      <abstract>This paper presents a new task, the grounding of spatio-temporal identifying descriptions in videos. Previous work suggests potential bias in existing datasets and emphasizes the need for a new data creation schema to better model linguistic structure. We introduce a new data collection scheme based on grammatical constraints for surface realization to enable us to investigate the problem of grounding spatio-temporal identifying descriptions in videos. We then propose a two-stream modular attention network that learns and grounds spatio-temporal identifying descriptions based on appearance and motion. We show that motion modules help to ground motion-related words and also help to learn in appearance modules because modular neural networks resolve task interference between modules. Finally, we propose a future challenge and a need for a robust system arising from replacing ground truth visual annotations with automatic video object detector and temporal event localization.</abstract>
      <url>W19-1802</url>
      <attachment type="supplementary">W19-1802.Supplementary.pdf</attachment>
    </paper>
    <paper id="3">
      <title>A Survey on Biomedical Image Captioning</title>
      <author><first>John</first><last>Pavlopoulos</last></author>
      <author><first>Vasiliki</first><last>Kougia</last></author>
      <author><first>Ion</first><last>Androutsopoulos</last></author>
      <pages>26–36</pages>
      <abstract>Image captioning applied to biomedical images can assist and accelerate the diagnosis process followed by clinicians. This article is the first survey of biomedical image captioning, discussing datasets, evaluation measures, and state of the art methods. Additionally, we suggest two baselines, a weak and a stronger one; the latter outperforms all current state of the art systems on one of the datasets.</abstract>
      <url>W19-1803</url>
    </paper>
    <paper id="4">
      <title>Revisiting Visual Grounding</title>
      <author><first>Erik</first><last>Conser</last></author>
      <author><first>Kennedy</first><last>Hahn</last></author>
      <author><first>Chandler</first><last>Watson</last></author>
      <author><first>Melanie</first><last>Mitchell</last></author>
      <pages>37–46</pages>
      <abstract>We revisit a particular visual grounding method: the “Image Retrieval Using Scene Graphs” (IRSG) system of Johnson et al. Our experiments indicate that the system does not effectively use its learned object-relationship models. We also look closely at the IRSG dataset, as well as the widely used Visual Relationship Dataset (VRD) that is adapted from it. We find that these datasets exhibit bias that allows methods that ignore relationships to perform relatively well. We also describe several other problems with the IRSG dataset, and report on experiments using a subset of the dataset in which the biases and other problems are removed. Our studies contribute to a more general effort: that of better understanding what machine-learning methods that combine language and vision actually learn and what popular datasets actually test.</abstract>
      <url>W19-1804</url>
    </paper>
    <paper id="5">
      <title>The Steep Road to Happily Ever after: an Analysis of Current Visual Storytelling Models</title>
      <author><first>Yatri</first><last>Modi</last></author>
      <author><first>Natalie</first><last>Parde</last></author>
      <pages>47–57</pages>
      <abstract>Visual storytelling is an intriguing and complex task that only recently entered the research arena. In this work, we survey relevant work to date, and conduct a thorough error analysis of three very recent approaches to visual storytelling. We categorize and provide examples of common types of errors, and identify key shortcomings in current work. Finally, we make recommendations for addressing these limitations in the future.</abstract>
      <url>W19-1805</url>
    </paper>
    <paper id="6">
      <title>“Caption” as a Coherence Relation: Evidence and Implications</title>
      <author><first>Malihe</first><last>Alikhani</last></author>
      <author><first>Matthew</first><last>Stone</last></author>
      <pages>58–67</pages>
      <abstract>We study verbs in image–text corpora, contrasting <i>caption</i> corpora, where texts are explicitly written to characterize image content, with <i>depiction</i> corpora, where texts and images may stand in more general relations. Captions show a distinctively limited distribution of verbs, with strong preferences for specific tense, aspect, lexical aspect, and semantic field. These limitations, which appear in data elicited by a range of methods, restrict the utility of caption corpora to inform image retrieval, multimodal document generation, and perceptually-grounded semantic models. We suggest that these limitations reflect the discourse constraints in play when subjects write texts to accompany imagery, so we argue that future development of image–text corpora should work to increase the diversity of event descriptions, while looking explicitly at the different ways text and imagery can be coherently related.</abstract>
      <url>W19-1806</url>
    </paper>
    <paper id="7">
      <title>Learning Multilingual Word Embeddings Using Image-Text Data</title>
      <author><first>Karan</first><last>Singhal</last></author>
      <author><first>Karthik</first><last>Raman</last></author>
      <author><first>Balder</first><last>ten Cate</last></author>
      <pages>68–77</pages>
      <abstract>There has been significant interest recently in learning multilingual word embeddings – in which semantically similar words across languages have similar embeddings. State-of-the-art approaches have relied on expensive labeled data, which is unavailable for low-resource languages, or have involved post-hoc unification of monolingual embeddings. In the present paper, we investigate the efficacy of multilingual embeddings learned from weakly-supervised image-text data. In particular, we propose methods for learning multilingual embeddings using image-text data, by enforcing similarity between the representations of the image and that of the text. Our experiments reveal that even without using any expensive labeled data, a bag-of-words-based embedding model trained on image-text data achieves performance comparable to the state-of-the-art on crosslingual semantic similarity tasks.</abstract>
      <url>W19-1807</url>
    </paper>
    <paper id="8">
      <title>Grounded Word Sense Translation</title>
      <author><first>Chiraag</first><last>Lala</last></author>
      <author><first>Pranava</first><last>Madhyastha</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <pages>78–85</pages>
      <abstract>Recent work on visually grounded language learning has focused on broader applications of grounded representations, such as visual question answering and multimodal machine translation. In this paper we consider grounded word sense translation, i.e. the task of correctly translating an ambiguous source word given the corresponding textual and visual context. Our main objective is to investigate the extent to which images help improve word-level (lexical) translation quality. We do so by first studying the dataset for this task to understand the scope and challenges of the task. We then explore different data settings, image features, and ways of grounding to investigate the gain from using images in each of the combinations. We find that grounding on the image is specially beneficial in weaker unidirectional recurrent translation models. We observe that adding structured image information leads to stronger gains in lexical translation accuracy.</abstract>
      <url>W19-1808</url>
    </paper>
  </volume>
  <volume id="19">
    <meta>
      <booktitle>Proceedings of the 2nd Clinical Natural Language Processing Workshop</booktitle>
      <url>W19-19</url>
      <editor><first>Anna</first><last>Rumshisky</last></editor>
      <editor><first>Kirk</first><last>Roberts</last></editor>
      <editor><first>Steven</first><last>Bethard</last></editor>
      <editor><first>Tristan</first><last>Naumann</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota, USA</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-1900</url>
    </frontmatter>
    <paper id="1">
      <title>Effective Feature Representation for Clinical Text Concept Extraction</title>
      <author><first>Yifeng</first><last>Tao</last></author>
      <author><first>Bruno</first><last>Godefroy</last></author>
      <author><first>Guillaume</first><last>Genthial</last></author>
      <author><first>Christopher</first><last>Potts</last></author>
      <pages>1–14</pages>
      <abstract>Crucial information about the practice of healthcare is recorded only in free-form text, which creates an enormous opportunity for high-impact NLP. However, annotated healthcare datasets tend to be small and expensive to obtain, which raises the question of how to make maximally efficient uses of the available data. To this end, we develop an LSTM-CRF model for combining unsupervised word representations and hand-built feature representations derived from publicly available healthcare ontologies. We show that this combined model yields superior performance on five datasets of diverse kinds of healthcare text (clinical, social, scientific, commercial). Each involves the labeling of complex, multi-word spans that pick out different healthcare concepts. We also introduce a new labeled dataset for identifying the treatment relations between drugs and diseases.</abstract>
      <url>W19-1901</url>
      <software>W19-1901.Software.txt</software>
    </paper>
    <paper id="2">
      <title>An Analysis of Attention over Clinical Notes for Predictive Tasks</title>
      <author><first>Sarthak</first><last>Jain</last></author>
      <author><first>Ramin</first><last>Mohammadi</last></author>
      <author><first>Byron C.</first><last>Wallace</last></author>
      <pages>15–21</pages>
      <abstract>The shift to electronic medical records (EMRs) has engendered research into machine learning and natural language technologies to analyze patient records, and to predict from these clinical outcomes of interest. Two observations motivate our aims here. First, unstructured notes contained within EMR often contain key information, and hence should be exploited by models. Second, while strong predictive performance is important, interpretability of models is perhaps equally so for applications in this domain. Together, these points suggest that neural models for EMR may benefit from incorporation of attention over notes, which one may hope will both yield performance gains and afford transparency in predictions. In this work we perform experiments to explore this question using two EMR corpora and four different predictive tasks, that: (i) inclusion of attention mechanisms is critical for neural encoder modules that operate over notes fields in order to yield competitive performance, but, (ii) unfortunately, while these boost predictive performance, it is decidedly less clear whether they provide meaningful support for predictions.</abstract>
      <url>W19-1902</url>
    </paper>
    <paper id="3">
      <title>Extracting Adverse Drug Event Information with Minimal Engineering</title>
      <author><first>Timothy</first><last>Miller</last></author>
      <author><first>Alon</first><last>Geva</last></author>
      <author><first>Dmitriy</first><last>Dligach</last></author>
      <pages>22–27</pages>
      <abstract>In this paper we describe an evaluation of the potential of classical information extraction methods to extract drug-related attributes, including adverse drug events, and compare to more recently developed neural methods. We use the 2018 N2C2 shared task data as our gold standard data set for training. We train support vector machine classifiers to detect drug and drug attribute spans, and pair these detected entities as training instances for an SVM relation classifier, with both systems using standard features. We compare to baseline neural methods that use standard contextualized embedding representations for entity and relation extraction. The SVM-based system and a neural system obtain comparable results, with the SVM system doing better on concepts and the neural system performing better on relation extraction tasks. The neural system obtains surprisingly strong results compared to the system based on years of research in developing features for information extraction.</abstract>
      <url>W19-1903</url>
    </paper>
    <paper id="4">
      <title>Hierarchical Nested Named Entity Recognition</title>
      <author><first>Zita</first><last>Marinho</last></author>
      <author><first>Afonso</first><last>Mendes</last></author>
      <author><first>Sebastião</first><last>Miranda</last></author>
      <author><first>David</first><last>Nogueira</last></author>
      <pages>28–34</pages>
      <abstract>In the medical domain and other scientific areas, it is often important to recognize different levels of hierarchy in mentions, such as those related to specific symptoms or diseases associated with different anatomical regions. Unlike previous approaches, we build a transition-based parser that explicitly models an arbitrary number of hierarchical and nested mentions, and propose a loss that encourages correct predictions of higher-level mentions. We further introduce a set of modifier classes which introduces certain concepts that change the meaning of an entity, such as absence, or uncertainty about a given disease. Our proposed model achieves state-of-the-art results in medical entity recognition datasets, using both nested and hierarchical mentions.</abstract>
      <url>W19-1904</url>
      <attachment type="supplementary">W19-1904.Supplementary.pdf</attachment>
    </paper>
    <paper id="5">
      <title>Towards Automatic Generation of Shareable Synthetic Clinical Notes Using Neural Language Models</title>
      <author><first>Oren</first><last>Melamud</last></author>
      <author><first>Chaitanya</first><last>Shivade</last></author>
      <pages>35–45</pages>
      <abstract>Large-scale clinical data is invaluable to driving many computational scientific advances today. However, understandable concerns regarding patient privacy hinder the open dissemination of such data and give rise to suboptimal siloed research. De-identification methods attempt to address these concerns but were shown to be susceptible to adversarial attacks. In this work, we focus on the vast amounts of unstructured natural language data stored in clinical notes and propose to automatically generate synthetic clinical notes that are more amenable to sharing using generative models trained on real de-identified records. To evaluate the merit of such notes, we measure both their privacy preservation properties as well as utility in training clinical NLP models. Experiments using neural language models yield notes whose utility is close to that of the real ones in some clinical NLP tasks, yet leave ample room for future improvements.</abstract>
      <url>W19-1905</url>
    </paper>
    <paper id="6">
      <title>A Novel System for Extractive Clinical Note Summarization using <fixed-case>EHR</fixed-case> Data</title>
      <author><first>Jennifer</first><last>Liang</last></author>
      <author><first>Ching-Huei</first><last>Tsou</last></author>
      <author><first>Ananya</first><last>Poddar</last></author>
      <pages>46–54</pages>
      <abstract>While much data within a patient’s electronic health record (EHR) is coded, crucial information concerning the patient’s care and management remain buried in unstructured clinical notes, making it difficult and time-consuming for physicians to review during their usual clinical workflow. In this paper, we present our clinical note processing pipeline, which extends beyond basic medical natural language processing (NLP) with concept recognition and relation detection to also include components specific to EHR data, such as structured data associated with the encounter, sentence-level clinical aspects, and structures of the clinical notes. We report on the use of this pipeline in a disease-specific extractive text summarization task on clinical notes, focusing primarily on progress notes by physicians and nurse practitioners. We show how the addition of EHR-specific components to the pipeline resulted in an improvement in our overall system performance and discuss the potential impact of EHR-specific components on other higher-level clinical NLP tasks.</abstract>
      <url>W19-1906</url>
      <revision id="2">W19-1906v2</revision>
    </paper>
    <paper id="7">
      <title>Study of lexical aspect in the <fixed-case>F</fixed-case>rench medical language. Development of a lexical resource</title>
      <author><first>Agathe</first><last>Pierson</last></author>
      <author><first>Cédrick</first><last>Fairon</last></author>
      <pages>55–64</pages>
      <abstract>This paper details the development of a linguistic resource designed to improve temporal information extraction systems and to integrate aspectual values. After a brief review of recent works in temporal information extraction for the medical area, we discuss the linguistic notion of aspect and how it got a place in the NLP field. Then, we present our clinical data and describe the five-step approach adopted in this study. Finally, we represent the linguistic resource itself and explain how we elaborated it and which properties were selected for the creation of the tables.</abstract>
      <url>W19-1907</url>
    </paper>
    <paper id="8">
      <title>A <fixed-case>BERT</fixed-case>-based Universal Model for Both Within- and Cross-sentence Clinical Temporal Relation Extraction</title>
      <author><first>Chen</first><last>Lin</last></author>
      <author><first>Timothy</first><last>Miller</last></author>
      <author><first>Dmitriy</first><last>Dligach</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <author><first>Guergana</first><last>Savova</last></author>
      <pages>65–71</pages>
      <abstract>Classic methods for clinical temporal relation extraction focus on relational candidates within a sentence. On the other hand, break-through Bidirectional Encoder Representations from Transformers (BERT) are trained on large quantities of arbitrary spans of contiguous text instead of sentences. In this study, we aim to build a sentence-agnostic framework for the task of CONTAINS temporal relation extraction. We establish a new state-of-the-art result for the task, 0.684F for in-domain (0.055-point improvement) and 0.565F for cross-domain (0.018-point improvement), by fine-tuning BERT and pre-training domain-specific BERT models on sentence-agnostic temporal relation instances with WordPiece-compatible encodings, and augmenting the labeled data with automatically generated “silver” instances.</abstract>
      <url>W19-1908</url>
    </paper>
    <paper id="9">
      <title>Publicly Available Clinical <fixed-case>BERT</fixed-case> Embeddings</title>
      <author><first>Emily</first><last>Alsentzer</last></author>
      <author><first>John</first><last>Murphy</last></author>
      <author><first>William</first><last>Boag</last></author>
      <author><first>Wei-Hung</first><last>Weng</last></author>
      <author><first>Di</first><last>Jindi</last></author>
      <author><first>Tristan</first><last>Naumann</last></author>
      <author><first>Matthew</first><last>McDermott</last></author>
      <pages>72–78</pages>
      <abstract>Contextual word embedding models such as ELMo and BERT have dramatically improved performance for many natural language processing (NLP) tasks in recent months. However, these models have been minimally explored on specialty corpora, such as clinical text; moreover, in the clinical domain, no publicly-available pre-trained BERT models yet exist. In this work, we address this need by exploring and releasing BERT models for clinical text: one for generic clinical text and another for discharge summaries specifically. We demonstrate that using a domain-specific model yields performance improvements on 3/5 clinical NLP tasks, establishing a new state-of-the-art on the MedNLI dataset. We find that these domain-specific models are not as performant on 2 clinical de-identification tasks, and argue that this is a natural consequence of the differences between de-identified source text and synthetically non de-identified task text.</abstract>
      <url>W19-1909</url>
    </paper>
    <paper id="10">
      <title>A General-Purpose Annotation Model for Knowledge Discovery: Case Study in <fixed-case>S</fixed-case>panish Clinical Text</title>
      <author><first>Alejandro</first><last>Piad-Morffis</last></author>
      <author><first>Yoan</first><last>Guitérrez</last></author>
      <author><first>Suilan</first><last>Estevez-Velarde</last></author>
      <author><first>Rafael</first><last>Muñoz</last></author>
      <pages>79–88</pages>
      <abstract>Knowledge discovery from text in natural language is a task usually aided by the manual construction of annotated corpora. Specifically in the clinical domain, several annotation models are used depending on the characteristics of the task to solve (e.g., named entity recognition, relation extraction, etc.). However, few general-purpose annotation models exist, that can support a broad range of knowledge extraction tasks. This paper presents an annotation model designed to capture a large portion of the semantics of natural language text. The structure of the annotation model is presented, with examples of annotated sentences and a brief description of each semantic role and relation defined. This research focuses on an application to clinical texts in the Spanish language. Nevertheless, the presented annotation model is extensible to other domains and languages. An example of annotated sentences, guidelines, and suitable configuration files for an annotation tool are also provided for the research community.</abstract>
      <url>W19-1910</url>
    </paper>
    <paper id="11">
      <title>Predicting <fixed-case>ICU</fixed-case> transfers using text messages between nurses and doctors</title>
      <author><first>Faiza</first><last>Khan Khattak</last></author>
      <author><first>Chloé</first><last>Pou-Prom</last></author>
      <author><first>Robert</first><last>Wu</last></author>
      <author><first>Frank</first><last>Rudzicz</last></author>
      <pages>89–94</pages>
      <abstract>We explore the use of real-time clinical information, i.e., text messages sent between nurses and doctors regarding patient conditions in order to predict transfer to the intensive care unit(ICU). Preliminary results, in data from five hospitals, indicate that, despite being short and full of noise, text messages can augment other visit information to improve the performance of ICU transfer prediction.</abstract>
      <url>W19-1911</url>
    </paper>
    <paper id="12">
      <title>Medical Entity Linking using Triplet Network</title>
      <author><first>Ishani</first><last>Mondal</last></author>
      <author><first>Sukannya</first><last>Purkayastha</last></author>
      <author><first>Sudeshna</first><last>Sarkar</last></author>
      <author><first>Pawan</first><last>Goyal</last></author>
      <author><first>Jitesh</first><last>Pillai</last></author>
      <author><first>Amitava</first><last>Bhattacharyya</last></author>
      <author><first>Mahanandeeshwar</first><last>Gattu</last></author>
      <pages>95–100</pages>
      <abstract>Entity linking (or Normalization) is an essential task in text mining that maps the entity mentions in the medical text to standard entities in a given Knowledge Base (KB). This task is of great importance in the medical domain. It can also be used for merging different medical and clinical ontologies. In this paper, we center around the problem of disease linking or normalization. This task is executed in two phases: candidate generation and candidate scoring. In this paper, we present an approach to rank the candidate Knowledge Base entries based on their similarity with disease mention. We make use of the Triplet Network for candidate ranking. While the existing methods have used carefully generated sieves and external resources for candidate generation, we introduce a robust and portable candidate generation scheme that does not make use of the hand-crafted rules. Experimental results on the standard benchmark NCBI disease dataset demonstrate that our system outperforms the prior methods by a significant margin.</abstract>
      <url>W19-1912</url>
    </paper>
    <paper id="13">
      <title>Annotating and Characterizing Clinical Sentences with Explicit Why-<fixed-case>QA</fixed-case> Cues</title>
      <author><first>Jungwei</first><last>Fan</last></author>
      <pages>101–106</pages>
      <abstract>Many clinical information needs can be stated as why-questions. The answers to them represent important clinical reasoning and justification. Clinical notes are a rich source for such why-question answering (why-QA). However, there are few dedicated corpora, and little is known about the characteristics of clinical why-QA narratives. To address this gap, the study performed manual annotation of 277 sentences containing explicit why-QA cues and summarized their quantitative and qualitative properties. The contributions are: 1) sharing a seed corpus that can be used for various QA-related training purposes, 2) adding to our knowledge about the diversity and distribution of clinical why-QA contents.</abstract>
      <url>W19-1913</url>
    </paper>
    <paper id="14">
      <title>Extracting Factual Min/Max Age Information from Clinical Trial Studies</title>
      <author><first>Yufang</first><last>Hou</last></author>
      <author><first>Debasis</first><last>Ganguly</last></author>
      <author><first>Léa</first><last>Deleris</last></author>
      <author><first>Francesca</first><last>Bonin</last></author>
      <pages>107–116</pages>
      <abstract>Population age information is an essential characteristic of clinical trials. In this paper, we focus on extracting minimum and maximum (min/max) age values for the study samples from clinical research articles. Specifically, we investigate the use of a neural network model for question answering to address this information extraction task. The min/max age QA model is trained on the massive structured clinical study records from ClinicalTrials.gov. For each article, based on multiple min and max age values extracted from the QA model, we predict both actual min/max age values for the study samples and filter out non-factual age expressions. Our system improves the results over (i) a passage retrieval based IE system and (ii) a CRF-based system by a large margin when evaluated on an annotated dataset consisting of 50 research papers on smoking cessation.</abstract>
      <url>W19-1914</url>
    </paper>
    <paper id="15">
      <title>Distinguishing Clinical Sentiment: The Importance of Domain Adaptation in Psychiatric Patient Health Records</title>
      <author><first>Eben</first><last>Holderness</last></author>
      <author><first>Philip</first><last>Cawkwell</last></author>
      <author><first>Kirsten</first><last>Bolton</last></author>
      <author><first>James</first><last>Pustejovsky</last></author>
      <author><first>Mei-Hua</first><last>Hall</last></author>
      <pages>117–123</pages>
      <abstract>Recently natural language processing (NLP) tools have been developed to identify and extract salient risk indicators in electronic health records (EHRs). Sentiment analysis, although widely used in non-medical areas for improving decision making, has been studied minimally in the clinical setting. In this study, we undertook, to our knowledge, the first domain adaptation of sentiment analysis to psychiatric EHRs by defining psychiatric clinical sentiment, performing an annotation project, and evaluating multiple sentence-level sentiment machine learning (ML) models. Results indicate that off-the-shelf sentiment analysis tools fail in identifying clinically positive or negative polarity, and that the definition of clinical sentiment that we provide is learnable with relatively small amounts of training data. This project is an initial step towards further refining sentiment analysis methods for clinical use. Our long-term objective is to incorporate the results of this project as part of a machine learning model that predicts inpatient readmission risk. We hope that this work will initiate a discussion concerning domain adaptation of sentiment analysis to the clinical setting.</abstract>
      <url>W19-1915</url>
    </paper>
    <paper id="16">
      <title>Medical Word Embeddings for <fixed-case>S</fixed-case>panish: Development and Evaluation</title>
      <author><first>Felipe</first><last>Soares</last></author>
      <author><first>Marta</first><last>Villegas</last></author>
      <author><first>Aitor</first><last>Gonzalez-Agirre</last></author>
      <author><first>Martin</first><last>Krallinger</last></author>
      <author><first>Jordi</first><last>Armengol-Estapé</last></author>
      <pages>124–133</pages>
      <abstract>Word embeddings are representations of words in a dense vector space. Although they are not recent phenomena in Natural Language Processing (NLP), they have gained momentum after the recent developments of neural methods and Word2Vec. Regarding their applications in medical and clinical NLP, they are invaluable resources when training in-domain named entity recognition systems, classifiers or taggers, for instance. Thus, the development of tailored word embeddings for medical NLP is of great interest. However, we identified a gap in the literature which we aim to fill in this paper: the availability of embeddings for medical NLP in Spanish, as well as a standardized form of intrinsic evaluation. Since most work has been done for English, some established datasets for intrinsic evaluation are already available. In this paper, we show the steps we employed to adapt such datasets for the first time to Spanish, of particular relevance due to the considerable volume of EHRs in this language, as well as the creation of in-domain medical word embeddings for the Spanish using the state-of-the-art FastText model. We performed intrinsic evaluation with our adapted datasets, as well as extrinsic evaluation with a named entity recognition systems using a baseline embedding of general-domain. Both experiments proved that our embeddings are suitable for use in medical NLP in the Spanish language, and are more accurate than general-domain ones.</abstract>
      <url>W19-1916</url>
    </paper>
    <paper id="17">
      <title>Attention Neural Model for Temporal Relation Extraction</title>
      <author><first>Sijia</first><last>Liu</last></author>
      <author><first>Liwei</first><last>Wang</last></author>
      <author><first>Vipin</first><last>Chaudhary</last></author>
      <author><first>Hongfang</first><last>Liu</last></author>
      <pages>134–139</pages>
      <abstract>Neural network models have shown promise in the temporal relation extraction task. In this paper, we present the attention based neural network model to extract the containment relations within sentences from clinical narratives. The attention mechanism used on top of GRU model outperforms the existing state-of-the-art neural network models on THYME corpus in intra-sentence temporal relation extraction.</abstract>
      <url>W19-1917</url>
    </paper>
    <paper id="18">
      <title>Automatically Generating Psychiatric Case Notes From Digital Transcripts of Doctor-Patient Conversations</title>
      <author><first>Nazmul</first><last>Kazi</last></author>
      <author><first>Indika</first><last>Kahanda</last></author>
      <pages>140–148</pages>
      <abstract>Electronic health records (EHRs) are notorious for reducing the face-to-face time with patients while increasing the screen-time for clinicians leading to burnout. This is especially problematic for psychiatry care in which maintaining consistent eye-contact and non-verbal cues are just as important as the spoken words. In this ongoing work, we explore the feasibility of automatically generating psychiatric EHR case notes from digital transcripts of doctor-patient conversation using a two-step approach: (1) predicting semantic topics for segments of transcripts using supervised machine learning, and (2) generating formal text of those segments using natural language processing. Through a series of preliminary experimental results obtained through a collection of synthetic and real-life transcripts, we demonstrate the viability of this approach.</abstract>
      <url>W19-1918</url>
    </paper>
    <paper id="19">
      <title>Clinical Data Classification using Conditional Random Fields and Neural Parsing for Morphologically Rich Languages</title>
      <author><first>Razieh</first><last>Ehsani</last></author>
      <author><first>Tyko</first><last>Niemi</last></author>
      <author><first>Gaurav</first><last>Khullar</last></author>
      <author><first>Tiina</first><last>Leivo</last></author>
      <pages>149–155</pages>
      <abstract>Past prescriptions constitute a central element in patient records. These are often written in an unstructured and brief form. Extracting information from such prescriptions enables the development of automated processes in the medical data mining field. This paper presents a Conditional Random Fields (CRFs) based approach to extract relevant information from prescriptions. We focus on Finnish language prescriptions and make use of Finnish language specific features. Our labeling accuracy is 95%, which compares favorably to the current state-of-the-art in English language prescriptions. This, to the best of our knowledge, is the first such work for the Finnish language.</abstract>
      <url>W19-1919</url>
    </paper>
  </volume>
  <volume id="20">
    <meta>
      <booktitle>Proceedings of the 3rd Workshop on Evaluating Vector Space Representations for <fixed-case>NLP</fixed-case></booktitle>
      <url>W19-20</url>
      <editor><first>Anna</first><last>Rogers</last></editor>
      <editor><first>Aleksandr</first><last>Drozd</last></editor>
      <editor><first>Anna</first><last>Rumshisky</last></editor>
      <editor><first>Yoav</first><last>Goldberg</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, USA</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-2000</url>
    </frontmatter>
    <paper id="1">
      <title>Neural Vector Conceptualization for Word Vector Space Interpretation</title>
      <author><first>Robert</first><last>Schwarzenberg</last></author>
      <author><first>Lisa</first><last>Raithel</last></author>
      <author><first>David</first><last>Harbecke</last></author>
      <pages>1–7</pages>
      <abstract>Distributed word vector spaces are considered hard to interpret which hinders the understanding of natural language processing (NLP) models. In this work, we introduce a new method to interpret arbitrary samples from a word vector space. To this end, we train a neural model to conceptualize word vectors, which means that it activates higher order concepts it recognizes in a given vector. Contrary to prior approaches, our model operates in the original vector space and is capable of learning non-linear relations between word vectors and concepts. Furthermore, we show that it produces considerably less entropic concept activation profiles than the popular cosine similarity.</abstract>
      <url>W19-2001</url>
    </paper>
    <paper id="2">
      <title>Characterizing the Impact of Geometric Properties of Word Embeddings on Task Performance</title>
      <author><first>Brendan</first><last>Whitaker</last></author>
      <author><first>Denis</first><last>Newman-Griffis</last></author>
      <author><first>Aparajita</first><last>Haldar</last></author>
      <author><first>Hakan</first><last>Ferhatosmanoglu</last></author>
      <author><first>Eric</first><last>Fosler-Lussier</last></author>
      <pages>8–17</pages>
      <abstract>Analysis of word embedding properties to inform their use in downstream NLP tasks has largely been studied by assessing nearest neighbors. However, geometric properties of the continuous feature space contribute directly to the use of embedding features in downstream models, and are largely unexplored. We consider four properties of word embedding geometry, namely: position relative to the origin, distribution of features in the vector space, global pairwise distances, and local pairwise distances. We define a sequence of transformations to generate new embeddings that expose subsets of these properties to downstream models and evaluate change in task performance to understand the contribution of each property to NLP models. We transform publicly available pretrained embeddings from three popular toolkits (word2vec, GloVe, and FastText) and evaluate on a variety of intrinsic tasks, which model linguistic information in the vector space, and extrinsic tasks, which use vectors as input to machine learning models. We find that intrinsic evaluations are highly sensitive to absolute position, while extrinsic tasks rely primarily on local similarity. Our findings suggest that future embedding models and post-processing techniques should focus primarily on similarity to nearby points in vector space.</abstract>
      <url>W19-2002</url>
      <attachment type="supplementary">W19-2002.Supplementary.zip</attachment>
      <attachment type="presentation">W19-2002.Presentation.pdf</attachment>
    </paper>
    <paper id="3">
      <title>The Influence of Down-Sampling Strategies on <fixed-case>SVD</fixed-case> Word Embedding Stability</title>
      <author><first>Johannes</first><last>Hellrich</last></author>
      <author><first>Bernd</first><last>Kampe</last></author>
      <author><first>Udo</first><last>Hahn</last></author>
      <pages>18–26</pages>
      <abstract>The stability of word embedding algorithms, i.e., the consistency of the word representations they reveal when trained repeatedly on the same data set, has recently raised concerns. We here compare word embedding algorithms on three corpora of different sizes, and evaluate both their stability and accuracy. We find strong evidence that down-sampling strategies (used as part of their training procedures) are particularly influential for the stability of SVD-PPMI-type embeddings. This finding seems to explain diverging reports on their stability and lead us to a simple modification which provides superior stability as well as accuracy on par with skip-gram embedding</abstract>
      <url>W19-2003</url>
    </paper>
    <paper id="4">
      <title>How Well Do Embedding Models Capture Non-compositionality? A View from Multiword Expressions</title>
      <author><first>Navnita</first><last>Nandakumar</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Bahar</first><last>Salehi</last></author>
      <pages>27–34</pages>
      <abstract>In this paper, we apply various embedding methods on multiword expressions to study how well they capture the nuances of non-compositional data. Our results from a pool of word-, character-, and document-level embbedings suggest that Word2vec performs the best, followed by FastText and Infersent. Moreover, we find that recently-proposed contextualised embedding models such as Bert and ELMo are not adept at handling non-compositionality in multiword expressions.</abstract>
      <url>W19-2004</url>
    </paper>
    <paper id="5">
      <title>Measuring Semantic Abstraction of Multilingual <fixed-case>NMT</fixed-case> with Paraphrase Recognition and Generation Tasks</title>
      <author><first>Jörg</first><last>Tiedemann</last></author>
      <author><first>Yves</first><last>Scherrer</last></author>
      <pages>35–42</pages>
      <abstract>In this paper, we investigate whether multilingual neural translation models learn stronger semantic abstractions of sentences than bilingual ones. We test this hypotheses by measuring the perplexity of such models when applied to paraphrases of the source language. The intuition is that an encoder produces better representations if a decoder is capable of recognizing synonymous sentences in the same language even though the model is never trained for that task. In our setup, we add 16 different auxiliary languages to a bidirectional bilingual baseline model (English-French) and test it with in-domain and out-of-domain paraphrases in English. The results show that the perplexity is significantly reduced in each of the cases, indicating that meaning can be grounded in translation. This is further supported by a study on paraphrase generation that we also include at the end of the paper.</abstract>
      <url>W19-2005</url>
      <attachment type="supplementary">W19-2005.Supplementary.pdf</attachment>
    </paper>
    <paper id="6">
      <title><fixed-case>SWOW</fixed-case>-8500: Word Association task for Intrinsic Evaluation of Word Embeddings</title>
      <author><first>Avijit</first><last>Thawani</last></author>
      <author><first>Biplav</first><last>Srivastava</last></author>
      <author><first>Anil</first><last>Singh</last></author>
      <pages>43–51</pages>
      <abstract>Downstream evaluation of pretrained word embeddings is expensive, more so for tasks where current state of the art models are very large architectures. Intrinsic evaluation using word similarity or analogy datasets, on the other hand, suffers from several disadvantages. We propose a novel intrinsic evaluation task employing large word association datasets (particularly the Small World of Words dataset). We observe correlations not just between performances on SWOW-8500 and previously proposed intrinsic tasks of word similarity prediction, but also with downstream tasks (eg. Text Classification and Natural Language Inference). Most importantly, we report better confidence intervals for scores on our word association task, with no fall in correlation with downstream performance.</abstract>
      <url>W19-2006</url>
      <attachment type="poster">W19-2006.Poster.pdf</attachment>
    </paper>
    <paper id="7">
      <title>Classification of Semantic Paraphasias: Optimization of a Word Embedding Model</title>
      <author><first>Katy</first><last>McKinney-Bock</last></author>
      <author><first>Steven</first><last>Bedrick</last></author>
      <pages>52–62</pages>
      <abstract>In clinical assessment of people with aphasia, impairment in the ability to recall and produce words for objects (anomia) is assessed using a confrontation naming task, where a target stimulus is viewed and a corresponding label is spoken by the participant. Vector space word embedding models have had inital results in assessing semantic similarity of target-production pairs in order to automate scoring of this task; however, the resulting models are also highly dependent upon training parameters. To select an optimal family of models, we fit a beta regression model to the distribution of performance metrics on a set of 2,880 grid search models and evaluate the resultant first- and second-order effects to explore how parameterization affects model performance. Comparing to SimLex-999, we show that clinical data can be used in an evaluation task with comparable optimal parameter settings as standard NLP evaluation datasets.</abstract>
      <url>W19-2007</url>
    </paper>
    <paper id="8">
      <title><fixed-case>CODAH</fixed-case>: An Adversarially-Authored Question Answering Dataset for Common Sense</title>
      <author><first>Michael</first><last>Chen</last></author>
      <author><first>Mike</first><last>D’Arcy</last></author>
      <author><first>Alisa</first><last>Liu</last></author>
      <author><first>Jared</first><last>Fernandez</last></author>
      <author><first>Doug</first><last>Downey</last></author>
      <pages>63–69</pages>
      <abstract>Commonsense reasoning is a critical AI capability, but it is difficult to construct challenging datasets that test common sense. Recent neural question answering systems, based on large pre-trained models of language, have already achieved near-human-level performance on commonsense knowledge benchmarks. These systems do not possess human-level common sense, but are able to exploit limitations of the datasets to achieve human-level scores. We introduce the CODAH dataset, an adversarially-constructed evaluation dataset for testing common sense. CODAH forms a challenging extension to the recently-proposed SWAG dataset, which tests commonsense knowledge using sentence-completion questions that describe situations observed in video. To produce a more difficult dataset, we introduce a novel procedure for question acquisition in which workers author questions designed to target weaknesses of state-of-the-art neural question answering systems. Workers are rewarded for submissions that models fail to answer correctly both before and after fine-tuning (in cross-validation). We create 2.8k questions via this procedure and evaluate the performance of multiple state-of-the-art question answering systems on our dataset. We observe a significant gap between human performance, which is 95.3%, and the performance of the best baseline accuracy of 65.3% by the OpenAI GPT model.</abstract>
      <url>W19-2008</url>
    </paper>
    <paper id="9">
      <title>Syntactic Interchangeability in Word Embedding Models</title>
      <author><first>Daniel</first><last>Hershcovich</last></author>
      <author><first>Assaf</first><last>Toledo</last></author>
      <author><first>Alon</first><last>Halfon</last></author>
      <author><first>Noam</first><last>Slonim</last></author>
      <pages>70–76</pages>
      <abstract>Nearest neighbors in word embedding models are commonly observed to be semantically similar, but the relations between them can vary greatly. We investigate the extent to which word embedding models preserve syntactic interchangeability, as reflected by distances between word vectors, and the effect of hyper-parameters—context window size in particular. We use part of speech (POS) as a proxy for syntactic interchangeability, as generally speaking, words with the same POS are syntactically valid in the same contexts. We also investigate the relationship between interchangeability and similarity as judged by commonly-used word similarity benchmarks, and correlate the result with the performance of word embedding models on these benchmarks. Our results will inform future research and applications in the selection of word embedding model, suggesting a principle for an appropriate selection of the context window size parameter depending on the use-case.</abstract>
      <url>W19-2009</url>
      <software>W19-2009.Software.zip</software>
      <attachment type="poster">W19-2009.Poster.pdf</attachment>
    </paper>
    <paper id="10">
      <title>Evaluation of Morphological Embeddings for <fixed-case>E</fixed-case>nglish and <fixed-case>R</fixed-case>ussian Languages</title>
      <author><first>Vitaly</first><last>Romanov</last></author>
      <author><first>Albina</first><last>Khusainova</last></author>
      <pages>77–81</pages>
      <abstract>This paper evaluates morphology-based embeddings for English and Russian languages. Despite the interest and introduction of several morphology based word embedding models in the past and acclaimed performance improvements on word similarity and language modeling tasks, in our experiments, we did not observe any stable preference over two of our baseline models - SkipGram and FastText. The performance exhibited by morphological embeddings is the average of the two baselines mentioned above.</abstract>
      <url>W19-2010</url>
    </paper>
    <paper id="11">
      <title>Probing Biomedical Embeddings from Language Models</title>
      <author><first>Qiao</first><last>Jin</last></author>
      <author><first>Bhuwan</first><last>Dhingra</last></author>
      <author><first>William</first><last>Cohen</last></author>
      <author><first>Xinghua</first><last>Lu</last></author>
      <pages>82–89</pages>
      <abstract>Contextualized word embeddings derived from pre-trained language models (LMs) show significant improvements on downstream NLP tasks. Pre-training on domain-specific corpora, such as biomedical articles, further improves their performance. In this paper, we conduct probing experiments to determine what additional information is carried intrinsically by the in-domain trained contextualized embeddings. For this we use the pre-trained LMs as fixed feature extractors and restrict the downstream task models to not have additional sequence modeling layers. We compare BERT (Devlin et al. 2018), ELMo (Peters et al., 2018), BioBERT (Lee et al., 2019) and BioELMo, a biomedical version of ELMo trained on 10M PubMed abstracts. Surprisingly, while fine-tuned BioBERT is better than BioELMo in biomedical NER and NLI tasks, as a fixed feature extractor BioELMo outperforms BioBERT in our probing tasks. We use visualization and nearest neighbor analysis to show that better encoding of entity-type and relational information leads to this superiority.</abstract>
      <url>W19-2011</url>
    </paper>
    <paper id="12">
      <title>Dyr Bul Shchyl. Proxying Sound Symbolism With Word Embeddings</title>
      <author><first>Ivan</first><last>Yamshchikov</last></author>
      <author><first>Viascheslav</first><last>Shibaev</last></author>
      <author><first>Alexey</first><last>Tikhonov</last></author>
      <pages>90–94</pages>
      <abstract>This paper explores modern word embeddings in the context of sound symbolism. Using basic properties of the representations space one can construct semantic axes. A method is proposed to measure if the presence of individual sounds in a given word shifts its semantics of that word along a specific axis. It is shown that, in accordance with several experimental and statistical results, word embeddings capture symbolism for certain sounds.</abstract>
      <url>W19-2012</url>
    </paper>
    <paper id="13">
      <title>Multi-Context Term Embeddings: the Use Case of Corpus-based Term Set Expansion</title>
      <author><first>Jonathan</first><last>Mamou</last></author>
      <author><first>Oren</first><last>Pereg</last></author>
      <author><first>Moshe</first><last>Wasserblat</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <pages>95–101</pages>
      <abstract>In this paper, we present a novel algorithm that combines multi-context term embeddings using a neural classifier and we test this approach on the use case of corpus-based term set expansion. In addition, we present a novel and unique dataset for intrinsic evaluation of corpus-based term set expansion algorithms. We show that, over this dataset, our algorithm provides up to 5 mean average precision points over the best baseline.</abstract>
      <url>W19-2013</url>
    </paper>
  </volume>
  <volume id="21">
    <meta>
      <booktitle>Proceedings of the Third Workshop on Natural Language Processing and Computational Social Science</booktitle>
      <url>W19-21</url>
      <editor><first>Svitlana</first><last>Volkova</last></editor>
      <editor><first>David</first><last>Jurgens</last></editor>
      <editor><first>Dirk</first><last>Hovy</last></editor>
      <editor><first>David</first><last>Bamman</last></editor>
      <editor><first>Oren</first><last>Tsur</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-2100</url>
    </frontmatter>
    <paper id="1">
      <title>Not My President: How Names and Titles Frame Political Figures</title>
      <author><first>Esther</first><last>van den Berg</last></author>
      <author><first>Katharina</first><last>Korfhage</last></author>
      <author><first>Josef</first><last>Ruppenhofer</last></author>
      <author><first>Michael</first><last>Wiegand</last></author>
      <author><first>Katja</first><last>Markert</last></author>
      <pages>1–6</pages>
      <abstract>Naming and titling have been discussed in sociolinguistics as markers of status or solidarity. However, these functions have not been studied on a larger scale or for social media data. We collect a corpus of tweets mentioning presidents of six G20 countries by various naming forms. We show that naming variation relates to stance towards the president in a way that is suggestive of a framing effect mediated by respectfulness. This confirms sociolinguistic theory of naming and titling as markers of status.</abstract>
      <url>W19-2101</url>
    </paper>
    <paper id="2">
      <title>Identification, Interpretability, and <fixed-case>B</fixed-case>ayesian Word Embeddings</title>
      <author><first>Adam</first><last>Lauretig</last></author>
      <pages>7–17</pages>
      <abstract>Social scientists have recently turned to analyzing text using tools from natural language processing like word embeddings to measure concepts like ideology, bias, and affinity. However, word embeddings are difficult to use in the regression framework familiar to social scientists: embeddings are are neither identified, nor directly interpretable. I offer two advances on standard embedding models to remedy these problems. First, I develop Bayesian Word Embeddings with Automatic Relevance Determination priors, relaxing the assumption that all embedding dimensions have equal weight. Second, I apply work identifying latent variable models to anchor embeddings, identifying them, and making them interpretable and usable in a regression. I then apply this model and anchoring approach to two cases, the shift in internationalist rhetoric in the American presidents’ inaugural addresses, and the relationship between bellicosity in American foreign policy decision-makers’ deliberations. I find that inaugural addresses became less internationalist after 1945, which goes against the conventional wisdom, and that an increase in bellicosity is associated with an increase in hostile actions by the United States, showing that elite deliberations are not cheap talk, and helping confirm the validity of the model.</abstract>
      <url>W19-2102</url>
    </paper>
    <paper id="3">
      <title>Tweet Classification without the Tweet: An Empirical Examination of User versus Document Attributes</title>
      <author><first>Veronica</first><last>Lynn</last></author>
      <author><first>Salvatore</first><last>Giorgi</last></author>
      <author><first>Niranjan</first><last>Balasubramanian</last></author>
      <author><first>H. Andrew</first><last>Schwartz</last></author>
      <pages>18–28</pages>
      <abstract>NLP naturally puts a primary focus on leveraging document language, occasionally considering user attributes as supplemental. However, as we tackle more social scientific tasks, it is possible user attributes might be of primary importance and the document supplemental. Here, we systematically investigate the predictive power of user-level features alone versus document-level features for document-level tasks. We first show user attributes can sometimes carry more task-related information than the document itself. For example, a tweet-level stance detection model using only 13 user-level attributes (i.e. features that did not depend on the specific tweet) was able to obtain a higher F1 than the top-performing SemEval participant. We then consider multiple tasks and a wider range of user attributes, showing the performance of strong document-only models can often be improved (as in stance, sentiment, and sarcasm) with user attributes, particularly benefiting tasks with stable “trait-like” outcomes (e.g. stance) most relative to frequently changing “state-like” outcomes (e.g. sentiment). These results not only support the growing work on integrating user factors into predictive systems, but that some of our NLP tasks might be better cast primarily as user-level (or human) tasks.</abstract>
      <url>W19-2103</url>
    </paper>
    <paper id="4">
      <title>Geolocating Political Events in Text</title>
      <author><first>Andrew</first><last>Halterman</last></author>
      <pages>29–39</pages>
      <abstract>This work introduces a general method for automatically finding the locations where political events in text occurred. Using a novel set of 8,000 labeled sentences, I create a method to link automatically extracted events and locations in text. The model achieves human level performance on the annotation task and outperforms previous event geolocation systems. It can be applied to most event extraction systems across geographic contexts. I formalize the event–location linking task, describe the neural network model, describe the potential uses of such a system in political science, and demonstrate a workflow to answer an open question on the role of conventional military offensives in causing civilian casualties in the Syrian civil war.</abstract>
      <url>W19-2104</url>
    </paper>
    <paper id="5">
      <title>Neural Network Prediction of Censorable Language</title>
      <author><first>Kei Yin</first><last>Ng</last></author>
      <author><first>Anna</first><last>Feldman</last></author>
      <author><first>Jing</first><last>Peng</last></author>
      <author><first>Chris</first><last>Leberknight</last></author>
      <pages>40–46</pages>
      <abstract>Internet censorship imposes restrictions on what information can be publicized or viewed on the Internet. According to Freedom House’s annual Freedom on the Net report, more than half the world’s Internet users now live in a place where the Internet is censored or restricted. China has built the world’s most extensive and sophisticated online censorship system. In this paper, we describe a new corpus of censored and uncensored social media tweets from a Chinese microblogging website, Sina Weibo, collected by tracking posts that mention ‘sensitive’ topics or authored by ‘sensitive’ users. We use this corpus to build a neural network classifier to predict censorship. Our model performs with a 88.50% accuracy using only linguistic features. We discuss these features in detail and hypothesize that they could potentially be used for censorship circumvention.</abstract>
      <url>W19-2105</url>
    </paper>
    <paper id="6">
      <title>Modeling performance differences on cognitive tests using <fixed-case>LSTM</fixed-case>s and skip-thought vectors trained on reported media consumption.</title>
      <author><first>Maury</first><last>Courtland</last></author>
      <author><first>Aida</first><last>Davani</last></author>
      <author><first>Melissa</first><last>Reyes</last></author>
      <author><first>Leigh</first><last>Yeh</last></author>
      <author><first>Jun</first><last>Leung</last></author>
      <author><first>Brendan</first><last>Kennedy</last></author>
      <author><first>Morteza</first><last>Dehghani</last></author>
      <author><first>Jason</first><last>Zevin</last></author>
      <pages>47–53</pages>
      <abstract>Cognitive tests have traditionally resorted to standardizing testing materials in the name of equality and because of the onerous nature of creating test items. This approach ignores participants’ diverse language experiences that potentially significantly affect testing outcomes. Here, we seek to explain our prior finding of significant performance differences on two cognitive tests (reading span and SPiN) between clusters of participants based on their media consumption. Here, we model the language contained in these media sources using an LSTM trained on corpora of each cluster’s media sources to predict target words. We also model semantic similarity of test items with each cluster’s corpus using skip-thought vectors. We find robust, significant correlations between performance on the SPiN test and the LSTMs and skip-thought models we present here, but not the reading span test.</abstract>
      <url>W19-2106</url>
    </paper>
    <paper id="7">
      <title>Using time series and natural language processing to identify viral moments in the 2016 <fixed-case>U</fixed-case>.<fixed-case>S</fixed-case>. Presidential Debate</title>
      <author><first>Josephine</first><last>Lukito</last></author>
      <author><first>Prathusha</first><last>K Sarma</last></author>
      <author><first>Jordan</first><last>Foley</last></author>
      <author><first>Aman</first><last>Abhishek</last></author>
      <pages>54–64</pages>
      <abstract>This paper proposes a method for identifying and studying viral moments or highlights during a political debate. Using a combined strategy of time series analysis and domain adapted word embeddings, this study provides an in-depth analysis of several key moments during the 2016 U.S. Presidential election. First, a time series outlier analysis is used to identify key moments during the debate. These moments had to result in a long-term shift in attention towards either Hillary Clinton or Donald Trump (i.e., a transient change outlier or an intervention, resulting in a permanent change in the time series). To assess whether these moments also resulted in a discursive shift, two corpora are produced for each potential viral moment (a pre-viral corpus and post-viral corpus). A domain adaptation layer learns weights to combine a generic and domain-specific (DS) word embedding into a domain adapted (DA) embedding. Words are then classified using a generic encoder+ classifier framework that relies on these word embeddings as inputs. Results suggest that both Clinton and Trump were able to induce discourse-shifting viral moments, though the former is much better at producing a topically-specific discursive shift.</abstract>
      <url>W19-2107</url>
    </paper>
    <paper id="8">
      <title>Stance Classification, Outcome Prediction, and Impact Assessment: <fixed-case>NLP</fixed-case> Tasks for Studying Group Decision-Making</title>
      <author><first>Elijah</first><last>Mayfield</last></author>
      <author><first>Alan</first><last>Black</last></author>
      <pages>65–77</pages>
      <abstract>In group decision-making, the nuanced process of conflict and resolution that leads to consensus formation is closely tied to the quality of decisions made. Behavioral scientists rarely have rich access to process variables, though, as unstructured discussion transcripts are difficult to analyze. Here, we define ways for NLP researchers to contribute to the study of groups and teams. We introduce three tasks alongside a large new corpus of over 400,000 group debates on Wikipedia. We describe the tasks and their importance, then provide baselines showing that BERT contextualized word embeddings consistently outperform other language representations.</abstract>
      <url>W19-2108</url>
    </paper>
    <paper id="9">
      <title>A Sociolinguistic Study of Online Echo Chambers on Twitter</title>
      <author><first>Nikita</first><last>Duseja</last></author>
      <author><first>Harsh</first><last>Jhamtani</last></author>
      <pages>78–83</pages>
      <abstract>Online social media platforms such as Facebook and Twitter are increasingly facing criticism for polarization of users. One particular aspect which has caught the attention of various critics is presence of users in echo chambers - a situation wherein users are exposed mostly to the opinions which are in sync with their own views. In this paper, we perform a sociolinguistic study by comparing the tweets of users in echo chambers with the tweets of users not in echo chambers with similar levels of polarity on a broad topic. Specifically, we carry out a comparative analysis of tweet structure, lexical choices, and focus issues, and provide possible explanations for the results.</abstract>
      <url>W19-2109</url>
    </paper>
    <paper id="10">
      <title>Uphill from here: Sentiment patterns in videos from left- and right-wing <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube news channels</title>
      <author><first>Felix</first><last>Soldner</last></author>
      <author><first>Justin Chun-ting</first><last>Ho</last></author>
      <author><first>Mykola</first><last>Makhortykh</last></author>
      <author><first>Isabelle W.J.</first><last>van der Vegt</last></author>
      <author><first>Maximilian</first><last>Mozes</last></author>
      <author><first>Bennett</first><last>Kleinberg</last></author>
      <pages>84–93</pages>
      <abstract>News consumption exhibits an increasing shift towards online sources, which bring platforms such as YouTube more into focus. Thus, the distribution of politically loaded news is easier, receives more attention, but also raises the concern of forming isolated ideological communities. Understanding how such news is communicated and received is becoming increasingly important. To expand our understanding in this domain, we apply a linguistic temporal trajectory analysis to analyze sentiment patterns in English-language videos from news channels on YouTube. We examine transcripts from videos distributed through eight channels with pro-left and pro-right political leanings. Using unsupervised clustering, we identify seven different sentiment patterns in the transcripts. We found that the use of two sentiment patterns differed significantly depending on political leaning. Furthermore, we used predictive models to examine how different sentiment patterns relate to video popularity and if they differ depending on the channel’s political leaning. No clear relations between sentiment patterns and popularity were found. However, results indicate, that videos from pro-right news channels are more popular and that a negative sentiment further increases that popularity, when sentiments are averaged for each video.</abstract>
      <url>W19-2110</url>
    </paper>
    <paper id="11">
      <title>Simple dynamic word embeddings for mapping perceptions in the public sphere</title>
      <author><first>Nabeel</first><last>Gillani</last></author>
      <author><first>Roger</first><last>Levy</last></author>
      <pages>94–99</pages>
      <abstract>Word embeddings trained on large-scale historical corpora can illuminate human biases and stereotypes that perpetuate social inequalities. These embeddings are often trained in separate vector space models defined according to different attributes of interest. In this paper, we introduce a single, unified dynamic embedding model that learns attribute-specific word embeddings and apply it to a novel dataset—talk radio shows from around the US—to analyze perceptions about refugees. We validate our model on a benchmark dataset and apply it to two corpora of talk radio shows averaging 117 million words produced over one month across 83 stations and 64 cities. Our findings suggest that dynamic word embeddings are capable of identifying nuanced differences in public discourse about contentious topics, suggesting their usefulness as a tool for better understanding how the public perceives and engages with different issues across time, geography, and other dimensions.</abstract>
      <url>W19-2111</url>
    </paper>
    <paper id="12">
      <title>Modeling Behavioral Aspects of Social Media Discourse for Moral Classification</title>
      <author><first>Kristen</first><last>Johnson</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <pages>100–109</pages>
      <abstract>Political discourse on social media microblogs, specifically Twitter, has become an undeniable part of mainstream U.S. politics. Given the length constraint of tweets, politicians must carefully word their statements to ensure their message is understood by their intended audience. This constraint often eliminates the context of the tweet, making automatic analysis of social media political discourse a difficult task. To overcome this challenge, we propose simultaneous modeling of high-level abstractions of political language, such as political slogans and framing strategies, with abstractions of how politicians behave on Twitter. These behavioral abstractions can be further leveraged as forms of supervision in order to increase prediction accuracy, while reducing the burden of annotation. In this work, we use Probabilistic Soft Logic (PSL) to build relational models to capture the similarities in language and behavior that obfuscate political messages on Twitter. When combined, these descriptors reveal the moral foundations underlying the discourse of U.S. politicians online, <i>across</i> differing governing administrations, showing how party talking points remain cohesive or change over time.</abstract>
      <url>W19-2112</url>
    </paper>
  </volume>
  <volume id="22">
    <meta>
      <booktitle>Proceedings of the Natural Legal Language Processing Workshop 2019</booktitle>
      <url>W19-22</url>
      <editor><first>Nikolaos</first><last>Aletras</last></editor>
      <editor><first>Elliott</first><last>Ash</last></editor>
      <editor><first>Leslie</first><last>Barrett</last></editor>
      <editor><first>Daniel</first><last>Chen</last></editor>
      <editor><first>Adam</first><last>Meyers</last></editor>
      <editor><first>Daniel</first><last>Preotiuc-Pietro</last></editor>
      <editor><first>David</first><last>Rosenberg</last></editor>
      <editor><first>Amanda</first><last>Stent</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-2200</url>
    </frontmatter>
    <paper id="1">
      <title>Plain <fixed-case>E</fixed-case>nglish Summarization of Contracts</title>
      <author><first>Laura</first><last>Manor</last></author>
      <author><first>Junyi Jessy</first><last>Li</last></author>
      <pages>1–11</pages>
      <abstract>Unilateral legal contracts, such as terms of service, play a substantial role in modern digital life. However, few read these documents before accepting the terms within, as they are too long and the language too complicated. We propose the task of summarizing such legal documents in plain English, which would enable users to have a better understanding of the terms they are accepting. We propose an initial dataset of legal text snippets paired with summaries written in plain English. We verify the quality of these summaries manually, and show that they involve heavy abstraction, compression, and simplification. Initial experiments show that unsupervised extractive summarization methods do not perform well on this task due to the level of abstraction and style differences. We conclude with a call for resource and technique development for simplification and style transfer for legal language.</abstract>
      <url>W19-2201</url>
      <attachment type="supplementary">W19-2201.Supplementary.pdf</attachment>
    </paper>
    <paper id="2">
      <title>Scalable Methods for Annotating Legal-Decision Corpora</title>
      <author><first>Lisa</first><last>Ferro</last></author>
      <author><first>John</first><last>Aberdeen</last></author>
      <author><first>Karl</first><last>Branting</last></author>
      <author><first>Craig</first><last>Pfeifer</last></author>
      <author><first>Alexander</first><last>Yeh</last></author>
      <author><first>Amartya</first><last>Chakraborty</last></author>
      <pages>12–20</pages>
      <abstract>Recent research has demonstrated that judicial and administrative decisions can be predicted by machine-learning models trained on prior decisions. However, to have any practical application, these predictions must be explainable, which in turn requires modeling a rich set of features. Such approaches face a roadblock if the knowledge engineering required to create these features is not scalable. We present an approach to developing a feature-rich corpus of administrative rulings about domain name disputes, an approach which leverages a small amount of manual annotation and prototypical patterns present in the case documents to automatically extend feature labels to the entire corpus. To demonstrate the feasibility of this approach, we report results from systems trained on this dataset.</abstract>
      <url>W19-2202</url>
    </paper>
    <paper id="3">
      <title>The Extent of Repetition in Contract Language</title>
      <author><first>Dan</first><last>Simonson</last></author>
      <author><first>Daniel</first><last>Broderick</last></author>
      <author><first>Jonathan</first><last>Herr</last></author>
      <pages>21–30</pages>
      <abstract>Contract language is repetitive (Anderson and Manns, 2017), but so is all language (Zipf, 1949). In this paper, we measure the extent to which contract language in English is repetitive compared with the language of other English language corpora. Contracts have much smaller vocabulary sizes compared with similarly sized non-contract corpora across multiple contract types, contain 1/5th as many hapax legomena, pattern differently on a log-log plot, use fewer pronouns, and contain sentences that are about 20% more similar to one another than in other corpora. These suggest that the study of contracts in natural language processing controls for some linguistic phenomena and allows for more in depth study of others.</abstract>
      <url>W19-2203</url>
    </paper>
    <paper id="4">
      <title>Sentence Boundary Detection in Legal Text</title>
      <author><first>George</first><last>Sanchez</last></author>
      <pages>31–38</pages>
      <abstract>In this paper, we examined several algorithms to detect sentence boundaries in legal text. Legal text presents challenges for sentence tokenizers because of the variety of punctuations and syntax of legal text. Out-of-the-box algorithms perform poorly on legal text affecting further analysis of the text. A novel and domain-specific approach is needed to detect sentence boundaries to further analyze legal text. We present the results of our investigation in this paper.</abstract>
      <url>W19-2204</url>
    </paper>
    <paper id="5">
      <title>Legal Linking: Citation Resolution and Suggestion in Constitutional Law</title>
      <author><first>Robert</first><last>Shaffer</last></author>
      <author><first>Stephen</first><last>Mayhew</last></author>
      <pages>39–44</pages>
      <abstract>This paper describes a dataset and baseline systems for linking paragraphs from court cases to clauses or amendments in the US Constitution. We implement a rule-based system, a linear model, and a neural architecture for matching pairs of paragraphs, taking training data from online databases in a distantly-supervised fashion. In experiments on a manually-annotated evaluation set, we find that our proposed neural system outperforms a rules-driven baseline. Qualitatively, this performance gap seems largest for abstract or indirect links between documents, which suggests that our system might be useful for answering political science and legal research questions or discovering novel links. We release the dataset along with the manually-annotated evaluation set to foster future work.</abstract>
      <url>W19-2205</url>
    </paper>
    <paper id="6">
      <title>Litigation Analytics: Case Outcomes Extracted from <fixed-case>US</fixed-case> Federal Court Dockets</title>
      <author><first>Thomas</first><last>Vacek</last></author>
      <author><first>Ronald</first><last>Teo</last></author>
      <author><first>Dezhao</first><last>Song</last></author>
      <author><first>Timothy</first><last>Nugent</last></author>
      <author><first>Conner</first><last>Cowling</last></author>
      <author><first>Frank</first><last>Schilder</last></author>
      <pages>45–54</pages>
      <abstract>Dockets contain a wealth of information for planning a litigation strategy, but the information is locked up in semi-structured text. Manually deriving the outcomes for each party (e.g., settlement, verdict) would be very labor intensive. Having such information available for every past court case, however, would be very useful for developing a strategy because it potentially reveals tendencies and trends of judges and courts and the opposing counsel. We used Natural Language Processing (NLP) techniques and deep learning methods allowing us to scale the automatic analysis of millions of US federal court dockets. The automatically extracted information is fed into a Litigation Analytics tool that is used by lawyers to plan how they approach concrete litigations.</abstract>
      <url>W19-2206</url>
    </paper>
    <paper id="7">
      <title>Developing and Orchestrating a Portfolio of Natural Legal Language Processing and Document Curation Services</title>
      <author><first>Georg</first><last>Rehm</last></author>
      <author><first>Julián</first><last>Moreno-Schneider</last></author>
      <author><first>Jorge</first><last>Gracia</last></author>
      <author><first>Artem</first><last>Revenko</last></author>
      <author><first>Victor</first><last>Mireles</last></author>
      <author><first>Maria</first><last>Khvalchik</last></author>
      <author><first>Ilan</first><last>Kernerman</last></author>
      <author><first>Andis</first><last>Lagzdins</last></author>
      <author><first>Marcis</first><last>Pinnis</last></author>
      <author><first>Artus</first><last>Vasilevskis</last></author>
      <author><first>Elena</first><last>Leitner</last></author>
      <author><first>Jan</first><last>Milde</last></author>
      <author><first>Pia</first><last>Weißenhorn</last></author>
      <pages>55–66</pages>
      <abstract>We present a portfolio of natural legal language processing and document curation services currently under development in a collaborative European project. First, we give an overview of the project and the different use cases, while, in the main part of the article, we focus upon the 13 different processing services that are being deployed in different prototype applications using a flexible and scalable microservices architecture. Their orchestration is operationalised using a content and document curation workflow manager.</abstract>
      <url>W19-2207</url>
    </paper>
    <paper id="8">
      <title>Legal Area Classification: A Comparative Study of Text Classifiers on Singapore Supreme Court Judgments</title>
      <author><first>Jerrold</first><last>Soh</last></author>
      <author><first>How Khang</first><last>Lim</last></author>
      <author><first>Ian Ernst</first><last>Chai</last></author>
      <pages>67–77</pages>
      <abstract>This paper conducts a comparative study on the performance of various machine learning approaches for classifying judgments into legal areas. Using a novel dataset of 6,227 Singapore Supreme Court judgments, we investigate how state-of-the-art NLP methods compare against traditional statistical models when applied to a legal corpus that comprised few but lengthy documents. All approaches tested, including topic model, word embedding, and language model-based classifiers, performed well with as little as a few hundred judgments. However, more work needs to be done to optimize state-of-the-art methods for the legal domain.</abstract>
      <url>W19-2208</url>
    </paper>
    <paper id="9">
      <title>Extreme Multi-Label Legal Text Classification: A Case Study in <fixed-case>EU</fixed-case> Legislation</title>
      <author><first>Ilias</first><last>Chalkidis</last></author>
      <author><first>Emmanouil</first><last>Fergadiotis</last></author>
      <author><first>Prodromos</first><last>Malakasiotis</last></author>
      <author><first>Nikolaos</first><last>Aletras</last></author>
      <author><first>Ion</first><last>Androutsopoulos</last></author>
      <pages>78–87</pages>
      <abstract>We consider the task of Extreme Multi-Label Text Classification (XMTC) in the legal domain. We release a new dataset of 57k legislative documents from EURLEX, the European Union’s public document database, annotated with concepts from EUROVOC, a multidisciplinary thesaurus. The dataset is substantially larger than previous EURLEX datasets and suitable for XMTC, few-shot and zero-shot learning. Experimenting with several neural classifiers, we show that BIGRUs with self-attention outperform the current multi-label state-of-the-art methods, which employ label-wise attention. Replacing CNNs with BIGRUs in label-wise attention networks leads to the best overall performance.</abstract>
      <url>W19-2209</url>
    </paper>
  </volume>
  <volume id="23">
    <meta>
      <booktitle>Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation</booktitle>
      <url>W19-23</url>
      <editor><first>Antoine</first><last>Bosselut</last></editor>
      <editor><first>Asli</first><last>Celikyilmaz</last></editor>
      <editor><first>Marjan</first><last>Ghazvininejad</last></editor>
      <editor><first>Srinivasan</first><last>Iyer</last></editor>
      <editor><first>Urvashi</first><last>Khandelwal</last></editor>
      <editor><first>Hannah</first><last>Rashkin</last></editor>
      <editor><first>Thomas</first><last>Wolf</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-2300</url>
    </frontmatter>
    <paper id="1">
      <title>An Adversarial Learning Framework For A Persona-Based Multi-Turn Dialogue Model</title>
      <author><first>Oluwatobi</first><last>Olabiyi</last></author>
      <author><first>Anish</first><last>Khazane</last></author>
      <author><first>Alan</first><last>Salimov</last></author>
      <author><first>Erik</first><last>Mueller</last></author>
      <pages>1–10</pages>
      <abstract>In this paper, we extend the persona-based sequence-to-sequence (Seq2Seq) neural network conversation model to a multi-turn dialogue scenario by modifying the state-of-the- art hredGAN architecture to simultaneously capture utterance attributes such as speaker identity, dialogue topic, speaker sentiments and so on. The proposed system, phredGAN has a persona-based HRED generator (PHRED) and a conditional discriminator. We also explore two approaches to accomplish the conditional discriminator: (1) phredGANa, a system that passes the attribute representation as an additional input into a traditional adversarial discriminator, and (2) phredGANd, a dual discriminator system which in addition to the adversarial discriminator, collaboratively predicts the attribute(s) that generated the input utterance. To demonstrate the superior performance of phredGAN over the persona Seq2Seq model, we experiment with two conversational datasets, the Ubuntu Dialogue Corpus (UDC) and TV series transcripts from the Big Bang Theory and Friends. Performance comparison is made with respect to a variety of quantitative measures as well as crowd-sourced human evaluation. We also explore the trade-offs from using either variant of phredGAN on datasets with many but weak attribute modalities (such as with Big Bang Theory and Friends) and ones with few but strong attribute modalities (customer-agent interactions in Ubuntu dataset).</abstract>
      <url>W19-2301</url>
    </paper>
    <paper id="2">
      <title><fixed-case>DAL</fixed-case>: Dual Adversarial Learning for Dialogue Generation</title>
      <author><first>Shaobo</first><last>Cui</last></author>
      <author><first>Rongzhong</first><last>Lian</last></author>
      <author><first>Di</first><last>Jiang</last></author>
      <author><first>Yuanfeng</first><last>Song</last></author>
      <author><first>Siqi</first><last>Bao</last></author>
      <author><first>Yong</first><last>Jiang</last></author>
      <pages>11–20</pages>
      <abstract>In open-domain dialogue systems, generative approaches have attracted much attention for response generation. However, existing methods are heavily plagued by generating safe responses and unnatural responses. To alleviate these two problems, we propose a novel framework named Dual Adversarial Learning(DAL) for high-quality response generation. DAL innovatively utilizes the duality between query generation and response generation to avoid safe responses and increase the diversity of the generated responses. Additionally, DAL uses adversarial learning to mimic human judges and guides the system to generate natural responses. Experimental results demonstrate that DAL effectively improves both diversity and overall quality of the generated responses. DAL outperforms state-of-the-art methods regarding automatic metrics and human evaluations.</abstract>
      <url>W19-2302</url>
    </paper>
    <paper id="3">
      <title>How to Compare Summarizers without Target Length? Pitfalls, Solutions and Re-Examination of the Neural Summarization Literature</title>
      <author><first>Simeng</first><last>Sun</last></author>
      <author><first>Ori</first><last>Shapira</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <author><first>Ani</first><last>Nenkova</last></author>
      <pages>21–29</pages>
      <abstract>We show that plain ROUGE F1 scores are not ideal for comparing current neural systems which on average produce different lengths. This is due to a non-linear pattern between ROUGE F1 and summary length. To alleviate the effect of length during evaluation, we have proposed a new method which normalizes the ROUGE F1 scores of a system by that of a random system with same average output length. A pilot human evaluation has shown that humans prefer short summaries in terms of the verbosity of a summary but overall consider longer summaries to be of higher quality. While human evaluations are more expensive in time and resources, it is clear that normalization, such as the one we proposed for automatic evaluation, will make human evaluations more meaningful.</abstract>
      <url>W19-2303</url>
    </paper>
    <paper id="4">
      <title><fixed-case>BERT</fixed-case> has a Mouth, and It Must Speak: <fixed-case>BERT</fixed-case> as a <fixed-case>M</fixed-case>arkov Random Field Language Model</title>
      <author><first>Alex</first><last>Wang</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <pages>30–36</pages>
      <abstract>We show that BERT (Devlin et al., 2018) is a Markov random field language model. This formulation gives way to a natural procedure to sample sentences from BERT. We generate from BERT and find that it can produce high quality, fluent generations. Compared to the generations of a traditional left-to-right language model, BERT generates sentences that are more diverse but of slightly worse quality.</abstract>
      <url>W19-2304</url>
    </paper>
    <paper id="5">
      <title>Neural Text Simplification in Low-Resource Conditions Using Weak Supervision</title>
      <author><first>Alessio</first><last>Palmero Aprosio</last></author>
      <author><first>Sara</first><last>Tonelli</last></author>
      <author><first>Marco</first><last>Turchi</last></author>
      <author><first>Matteo</first><last>Negri</last></author>
      <author><first>Mattia A.</first><last>Di Gangi</last></author>
      <pages>37–44</pages>
      <abstract>Neural text simplification has gained increasing attention in the NLP community thanks to recent advancements in deep sequence-to-sequence learning. Most recent efforts with such a data-demanding paradigm have dealt with the English language, for which sizeable training datasets are currently available to deploy competitive models. Similar improvements on less resource-rich languages are conditioned either to intensive manual work to create training data, or to the design of effective automatic generation techniques to bypass the data acquisition bottleneck. Inspired by the machine translation field, in which synthetic parallel pairs generated from monolingual data yield significant improvements to neural models, in this paper we exploit large amounts of heterogeneous data to automatically select simple sentences, which are then used to create synthetic simplification pairs. We also evaluate other solutions, such as oversampling and the use of external word embeddings to be fed to the neural simplification system. Our approach is evaluated on Italian and Spanish, for which few thousand gold sentence pairs are available. The results show that these techniques yield performance improvements over a baseline sequence-to-sequence configuration.</abstract>
      <url>W19-2305</url>
    </paper>
    <paper id="6">
      <title>Paraphrase Generation for Semi-Supervised Learning in <fixed-case>NLU</fixed-case></title>
      <author><first>Eunah</first><last>Cho</last></author>
      <author><first>He</first><last>Xie</last></author>
      <author><first>William M.</first><last>Campbell</last></author>
      <pages>45–54</pages>
      <abstract>Semi-supervised learning is an efficient way to improve performance for natural language processing systems. In this work, we propose Para-SSL, a scheme to generate candidate utterances using paraphrasing and methods from semi-supervised learning. In order to perform paraphrase generation in the context of a dialog system, we automatically extract paraphrase pairs to create a paraphrase corpus. Using this data, we build a paraphrase generation system and perform one-to-many generation, followed by a validation step to select only the utterances with good quality. The paraphrase-based semi-supervised learning is applied to five functionalities in a natural language understanding system. Our proposed method for semi-supervised learning using paraphrase generation does not require user utterances and can be applied prior to releasing a new functionality to a system. Experiments show that we can achieve up to 19% of relative slot error reduction without an access to user utterances, and up to 35% when leveraging live traffic utterances.</abstract>
      <url>W19-2306</url>
    </paper>
    <paper id="7">
      <title>Bilingual-<fixed-case>GAN</fixed-case>: A Step Towards Parallel Text Generation</title>
      <author><first>Ahmad</first><last>Rashid</last></author>
      <author><first>Alan</first><last>Do-Omri</last></author>
      <author><first>Md. Akmal</first><last>Haidar</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <author><first>Mehdi</first><last>Rezagholizadeh</last></author>
      <pages>55–64</pages>
      <abstract>Latent space based GAN methods and attention based sequence to sequence models have achieved impressive results in text generation and unsupervised machine translation respectively. Leveraging the two domains, we propose an adversarial latent space based model capable of generating parallel sentences in two languages concurrently and translating bidirectionally. The bilingual generation goal is achieved by sampling from the latent space that is shared between both languages. First two denoising autoencoders are trained, with shared encoders and back-translation to enforce a shared latent state between the two languages. The decoder is shared for the two translation directions. Next, a GAN is trained to generate synthetic ‘code’ mimicking the languages’ shared latent space. This code is then fed into the decoder to generate text in either language. We perform our experiments on Europarl and Multi30k datasets, on the English-French language pair, and document our performance using both supervised and unsupervised machine translation.</abstract>
      <url>W19-2307</url>
    </paper>
    <paper id="8">
      <title>Designing a Symbolic Intermediate Representation for Neural Surface Realization</title>
      <author><first>Henry</first><last>Elder</last></author>
      <author><first>Jennifer</first><last>Foster</last></author>
      <author><first>James</first><last>Barry</last></author>
      <author><first>Alexander</first><last>O’Connor</last></author>
      <pages>65–73</pages>
      <abstract>Generated output from neural NLG systems often contain errors such as hallucination, repetition or contradiction. This work focuses on designing a symbolic intermediate representation to be used in multi-stage neural generation with the intention of reducing the frequency of failed outputs. We show that surface realization from this intermediate representation is of high quality and when the full system is applied to the E2E dataset it outperforms the winner of the E2E challenge. Furthermore, by breaking out the surface realization step from typically end-to-end neural systems, we also provide a framework for non-neural based content selection and planning systems to potentially take advantage of semi-supervised pretraining of neural surface realization models.</abstract>
      <url>W19-2308</url>
    </paper>
    <paper id="9">
      <title>Neural Text Style Transfer via Denoising and Reranking</title>
      <author><first>Joseph</first><last>Lee</last></author>
      <author><first>Ziang</first><last>Xie</last></author>
      <author><first>Cindy</first><last>Wang</last></author>
      <author><first>Max</first><last>Drach</last></author>
      <author><first>Dan</first><last>Jurafsky</last></author>
      <author><first>Andrew</first><last>Ng</last></author>
      <pages>74–81</pages>
      <abstract>We introduce a simple method for text style transfer that frames style transfer as denoising: we synthesize a noisy corpus and treat the source style as a noisy version of the target style. To control for aspects such as preserving meaning while modifying style, we propose a reranking approach in the data synthesis phase. We evaluate our method on three novel style transfer tasks: transferring between British and American varieties, text genres (formal vs. casual), and lyrics from different musical genres. By measuring style transfer quality, meaning preservation, and the fluency of generated outputs, we demonstrate that our method is able both to produce high-quality output while maintaining the flexibility to suggest syntactically rich stylistic edits.</abstract>
      <url>W19-2309</url>
    </paper>
    <paper id="10">
      <title>Better Automatic Evaluation of Open-Domain Dialogue Systems with Contextualized Embeddings</title>
      <author><first>Sarik</first><last>Ghazarian</last></author>
      <author><first>Johnny</first><last>Wei</last></author>
      <author><first>Aram</first><last>Galstyan</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <pages>82–89</pages>
      <abstract>Despite advances in open-domain dialogue systems, automatic evaluation of such systems is still a challenging problem. Traditional reference-based metrics such as BLEU are ineffective because there could be many valid responses for a given context that share no common words with reference responses. A recent work proposed Referenced metric and Unreferenced metric Blended Evaluation Routine (RUBER) to combine a learning-based metric, which predicts relatedness between a generated response and a given query, with reference-based metric; it showed high correlation with human judgments. In this paper, we explore using contextualized word embeddings to compute more accurate relatedness scores, thus better evaluation metrics. Experiments show that our evaluation metrics outperform RUBER, which is trained on static embeddings.</abstract>
      <url>W19-2310</url>
    </paper>
    <paper id="11">
      <title>Jointly Measuring Diversity and Quality in Text Generation Models</title>
      <author><first>Danial</first><last>Alihosseini</last></author>
      <author><first>Ehsan</first><last>Montahaei</last></author>
      <author><first>Mahdieh</first><last>Soleymani Baghshah</last></author>
      <pages>90–98</pages>
      <abstract>Text generation is an important Natural Language Processing task with various applications. Although several metrics have already been introduced to evaluate the text generation methods, each of them has its own shortcomings. The most widely used metrics such as BLEU only consider the quality of generated sentences and neglecting their diversity. For example, repeatedly generation of only one high quality sentence would result in a high BLEU score. On the other hand, the more recent metric introduced to evaluate the diversity of generated texts known as Self-BLEU ignores the quality of generated texts. In this paper, we propose metrics to evaluate both the quality and diversity simultaneously by approximating the distance of the learned generative model and the real data distribution. For this purpose, we first introduce a metric that approximates this distance using n-gram based measures. Then, a feature-based measure which is based on a recent highly deep model trained on a large text corpus called BERT is introduced. Finally, for oracle training mode in which the generatorʼs density can also be calculated, we propose to use the distance measures between the corresponding explicit distributions. Eventually, the most popular and recent text generation models are evaluated using both the existing and the proposed metrics and the preferences of the proposed metrics are determined.</abstract>
      <url>W19-2311</url>
    </paper>
  </volume>
  <volume id="24">
    <meta>
      <booktitle>Proceedings of the First Workshop on Narrative Understanding</booktitle>
      <url>W19-24</url>
      <editor><first>David</first><last>Bamman</last></editor>
      <editor><first>Snigdha</first><last>Chaturvedi</last></editor>
      <editor><first>Elizabeth</first><last>Clark</last></editor>
      <editor><first>Madalina</first><last>Fiterau</last></editor>
      <editor><first>Mohit</first><last>Iyyer</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-2400</url>
    </frontmatter>
    <paper id="1">
      <title>Towards Coherent and Cohesive Long-form Text Generation</title>
      <author><first>Woon Sang</first><last>Cho</last></author>
      <author><first>Pengchuan</first><last>Zhang</last></author>
      <author><first>Yizhe</first><last>Zhang</last></author>
      <author><first>Xiujun</first><last>Li</last></author>
      <author><first>Michel</first><last>Galley</last></author>
      <author><first>Chris</first><last>Brockett</last></author>
      <author><first>Mengdi</first><last>Wang</last></author>
      <author><first>Jianfeng</first><last>Gao</last></author>
      <pages>1–11</pages>
      <abstract>Generating coherent and cohesive long-form texts is a challenging task. Previous works relied on large amounts of human-generated texts to train neural language models. However, few attempted to explicitly improve neural language models from the perspectives of coherence and cohesion. In this work, we propose a new neural language model that is equipped with two neural discriminators which provide feedback signals at the levels of sentence (cohesion) and paragraph (coherence). Our model is trained using a simple yet efficient variant of policy gradient, called ‘negative-critical sequence training’, which is proposed to eliminate the need of training a separate critic for estimating ‘baseline’. Results demonstrate the effectiveness of our approach, showing improvements over the strong baseline – recurrent attention-based bidirectional MLE-trained neural language model.</abstract>
      <url>W19-2401</url>
      <attachment type="supplementary">W19-2401.Supplementary.pdf</attachment>
    </paper>
    <paper id="2">
      <title>Character Identification Refined: A Proposal</title>
      <author><first>Labiba</first><last>Jahan</last></author>
      <author><first>Mark</first><last>Finlayson</last></author>
      <pages>12–18</pages>
      <abstract>Characters are a key element of narrative and so character identification plays an important role in automatic narrative understanding. Unfortunately, most prior work that incorporates character identification is not built upon a clear, theoretically grounded concept of character. They either take character identification for granted (e.g., using simple heuristics on referring expressions), or rely on simplified definitions that do not capture important distinctions between characters and other referents in the story. Prior approaches have also been rather complicated, relying, for example, on predefined case bases or ontologies. In this paper we propose a narratologically grounded definition of character for discussion at the workshop, and also demonstrate a preliminary yet straightforward supervised machine learning model with a small set of features that performs well on two corpora. The most important of the two corpora is a set of 46 Russian folktales, on which the model achieves an F1 of 0.81. Error analysis suggests that features relevant to the plot will be necessary for further improvements in performance.</abstract>
      <url>W19-2402</url>
    </paper>
    <paper id="3">
      <title>Deep Natural Language Understanding of News Text</title>
      <author><first>Jaya</first><last>Shree</last></author>
      <author><first>Emily</first><last>Liu</last></author>
      <author><first>Andrew</first><last>Gordon</last></author>
      <author><first>Jerry</first><last>Hobbs</last></author>
      <pages>19–27</pages>
      <abstract>Early proposals for the deep understanding of natural language text advocated an approach of “interpretation as abduction,” where the meaning of a text was derived as an explanation that logically entailed the input words, given a knowledge base of lexical and commonsense axioms. While most subsequent NLP research has instead pursued statistical and data-driven methods, the approach of interpretation as abduction has seen steady advancements in both theory and software implementations. In this paper, we summarize advances in deriving the logical form of the text, encoding commonsense knowledge, and technologies for scalable abductive reasoning. We then explore the application of these advancements to the deep understanding of a paragraph of news text, where the subtle meaning of words and phrases are resolved by backward chaining on a knowledge base of 80 hand-authored axioms.</abstract>
      <url>W19-2403</url>
    </paper>
    <paper id="4">
      <title>Extraction of Message Sequence Charts from Narrative History Text</title>
      <author><first>Girish</first><last>Palshikar</last></author>
      <author><first>Sachin</first><last>Pawar</last></author>
      <author><first>Sangameshwar</first><last>Patil</last></author>
      <author><first>Swapnil</first><last>Hingmire</last></author>
      <author><first>Nitin</first><last>Ramrakhiyani</last></author>
      <author><first>Harsimran</first><last>Bedi</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <author><first>Vasudeva</first><last>Varma</last></author>
      <pages>28–36</pages>
      <abstract>In this paper, we advocate the use of Message Sequence Chart (MSC) as a knowledge representation to capture and visualize multi-actor interactions and their temporal ordering. We propose algorithms to automatically extract an MSC from a history narrative. For a given narrative, we first identify verbs which indicate interactions and then use dependency parsing and Semantic Role Labelling based approaches to identify senders (initiating actors) and receivers (other actors involved) for these interaction verbs. As a final step in MSC extraction, we employ a state-of-the art algorithm to temporally re-order these interactions. Our evaluation on multiple publicly available narratives shows improvements over four baselines.</abstract>
      <url>W19-2404</url>
    </paper>
    <paper id="5">
      <title>Unsupervised Hierarchical Story Infilling</title>
      <author><first>Daphne</first><last>Ippolito</last></author>
      <author><first>David</first><last>Grangier</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <author><first>Douglas</first><last>Eck</last></author>
      <pages>37–43</pages>
      <abstract>Story infilling involves predicting words to go into a missing span from a story. This challenging task has the potential to transform interactive tools for creative writing. However, state-of-the-art conditional language models have trouble balancing fluency and coherence with novelty and diversity. We address this limitation with a hierarchical model which first selects a set of rare words and then generates text conditioned on that set. By relegating the high entropy task of picking rare words to a word-sampling model, the second-stage model conditioned on those words can achieve high fluency and coherence by searching for likely sentences, without sacrificing diversity.</abstract>
      <url>W19-2405</url>
    </paper>
    <paper id="6">
      <title>Identifying Sensible Lexical Relations in Generated Stories</title>
      <author><first>Melissa</first><last>Roemmele</last></author>
      <pages>44–52</pages>
      <abstract>As with many text generation tasks, the focus of recent progress on story generation has been in producing texts that are perceived to “make sense” as a whole. There are few automated metrics that address this dimension of story quality even on a shallow lexical level. To initiate investigation into such metrics, we apply a simple approach to identifying word relations that contribute to the ‘narrative sense’ of a story. We use this approach to comparatively analyze the output of a few notable story generation systems in terms of these relations. We characterize differences in the distributions of relations according to their strength within each story.</abstract>
      <url>W19-2406</url>
    </paper>
  </volume>
  <volume id="25">
    <meta>
      <booktitle>Proceedings of the 3rd Joint <fixed-case>SIGHUM</fixed-case> Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</booktitle>
      <url>W19-25</url>
      <editor><first>Beatrice</first><last>Alex</last></editor>
      <editor><first>Stefania</first><last>Degaetano-Ortlieb</last></editor>
      <editor><first>Anna</first><last>Kazantseva</last></editor>
      <editor><first>Nils</first><last>Reiter</last></editor>
      <editor><first>Stan</first><last>Szpakowicz</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, USA</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-2500</url>
    </frontmatter>
    <paper id="1">
      <title>Modeling Word Emotion in Historical Language: Quantity Beats Supposed Stability in Seed Word Selection</title>
      <author><first>Johannes</first><last>Hellrich</last></author>
      <author><first>Sven</first><last>Buechel</last></author>
      <author><first>Udo</first><last>Hahn</last></author>
      <pages>1–11</pages>
      <abstract>To understand historical texts, we must be aware that language—including the emotional connotation attached to words—changes over time. In this paper, we aim at estimating the emotion which is associated with a given word in former language stages of English and German. Emotion is represented following the popular Valence-Arousal-Dominance (VAD) annotation scheme. While being more expressive than polarity alone, existing word emotion induction methods are typically not suited for addressing it. To overcome this limitation, we present adaptations of two popular algorithms to VAD. To measure their effectiveness in diachronic settings, we present the first gold standard for historical word emotions, which was created by scholars with proficiency in the respective language stages and covers both English and German. In contrast to claims in previous work, our findings indicate that hand-selecting small sets of seed words with supposedly stable emotional meaning is actually harm- rather than helpful.</abstract>
      <url>W19-2501</url>
    </paper>
    <paper id="2">
      <title>Clustering-Based Article Identification in Historical Newspapers</title>
      <author><first>Martin</first><last>Riedl</last></author>
      <author><first>Daniela</first><last>Betz</last></author>
      <author><first>Sebastian</first><last>Padó</last></author>
      <pages>12–17</pages>
      <abstract>This article focuses on the problem of identifying articles and recovering their text from within and across newspaper pages when OCR just delivers one text file per page. We frame the task as a segmentation plus clustering step. Our results on a sample of 1912 New York Tribune magazine shows that performing the clustering based on similarities computed with word embeddings outperforms a similarity measure based on character n-grams and words. Furthermore, the automatic segmentation based on the text results in low scores, due to the low quality of some OCRed documents.</abstract>
      <url>W19-2502</url>
    </paper>
    <paper id="3">
      <title>The Scientization of Literary Study</title>
      <author><first>Stefania</first><last>Degaetano-Ortlieb</last></author>
      <author><first>Andrew</first><last>Piper</last></author>
      <pages>18–28</pages>
      <abstract>Scholarly practices within the humanities have historically been perceived as distinct from the natural sciences. We look at literary studies, a discipline strongly anchored in the humanities, and hypothesize that over the past half-century literary studies has instead undergone a process of “scientization”, adopting linguistic behavior similar to the sciences. We test this using methods based on information theory, comparing a corpus of literary studies articles (around 63,400) with a corpus of standard English and scientific English respectively. We show evidence for “scientization” effects in literary studies, though at a more muted level than scientific English, suggesting that literary studies occupies a middle ground with respect to standard English in the larger space of academic disciplines. More generally, our methodology can be applied to investigate the social positioning and development of language use across different domains (e.g. scientific disciplines, language varieties, registers).</abstract>
      <url>W19-2503</url>
    </paper>
    <paper id="4">
      <title>Are Fictional Voices Distinguishable? Classifying Character Voices in Modern Drama</title>
      <author><first>Krishnapriya</first><last>Vishnubhotla</last></author>
      <author><first>Adam</first><last>Hammond</last></author>
      <author><first>Graeme</first><last>Hirst</last></author>
      <pages>29–34</pages>
      <abstract>According to the literary theory of Mikhail Bakhtin, a dialogic novel is one in which characters speak in their own distinct voices, rather than serving as mouthpieces for their authors. We use text classification to determine which authors best achieve dialogism, looking at a corpus of plays from the late nineteenth and early twentieth centuries. We find that the SAGE model of text generation, which highlights deviations from a background lexical distribution, is an effective method of weighting the words of characters’ utterances. Our results show that it is indeed possible to distinguish characters by their speech in the plays of canonical writers such as George Bernard Shaw, whereas characters are clustered more closely in the works of lesser-known playwrights.</abstract>
      <url>W19-2504</url>
    </paper>
    <paper id="5">
      <title>Automatic Alignment and Annotation Projection for Literary Texts</title>
      <author><first>Uli</first><last>Steinbach</last></author>
      <author><first>Ines</first><last>Rehbein</last></author>
      <pages>35–45</pages>
      <abstract>This paper presents a modular NLP pipeline for the creation of a parallel literature corpus, followed by annotation transfer from the source to the target language. The test case we use to evaluate our pipeline is the automatic transfer of quote and speaker mention annotations from English to German. We evaluate the different components of the pipeline and discuss challenges specific to literary texts. Our experiments show that after applying a reasonable amount of semi-automatic postprocessing we can obtain high-quality aligned and annotated resources for a new language.</abstract>
      <url>W19-2505</url>
    </paper>
    <paper id="6">
      <title>Inferring missing metadata from environmental policy texts</title>
      <author><first>Steven</first><last>Bethard</last></author>
      <author><first>Egoitz</first><last>Laparra</last></author>
      <author><first>Sophia</first><last>Wang</last></author>
      <author><first>Yiyun</first><last>Zhao</last></author>
      <author><first>Ragheb</first><last>Al-Ghezi</last></author>
      <author><first>Aaron</first><last>Lien</last></author>
      <author><first>Laura</first><last>López-Hoffman</last></author>
      <pages>46–51</pages>
      <abstract>The National Environmental Policy Act (NEPA) provides a trove of data on how environmental policy decisions have been made in the United States over the last 50 years. Unfortunately, there is no central database for this information and it is too voluminous to assess manually. We describe our efforts to enable systematic research over US environmental policy by extracting and organizing metadata from the text of NEPA documents. Our contributions include collecting more than 40,000 NEPA-related documents, and evaluating rule-based baselines that establish the difficulty of three important tasks: identifying lead agencies, aligning document versions, and detecting reused text.</abstract>
      <url>W19-2506</url>
    </paper>
    <paper id="7">
      <title>Stylometric Classification of Ancient <fixed-case>G</fixed-case>reek Literary Texts by Genre</title>
      <author><first>Efthimios</first><last>Gianitsos</last></author>
      <author><first>Thomas</first><last>Bolt</last></author>
      <author><first>Pramit</first><last>Chaudhuri</last></author>
      <author><first>Joseph</first><last>Dexter</last></author>
      <pages>52–60</pages>
      <abstract>Classification of texts by genre is an important application of natural language processing to literary corpora but remains understudied for premodern and non-English traditions. We develop a stylometric feature set for ancient Greek that enables identification of texts as prose or verse. The set contains over 20 primarily syntactic features, which are calculated according to custom, language-specific heuristics. Using these features, we classify almost all surviving classical Greek literature as prose or verse with &gt;97% accuracy and F1 score, and further classify a selection of the verse texts into the traditional genres of epic and drama.</abstract>
      <url>W19-2507</url>
      <software>W19-2507.Software.zip</software>
    </paper>
    <paper id="8">
      <title>A framework for streamlined statistical prediction using topic models</title>
      <author><first>Vanessa</first><last>Glenny</last></author>
      <author><first>Jonathan</first><last>Tuke</last></author>
      <author><first>Nigel</first><last>Bean</last></author>
      <author><first>Lewis</first><last>Mitchell</last></author>
      <pages>61–70</pages>
      <abstract>In the Humanities and Social Sciences, there is increasing interest in approaches to information extraction, prediction, intelligent linkage, and dimension reduction applicable to large text corpora. With approaches in these fields being grounded in traditional statistical techniques, the need arises for frameworks whereby advanced NLP techniques such as topic modelling may be incorporated within classical methodologies. This paper provides a classical, supervised, statistical learning framework for prediction from text, using topic models as a data reduction method and the topics themselves as predictors, alongside typical statistical tools for predictive modelling. We apply this framework in a Social Sciences context (applied animal behaviour) as well as a Humanities context (narrative analysis) as examples of this framework. The results show that topic regression models perform comparably to their much less efficient equivalents that use individual words as predictors.</abstract>
      <url>W19-2508</url>
    </paper>
    <paper id="9">
      <title>Revisiting <fixed-case>NMT</fixed-case> for Normalization of Early <fixed-case>E</fixed-case>nglish Letters</title>
      <author><first>Mika</first><last>Hämäläinen</last></author>
      <author><first>Tanja</first><last>Säily</last></author>
      <author><first>Jack</first><last>Rueter</last></author>
      <author><first>Jörg</first><last>Tiedemann</last></author>
      <author><first>Eetu</first><last>Mäkelä</last></author>
      <pages>71–75</pages>
      <abstract>This paper studies the use of NMT (neural machine translation) as a normalization method for an early English letter corpus. The corpus has previously been normalized so that only less frequent deviant forms are left out without normalization. This paper discusses different methods for improving the normalization of these deviant forms by using different approaches. Adding features to the training data is found to be unhelpful, but using a lexicographical resource to filter the top candidates produced by the NMT model together with lemmatization improves results.</abstract>
      <url>W19-2509</url>
    </paper>
    <paper id="10">
      <title>Graph convolutional networks for exploring authorship hypotheses</title>
      <author><first>Tom</first><last>Lippincott</last></author>
      <pages>76–81</pages>
      <abstract>This work considers a task from traditional literary criticism: annotating a structured, composite document with information about its sources. We take the Documentary Hypothesis, a prominent theory regarding the composition of the first five books of the Hebrew bible, extract stylistic features designed to avoid bias or overfitting, and train several classification models. Our main result is that the recently-introduced graph convolutional network architecture outperforms structurally-uninformed models. We also find that including information about the granularity of text spans is a crucial ingredient when employing hidden layers, in contrast to simple logistic regression. We perform error analysis at several levels, noting how some characteristic limitations of the models and simple features lead to misclassifications, and conclude with an overview of future work.</abstract>
      <url>W19-2510</url>
    </paper>
    <paper id="11">
      <title>Semantics and Homothetic Clustering of Hafez Poetry</title>
      <author><first>Arya</first><last>Rahgozar</last></author>
      <author><first>Diana</first><last>Inkpen</last></author>
      <pages>82–90</pages>
      <abstract>We have created two sets of labels for Hafez (1315-1390) poems, using unsupervised learn- ing. Our labels are the only semantic cluster- ing alternative to the previously existing, hand- labeled, gold-standard classification of Hafez poems, to be used for literary research. We have cross-referenced, measured and analyzed the agreements of our clustering labels with Houman’s chronological classes. Our features are based on topic modeling and word embed- dings. We also introduced a similarity of similarities’ features, we called homothetic clustering approach that proved effective, in case of Hafez’s small corpus of ghazals2. Although all our experiments showed different clusters when compared with Houman’s classes, we think they were valid in their own right to have provided further insights, and have proved useful as a contrasting alternative to Houman’s classes. Our homothetic clusterer and its feature design and engineering framework can be used for further semantic analysis of Hafez’s poetry and other similar literary research.</abstract>
      <url>W19-2511</url>
    </paper>
    <paper id="12">
      <title>Computational Linguistics Applications for Multimedia Services</title>
      <author><first>Kyeongmin</first><last>Rim</last></author>
      <author><first>Kelley</first><last>Lynch</last></author>
      <author><first>James</first><last>Pustejovsky</last></author>
      <pages>91–97</pages>
      <abstract>We present Computational Linguistics Applications for Multimedia Services (CLAMS), a platform that provides access to computational content analysis tools for archival multimedia material that appear in different media, such as text, audio, image, and video. The primary goal of CLAMS is: (1) to develop an interchange format between multimodal metadata generation tools to ensure interoperability between tools; (2) to provide users with a portable, user-friendly workflow engine to chain selected tools to extract meaningful analyses; and (3) to create a public software development kit (SDK) for developers that eases deployment of analysis tools within the CLAMS platform. CLAMS is designed to help archives and libraries enrich the metadata associated with their mass-digitized multimedia collections, that would otherwise be largely unsearchable.</abstract>
      <url>W19-2512</url>
    </paper>
    <paper id="13">
      <title>Correcting Whitespace Errors in Digitized Historical Texts</title>
      <author><first>Sandeep</first><last>Soni</last></author>
      <author><first>Lauren</first><last>Klein</last></author>
      <author><first>Jacob</first><last>Eisenstein</last></author>
      <pages>98–103</pages>
      <abstract>Whitespace errors are common to digitized archives. This paper describes a lightweight unsupervised technique for recovering the original whitespace. Our approach is based on count statistics from Google n-grams, which are converted into a likelihood ratio test computed from interpolated trigram and bigram probabilities. To evaluate this approach, we annotate a small corpus of whitespace errors in a digitized corpus of newspapers from the 19th century United States. Our technique identifies and corrects most whitespace errors while introducing a minimal amount of oversegmentation: it achieves 77% recall at a false positive rate of less than 1%, and 91% recall at a false positive rate of less than 3%.</abstract>
      <url>W19-2513</url>
    </paper>
    <paper id="14">
      <title>On the Feasibility of Automated Detection of Allusive Text Reuse</title>
      <author><first>Enrique</first><last>Manjavacas</last></author>
      <author><first>Brian</first><last>Long</last></author>
      <author><first>Mike</first><last>Kestemont</last></author>
      <pages>104–114</pages>
      <abstract>The detection of allusive text reuse is particularly challenging due to the sparse evidence on which allusive references rely — commonly based on none or very few shared words. Arguably, lexical semantics can be resorted to since uncovering semantic relations between words has the potential to increase the support underlying the allusion and alleviate the lexical sparsity. A further obstacle is the lack of evaluation benchmark corpora, largely due to the highly interpretative character of the annotation process. In the present paper, we aim to elucidate the feasibility of automated allusion detection. We approach the matter from an Information Retrieval perspective in which referencing texts act as queries and referenced texts as relevant documents to be retrieved, and estimate the difficulty of benchmark corpus compilation by a novel inter-annotator agreement study on query segmentation. Furthermore, we investigate to what extent the integration of lexical semantic information derived from distributional models and ontologies can aid retrieving cases of allusive reuse. The results show that (i) despite low agreement scores, using manual queries considerably improves retrieval performance with respect to a windowing approach, and that (ii) retrieval performance can be moderately boosted with distributional semantics.</abstract>
      <url>W19-2514</url>
    </paper>
    <paper id="15">
      <title>The limits of <fixed-case>S</fixed-case>panglish?</title>
      <author><first>Barbara</first><last>Bullock</last></author>
      <author><first>Wally</first><last>Guzmán</last></author>
      <author><first>Almeida Jacqueline</first><last>Toribio</last></author>
      <pages>115–121</pages>
      <abstract>Linguistic code-switching (C-S) is common in oral bilingual vernacular speech. When used in literature, C-S becomes an artistic choice that can mirror the patterns of bilingual interactions. But it can also potentially exceed them. What are the limits of C-S? We model features of C-S in corpora of contemporary U.S. Spanish-English literary and conversational data to analyze why some critics view the ‘Spanglish’ texts of Ilan Stavans as deviating from a C-S norm.</abstract>
      <url>W19-2515</url>
    </paper>
    <paper id="16">
      <title>Sign Clustering and Topic Extraction in Proto-Elamite</title>
      <author><first>Logan</first><last>Born</last></author>
      <author><first>Kate</first><last>Kelley</last></author>
      <author><first>Nishant</first><last>Kambhatla</last></author>
      <author><first>Carolyn</first><last>Chen</last></author>
      <author><first>Anoop</first><last>Sarkar</last></author>
      <pages>122–132</pages>
      <abstract>We describe a first attempt at using techniques from computational linguistics to analyze the undeciphered proto-Elamite script. Using hierarchical clustering, n-gram frequencies, and LDA topic models, we both replicate results obtained by manual decipherment and reveal previously-unobserved relationships between signs. This demonstrates the utility of these techniques as an aid to manual decipherment.</abstract>
      <url>W19-2516</url>
    </paper>
  </volume>
  <volume id="26">
    <meta>
      <booktitle>Proceedings of the Workshop on Extracting Structured Knowledge from Scientific Publications</booktitle>
      <url>W19-26</url>
      <editor><first>Vivi</first><last>Nastase</last></editor>
      <editor><first>Benjamin</first><last>Roth</last></editor>
      <editor><first>Laura</first><last>Dietz</last></editor>
      <editor><first>Andrew</first><last>McCallum</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-2600</url>
    </frontmatter>
    <paper id="1">
      <title>Distantly Supervised Biomedical Knowledge Acquisition via Knowledge Graph Based Attention</title>
      <author><first>Qin</first><last>Dai</last></author>
      <author><first>Naoya</first><last>Inoue</last></author>
      <author><first>Paul</first><last>Reisert</last></author>
      <author><first>Ryo</first><last>Takahashi</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>1–10</pages>
      <abstract>The increased demand for structured scientific knowledge has attracted considerable attention in extracting scientific relation from the ever growing scientific publications. Distant supervision is widely applied approach to automatically generate large amounts of labelled data with low manual annotation cost. However, distant supervision inevitably accompanies the wrong labelling problem, which will negatively affect the performance of Relation Extraction (RE). To address this issue, (Han et al., 2018) proposes a novel framework for jointly training both RE model and Knowledge Graph Completion (KGC) model to extract structured knowledge from non-scientific dataset. In this work, we firstly investigate the feasibility of this framework on scientific dataset, specifically on biomedical dataset. Secondly, to achieve better performance on the biomedical dataset, we extend the framework with other competitive KGC models. Moreover, we proposed a new end-to-end KGC model to extend the framework. Experimental results not only show the feasibility of the framework on the biomedical dataset, but also indicate the effectiveness of our extensions, because our extended model achieves significant and consistent improvements on distant supervised RE as compared with baselines.</abstract>
      <url>W19-2601</url>
    </paper>
    <paper id="2">
      <title>Scalable, Semi-Supervised Extraction of Structured Information from Scientific Literature</title>
      <author><first>Kritika</first><last>Agrawal</last></author>
      <author><first>Aakash</first><last>Mittal</last></author>
      <author><first>Vikram</first><last>Pudi</last></author>
      <pages>11–20</pages>
      <abstract>As scientific communities grow and evolve, there is a high demand for improved methods for finding relevant papers, comparing papers on similar topics and studying trends in the research community. All these tasks involve the common problem of extracting structured information from scientific articles. In this paper, we propose a novel, scalable, semi-supervised method for extracting relevant structured information from the vast available raw scientific literature. We extract the fundamental concepts of “aim”, ”method” and “result” from scientific articles and use them to construct a knowledge graph. Our algorithm makes use of domain-based word embedding and the bootstrap framework. Our experiments show that our system achieves precision and recall comparable to the state of the art. We also show the domain independence of our algorithm by analyzing the research trends of two distinct communities - computational linguistics and computer vision.</abstract>
      <url>W19-2602</url>
    </paper>
    <paper id="3">
      <title>Understanding the Polarity of Events in the Biomedical Literature: Deep Learning vs. Linguistically-informed Methods</title>
      <author><first>Enrique</first><last>Noriega-Atala</last></author>
      <author><first>Zhengzhong</first><last>Liang</last></author>
      <author><first>John</first><last>Bachman</last></author>
      <author><first>Clayton</first><last>Morrison</last></author>
      <author><first>Mihai</first><last>Surdeanu</last></author>
      <pages>21–30</pages>
      <abstract>An important task in the machine reading of biochemical events expressed in biomedical texts is correctly reading the polarity, i.e., attributing whether the biochemical event is a promotion or an inhibition. Here we present a novel dataset for studying polarity attribution accuracy. We use this dataset to train and evaluate several deep learning models for polarity identification, and compare these to a linguistically-informed model. The best performing deep learning architecture achieves 0.968 average F1 performance in a five-fold cross-validation study, a considerable improvement over the linguistically informed model average F1 of 0.862.</abstract>
      <url>W19-2603</url>
    </paper>
    <paper id="4">
      <title>Dataset Mention Extraction and Classification</title>
      <author><first>Animesh</first><last>Prasad</last></author>
      <author><first>Chenglei</first><last>Si</last></author>
      <author><first>Min-Yen</first><last>Kan</last></author>
      <pages>31–36</pages>
      <abstract>Datasets are integral artifacts of empirical scientific research. However, due to natural language variation, their recognition can be difficult and even when identified, can often be inconsistently referred across and within publications. We report our approach to the Coleridge Initiative’s Rich Context Competition, which tasks participants with identifying dataset surface forms (dataset mention extraction) and associating the extracted mention to its referred dataset (dataset classification). In this work, we propose various neural baselines and evaluate these model on one-plus and zero-shot classification scenarios. We further explore various joint learning approaches - exploring the synergy between the tasks - and report the issues with such techniques.</abstract>
      <url>W19-2604</url>
    </paper>
    <paper id="5">
      <title>Annotating with Pros and Cons of Technologies in Computer Science Papers</title>
      <author><first>Hono</first><last>Shirai</last></author>
      <author><first>Naoya</first><last>Inoue</last></author>
      <author><first>Jun</first><last>Suzuki</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>37–42</pages>
      <abstract>This paper explores a task for extracting a technological expression and its pros/cons from computer science papers. We report ongoing efforts on an annotated corpus of pros/cons and an analysis of the nature of the automatic extraction task. Specifically, we show how to adapt the targeted sentiment analysis task for pros/cons extraction in computer science papers and conduct an annotation study. In order to identify the challenges of the automatic extraction task, we construct a strong baseline model and conduct an error analysis. The experiments show that pros/cons can be consistently annotated by several annotators, and that the task is challenging due to domain-specific knowledge. The annotated dataset is made publicly available for research purposes.</abstract>
      <url>W19-2605</url>
    </paper>
    <paper id="6">
      <title>Browsing Health: Information Extraction to Support New Interfaces for Accessing Medical Evidence</title>
      <author><first>Soham</first><last>Parikh</last></author>
      <author><first>Elizabeth</first><last>Conrad</last></author>
      <author><first>Oshin</first><last>Agarwal</last></author>
      <author><first>Iain</first><last>Marshall</last></author>
      <author><first>Byron</first><last>Wallace</last></author>
      <author><first>Ani</first><last>Nenkova</last></author>
      <pages>43–47</pages>
      <abstract>Standard paradigms for search do not work well in the medical context. Typical information needs, such as retrieving a full list of medical interventions for a given condition, or finding the reported efficacy of a particular treatment with respect to a specific outcome of interest cannot be straightforwardly posed in typical text-box search. Instead, we propose faceted-search in which a user specifies a condition and then can browse treatments and outcomes that have been evaluated. Choosing from these, they can access randomized control trials (RCTs) describing individual studies. Realizing such a view of the medical evidence requires information extraction techniques to identify the population, interventions, and outcome measures in an RCT. Patients, health practitioners, and biomedical librarians all stand to benefit from such innovation in search of medical evidence. We present an initial prototype of such an interface applied to pre-registered clinical studies. We also discuss pilot studies into the applicability of information extraction methods to allow for similar access to all published trial results.</abstract>
      <url>W19-2606</url>
    </paper>
    <paper id="7">
      <title>An Analysis of Deep Contextual Word Embeddings and Neural Architectures for Toponym Mention Detection in Scientific Publications</title>
      <author><first>Matthew</first><last>Magnusson</last></author>
      <author><first>Laura</first><last>Dietz</last></author>
      <pages>48–56</pages>
      <abstract>Toponym detection in scientific papers is an open task and a key first step in place entity enrichment of documents. We examine three common neural architectures in NLP: 1) convolutional neural network, 2) multi-layer perceptron (both applied in a sliding window context) and 3) bidirectional LSTM and apply contextual and non-contextual word embedding layers to these models. We find that deep contextual word embeddings improve the performance of the bi-LSTM with CRF neural architecture achieving the best performance when multiple layers of deep contextual embeddings are concatenated. Our best performing model achieves an average F1 of 0.910 when evaluated on overlap macro exceeding previous state-of-the-art models in the toponym detection task.</abstract>
      <url>W19-2607</url>
    </paper>
    <paper id="8">
      <title><fixed-case>STAC</fixed-case>: Science Toolkit Based on <fixed-case>C</fixed-case>hinese Idiom Knowledge Graph</title>
      <author><first>Meiling</first><last>Wang</last></author>
      <author><first>Min</first><last>Xiao</last></author>
      <author><first>Changliang</first><last>Li</last></author>
      <author><first>Yu</first><last>Guo</last></author>
      <author><first>Zhixin</first><last>Zhao</last></author>
      <author><first>Xiaonan</first><last>Liu</last></author>
      <pages>57–61</pages>
      <abstract>Chinese idioms (Cheng Yu) have seen five thousand years’ history and culture of China, meanwhile they contain large number of scientific achievement of ancient China. However, existing Chinese online idiom dictionaries have limited function for scientific exploration. In this paper, we first construct a Chinese idiom knowledge graph by extracting domains and dynasties and associating them with idioms, and based on the idiom knowledge graph, we propose a Science Toolkit for Ancient China (STAC) aiming to support scientific exploration. In the STAC toolkit, idiom navigator helps users explore overall scientific progress from idiom perspective with visualization tools, and idiom card and idiom QA shorten action path and avoid thinking being interrupted while users are reading and writing. The current STAC toolkit is deployed at http://120.92.208.22:7476/demo/#/stac.</abstract>
      <url>W19-2608</url>
    </paper>
    <paper id="9">
      <title>Playing by the Book: An Interactive Game Approach for Action Graph Extraction from Text</title>
      <author><first>Ronen</first><last>Tamari</last></author>
      <author><first>Hiroyuki</first><last>Shindo</last></author>
      <author><first>Dafna</first><last>Shahaf</last></author>
      <author><first>Yuji</first><last>Matsumoto</last></author>
      <pages>62–71</pages>
      <abstract>Understanding procedural text requires tracking entities, actions and effects as the narrative unfolds. We focus on the challenging real-world problem of action-graph extraction from materials science papers, where language is highly specialized and data annotation is expensive and scarce. We propose a novel approach, Text2Quest, where procedural text is interpreted as instructions for an interactive game. A learning agent completes the game by executing the procedure correctly in a text-based simulated lab environment. The framework can complement existing approaches and enables richer forms of learning compared to static texts. We discuss potential limitations and advantages of the approach, and release a prototype proof-of-concept, hoping to encourage research in this direction.</abstract>
      <url>W19-2609</url>
    </paper>
    <paper id="10">
      <title>Textual and Visual Characteristics of Mathematical Expressions in Scholar Documents</title>
      <author><first>Vidas</first><last>Daudaravicius</last></author>
      <pages>72–81</pages>
      <abstract>Mathematical expressions (ME) are widely used in scholar documents. In this paper we analyze characteristics of textual and visual MEs characteristics for the image-to-LaTeX translation task. While there are open data-sets of LaTeX files with MEs included it is very complicated to extract these MEs from a document and to compile the list of MEs. Therefore we release a corpus of open-access scholar documents with PDF and JATS-XML parallel files. The MEs in these documents are LaTeX encoded and are document independent. The data contains more than 1.2 million distinct annotated formulae and more than 80 million raw tokens of LaTeX MEs in more than 8 thousand documents. While the variety of textual lengths and visual sizes of MEs are not well defined we found that the task of analyzing MEs in scholar documents can be reduced to the subtask of a particular text length, image width and height bounds, and display MEs can be processed as arrays of partial MEs.</abstract>
      <url>W19-2610</url>
    </paper>
  </volume>
  <volume id="27">
    <meta>
      <booktitle>Proceedings of the Workshop on Discourse Relation Parsing and Treebanking 2019</booktitle>
      <url>W19-27</url>
      <editor><first>Amir</first><last>Zeldes</last></editor>
      <editor><first>Debopam</first><last>Das</last></editor>
      <editor><first>Erick Maziero</first><last>Galani</last></editor>
      <editor><first>Juliano Desiderato</first><last>Antonio</last></editor>
      <editor><first>Mikel</first><last>Iruskieta</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, MN</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-2700</url>
    </frontmatter>
    <paper id="1">
      <title>Introduction to Discourse Relation Parsing and Treebanking (<fixed-case>DISRPT</fixed-case>): 7th Workshop on Rhetorical Structure Theory and Related Formalisms</title>
      <author><first>Amir</first><last>Zeldes</last></author>
      <author><first>Debopam</first><last>Das</last></author>
      <author><first>Erick Galani</first><last>Maziero</last></author>
      <author><first>Juliano</first><last>Antonio</last></author>
      <author><first>Mikel</first><last>Iruskieta</last></author>
      <pages>1–6</pages>
      <abstract>This overview summarizes the main contributions of the accepted papers at the 2019 workshop on Discourse Relation Parsing and Treebanking (DISRPT 2019). Co-located with NAACL 2019 in Minneapolis, the workshop’s aim was to bring together researchers working on corpus-based and computational approaches to discourse relations. In addition to an invited talk, eighteen papers outlined below were presented, four of which were submitted as part of a shared task on elementary discourse unit segmentation and connective detection.</abstract>
      <url>W19-2701</url>
    </paper>
    <paper id="2">
      <title>Toward Cross-theory Discourse Relation Annotation</title>
      <author><first>Peter</first><last>Bourgonje</last></author>
      <author><first>Olha</first><last>Zolotarenko</last></author>
      <pages>7–11</pages>
      <abstract>In this exploratory study, we attempt to automatically induce PDTB-style relations from RST trees. We work with a German corpus of news commentary articles, annotated for RST trees and explicit PDTB-style relations and we focus on inducing the implicit relations in an automated way. Preliminary results look promising as a high-precision (but low-recall) way of finding implicit relations where there is no shallow structure annotated at all, but mapping proves more difficult in cases where EDUs and relation arguments overlap, yet do not seem to signal the same relation.</abstract>
      <url>W19-2702</url>
    </paper>
    <paper id="3">
      <title>Acquiring Annotated Data with Cross-lingual Explicitation for Implicit Discourse Relation Classification</title>
      <author><first>Wei</first><last>Shi</last></author>
      <author><first>Frances</first><last>Yung</last></author>
      <author><first>Vera</first><last>Demberg</last></author>
      <pages>12–21</pages>
      <abstract>Implicit discourse relation classification is one of the most challenging and important tasks in discourse parsing, due to the lack of connectives as strong linguistic cues. A principle bottleneck to further improvement is the shortage of training data (ca. 18k instances in the Penn Discourse Treebank (PDTB)). Shi et al. (2017) proposed to acquire additional data by exploiting connectives in translation: human translators mark discourse relations which are implicit in the source language explicitly in the translation. Using back-translations of such explicitated connectives improves discourse relation parsing performance. This paper addresses the open question of whether the choice of the translation language matters, and whether multiple translations into different languages can be effectively used to improve the quality of the additional data.</abstract>
      <url>W19-2703</url>
    </paper>
    <paper id="4">
      <title>From News to Medical: Cross-domain Discourse Segmentation</title>
      <author><first>Elisa</first><last>Ferracane</last></author>
      <author><first>Titan</first><last>Page</last></author>
      <author><first>Junyi Jessy</first><last>Li</last></author>
      <author><first>Katrin</first><last>Erk</last></author>
      <pages>22–29</pages>
      <abstract>The first step in discourse analysis involves di- viding a text into segments. We annotate the first high-quality small-scale medical corpus in English with discourse segments and analyze how well news-trained segmenters perform on this domain. While we expectedly find a drop in performance, the nature of the segmentation errors suggests some problems can be addressed earlier in the pipeline, while others would require expanding the corpus to a trainable size to learn the nuances of the medical domain.</abstract>
      <url>W19-2704</url>
      <attachment type="presentation">W19-2704.Presentation.pdf</attachment>
    </paper>
    <paper id="5">
      <title>Nuclearity in <fixed-case>RST</fixed-case> and signals of coherence relations</title>
      <author><first>Debopam</first><last>Das</last></author>
      <pages>30–37</pages>
      <abstract>We investigate the relationship between the notion of nuclearity as proposed in Rhetorical Structure Theory (RST) and the signalling of coherence relations. RST relations are categorized as either mononuclear (comprising a nucleus and a satellite span) or multinuclear (comprising two or more nuclei spans). We examine how mononuclear relations (e.g., Antithesis, Condition) and multinuclear relations (e.g., Contrast, List) are indicated by relational signals, more particularly by discourse markers (e.g., because, however, if, therefore). We conduct a corpus study, examining the distribution of either type of relations in the RST Discourse Treebank (Carlson et al., 2002) and the distribution of discourse markers for those relations in the RST Signalling Corpus (Das et al., 2015). Our results show that discourse markers are used more often to signal multinuclear relations than mononuclear relations. The findings also suggest a complex relationship between the relation types and syntactic categories of discourse markers (subordinating and coordinating conjunctions).</abstract>
      <url>W19-2705</url>
    </paper>
    <paper id="6">
      <title>The Rhetorical Structure of Attribution</title>
      <author><first>Andrew</first><last>Potter</last></author>
      <pages>38–49</pages>
      <abstract>The relational status of Attribution in Rhetorical Structure Theory has been a matter of ongoing debate. Although several researchers have weighed in on the topic, and although numerous studies have relied upon attributional structures for their analyses, nothing approaching consensus has emerged. This paper identifies three basic issues that must be resolved to determine the relational status of attributions. These are identified as the Discourse Units Issue, the Nuclearity Issue, and the Relation Identification Issue. These three issues are analyzed from the perspective of classical RST. A finding of this analysis is that the nuclearity and the relational identification of attribution structures are shown to depend on the writer’s intended effect, such that attributional relations cannot be considered as a single relation, but rather as attributional instances of other RST relations.</abstract>
      <url>W19-2706</url>
      <attachment type="presentation">W19-2706.Presentation.pptx</attachment>
    </paper>
    <paper id="7">
      <title>Annotating Shallow Discourse Relations in Twitter Conversations</title>
      <author><first>Tatjana</first><last>Scheffler</last></author>
      <author><first>Berfin</first><last>Aktaş</last></author>
      <author><first>Debopam</first><last>Das</last></author>
      <author><first>Manfred</first><last>Stede</last></author>
      <pages>50–55</pages>
      <abstract>We introduce our pilot study applying PDTB-style annotation to Twitter conversations. Lexically grounded coherence annotation for Twitter threads will enable detailed investigations of the discourse structure of conversations on social media. Here, we present our corpus of 185 threads and annotation, including an inter-annotator agreement study. We discuss our observations as to how Twitter discourses differ from written news text wrt. discourse connectives and relations. We confirm our hypothesis that discourse relations in written social media conversations are expressed differently than in (news) text. We find that in Twitter, connective arguments frequently are not full syntactic clauses, and that a few general connectives expressing EXPANSION and CONTINGENCY make up the majority of the explicit relations in our data.</abstract>
      <url>W19-2707</url>
    </paper>
    <paper id="8">
      <title>A Discourse Signal Annotation System for <fixed-case>RST</fixed-case> Trees</title>
      <author><first>Luke</first><last>Gessler</last></author>
      <author id="yang-liu-georgetown"><first>Yang</first><last>Liu</last></author>
      <author><first>Amir</first><last>Zeldes</last></author>
      <pages>56–61</pages>
      <abstract>This paper presents a new system for open-ended discourse relation signal annotation in the framework of Rhetorical Structure Theory (RST), implemented on top of an online tool for RST annotation. We discuss existing projects annotating textual signals of discourse relations, which have so far not allowed simultaneously structuring and annotating words signaling hierarchical discourse trees, and demonstrate the design and applications of our interface by extending existing RST annotations in the freely available GUM corpus.</abstract>
      <url>W19-2708</url>
    </paper>
    <paper id="9">
      <title><fixed-case>E</fixed-case>us<fixed-case>D</fixed-case>is<fixed-case>P</fixed-case>arser: improving an under-resourced discourse parser with cross-lingual data</title>
      <author><first>Mikel</first><last>Iruskieta</last></author>
      <author><first>Chloé</first><last>Braud</last></author>
      <pages>62–71</pages>
      <abstract>Development of discourse parsers to annotate the relational discourse structure of a text is crucial for many downstream tasks. However, most of the existing work focuses on English, assuming a quite large dataset. Discourse data have been annotated for Basque, but training a system on these data is challenging since the corpus is very small. In this paper, we create the first demonstrator based on RST for Basque, and we investigate the use of data in another language to improve the performance of a Basque discourse parser. More precisely, we build a monolingual system using the small set of data available and investigate the use of multilingual word embeddings to train a system for Basque using data annotated for another language. We found that our approach to building a system limited to the small set of data available for Basque allowed us to get an improvement over previous approaches making use of many data annotated in other languages. At best, we get 34.78 in F1 for the full discourse structure. More data annotation is necessary in order to improve the results obtained with these techniques. We also describe which relations match with the gold standard, in order to understand these results.</abstract>
      <url>W19-2709</url>
    </paper>
    <paper id="10">
      <title>Beyond The Wall Street Journal: Anchoring and Comparing Discourse Signals across Genres</title>
      <author id="yang-liu-georgetown"><first>Yang</first><last>Liu</last></author>
      <pages>72–81</pages>
      <abstract>Recent research on discourse relations has found that they are cued not only by discourse markers (DMs) but also by other textual signals and that signaling information is indicative of genres. While several corpora exist with discourse relation signaling information such as the Penn Discourse Treebank (PDTB, Prasad et al. 2008) and the Rhetorical Structure Theory Signalling Corpus (RST-SC, Das and Taboada 2018), they both annotate the Wall Street Journal (WSJ) section of the Penn Treebank (PTB, Marcus et al. 1993), which is limited to the news domain. Thus, this paper adapts the signal identification and anchoring scheme (Liu and Zeldes, 2019) to three more genres, examines the distribution of signaling devices across relations and genres, and provides a taxonomy of indicative signals found in this dataset.</abstract>
      <url>W19-2710</url>
    </paper>
    <paper id="11">
      <title>Towards the Data-driven System for Rhetorical Parsing of <fixed-case>R</fixed-case>ussian Texts</title>
      <author><first>Artem</first><last>Shelmanov</last></author>
      <author><first>Dina</first><last>Pisarevskaya</last></author>
      <author><first>Elena</first><last>Chistova</last></author>
      <author><first>Svetlana</first><last>Toldova</last></author>
      <author><first>Maria</first><last>Kobozeva</last></author>
      <author><first>Ivan</first><last>Smirnov</last></author>
      <pages>82–87</pages>
      <abstract>Results of the first experimental evaluation of machine learning models trained on Ru-RSTreebank – first Russian corpus annotated within RST framework – are presented. Various lexical, quantitative, morphological, and semantic features were used. In rhetorical relation classification, ensemble of CatBoost model with selected features and a linear SVM model provides the best score (macro F1 = 54.67 ± 0.38). We discover that most of the important features for rhetorical relation classification are related to discourse connectives derived from the connectives lexicon for Russian and from other sources.</abstract>
      <url>W19-2711</url>
      <attachment type="poster">W19-2711.Poster.pdf</attachment>
    </paper>
    <paper id="12">
      <title><fixed-case>RST</fixed-case>-Tace A tool for automatic comparison and evaluation of <fixed-case>RST</fixed-case> trees</title>
      <author><first>Shujun</first><last>Wan</last></author>
      <author><first>Tino</first><last>Kutschbach</last></author>
      <author><first>Anke</first><last>Lüdeling</last></author>
      <author><first>Manfred</first><last>Stede</last></author>
      <pages>88–96</pages>
      <abstract>This paper presents RST-Tace, a tool for automatic comparison and evaluation of RST trees. RST-Tace serves as an implementation of Iruskieta’s comparison method, which allows trees to be compared and evaluated without the influence of decisions at lower levels in a tree in terms of four factors: constituent, attachment point, nuclearity as well as relation. RST-Tace can be used regardless of the language or the size of rhetorical trees. This tool aims to measure the agreement between two annotators. The result is reflected by F- measure and inter-annotator agreement. Both the comparison table and the result of the evaluation can be obtained automatically.</abstract>
      <url>W19-2712</url>
    </paper>
    <paper id="13">
      <title>The <fixed-case>DISRPT</fixed-case> 2019 Shared Task on Elementary Discourse Unit Segmentation and Connective Detection</title>
      <author><first>Amir</first><last>Zeldes</last></author>
      <author><first>Debopam</first><last>Das</last></author>
      <author><first>Erick Galani</first><last>Maziero</last></author>
      <author><first>Juliano</first><last>Antonio</last></author>
      <author><first>Mikel</first><last>Iruskieta</last></author>
      <pages>97–104</pages>
      <abstract>In 2019, we organized the first iteration of a shared task dedicated to the underlying units used in discourse parsing across formalisms: the DISRPT Shared Task on Elementary Discourse Unit Segmentation and Connective Detection. In this paper we review the data included in the task, which cover 2.6 million manually annotated tokens from 15 datasets in 10 languages, survey and compare submitted systems and report on system performance on each task for both annotated and plain-tokenized versions of the data.</abstract>
      <url>W19-2713</url>
    </paper>
    <paper id="14">
      <title>Multi-lingual and Cross-genre Discourse Unit Segmentation</title>
      <author><first>Peter</first><last>Bourgonje</last></author>
      <author><first>Robin</first><last>Schäfer</last></author>
      <pages>105–114</pages>
      <abstract>We describe a series of experiments applied to data sets from different languages and genres annotated for coherence relations according to different theoretical frameworks. Specifically, we investigate the feasibility of a unified (theory-neutral) approach toward discourse segmentation; a process which divides a text into minimal discourse units that are involved in s coherence relation. We apply a RandomForest and an LSTM based approach for all data sets, and we improve over a simple baseline assuming simple sentence or clause-like segmentation. Performance however varies a lot depending on language, and more importantly genre, with f-scores ranging from 73.00 to 94.47.</abstract>
      <url>W19-2714</url>
    </paper>
    <paper id="15">
      <title><fixed-case>T</fixed-case>o<fixed-case>N</fixed-case>y: Contextual embeddings for accurate multilingual discourse segmentation of full documents</title>
      <author><first>Philippe</first><last>Muller</last></author>
      <author><first>Chloé</first><last>Braud</last></author>
      <author><first>Mathieu</first><last>Morey</last></author>
      <pages>115–124</pages>
      <abstract>Segmentation is the first step in building practical discourse parsers, and is often neglected in discourse parsing studies. The goal is to identify the minimal spans of text to be linked by discourse relations, or to isolate explicit marking of discourse relations. Existing systems on English report F1 scores as high as 95%, but they generally assume gold sentence boundaries and are restricted to English newswire texts annotated within the RST framework. This article presents a generic approach and a system, ToNy, a discourse segmenter developed for the DisRPT shared task where multiple discourse representation schemes, languages and domains are represented. In our experiments, we found that a straightforward sequence prediction architecture with pretrained contextual embeddings is sufficient to reach performance levels comparable to existing systems, when separately trained on each corpus. We report performance between 81% and 96% in F1 score. We also observed that discourse segmentation models only display a moderate generalization capability, even within the same language and discourse representation scheme.</abstract>
      <url>W19-2715</url>
      <attachment type="poster">W19-2715.Poster.pdf</attachment>
    </paper>
    <paper id="16">
      <title>Multilingual segmentation based on neural networks and pre-trained word embeddings</title>
      <author><first>Mikel</first><last>Iruskieta</last></author>
      <author><first>Kepa</first><last>Bengoetxea</last></author>
      <author><first>Aitziber</first><last>Atutxa Salazar</last></author>
      <author><first>Arantza</first><last>Diaz de Ilarraza</last></author>
      <pages>125–132</pages>
      <abstract>The DISPRT 2019 workshop has organized a shared task aiming to identify cross-formalism and multilingual discourse segments. Elementary Discourse Units (EDUs) are quite similar across different theories. Segmentation is the very first stage on the way of rhetorical annotation. Still, each annotation project adopted several decisions with consequences not only on the annotation of the relational discourse structure but also at the segmentation stage. In this shared task, we have employed pre-trained word embeddings, neural networks (BiLSTM+CRF) to perform the segmentation. We report F1 results for 6 languages: Basque (0.853), English (0.919), French (0.907), German (0.913), Portuguese (0.926) and Spanish (0.868 and 0.769). Finally, we also pursued an error analysis based on clause typology for Basque and Spanish, in order to understand the performance of the segmenter.</abstract>
      <url>W19-2716</url>
      <software>W19-2716.Software.pdf</software>
    </paper>
    <paper id="17">
      <title><fixed-case>G</fixed-case>um<fixed-case>D</fixed-case>rop at the <fixed-case>DISRPT</fixed-case>2019 Shared Task: A Model Stacking Approach to Discourse Unit Segmentation and Connective Detection</title>
      <author><first>Yue</first><last>Yu</last></author>
      <author><first>Yilun</first><last>Zhu</last></author>
      <author id="yang-liu-georgetown"><first>Yang</first><last>Liu</last></author>
      <author><first>Yan</first><last>Liu</last></author>
      <author><first>Siyao</first><last>Peng</last></author>
      <author><first>Mackenzie</first><last>Gong</last></author>
      <author><first>Amir</first><last>Zeldes</last></author>
      <pages>133–143</pages>
      <abstract>In this paper we present GumDrop, Georgetown University’s entry at the DISRPT 2019 Shared Task on automatic discourse unit segmentation and connective detection. Our approach relies on model stacking, creating a heterogeneous ensemble of classifiers, which feed into a metalearner for each final task. The system encompasses three trainable component stacks: one for sentence splitting, one for discourse unit segmentation and one for connective detection. The flexibility of each ensemble allows the system to generalize well to datasets of different sizes and with varying levels of homogeneity.</abstract>
      <url>W19-2717</url>
    </paper>
    <paper id="18">
      <title>Towards discourse annotation and sentiment analysis of the Basque Opinion Corpus</title>
      <author><first>Jon</first><last>Alkorta</last></author>
      <author><first>Koldo</first><last>Gojenola</last></author>
      <author><first>Mikel</first><last>Iruskieta</last></author>
      <pages>144–152</pages>
      <abstract>Discourse information is crucial for a better understanding of the text structure and it is also necessary to describe which part of an opinionated text is more relevant or to decide how a text span can change the polarity (strengthen or weaken) of other span by means of coherence relations. This work presents the first results on the annotation of the Basque Opinion Corpus using Rhetorical Structure Theory (RST). Our evaluation results and analysis show us the main avenues to improve on a future annotation process. We have also extracted the subjectivity of several rhetorical relations and the results show the effect of sentiment words in relations and the influence of each relation in the semantic orientation value.</abstract>
      <url>W19-2718</url>
      <attachment type="presentation">W19-2718.Presentation.pdf</attachment>
    </paper>
    <paper id="19">
      <title>Using Rhetorical Structure Theory to Assess Discourse Coherence for Non-native Spontaneous Speech</title>
      <author><first>Xinhao</first><last>Wang</last></author>
      <author><first>Binod</first><last>Gyawali</last></author>
      <author><first>James V.</first><last>Bruno</last></author>
      <author><first>Hillary R.</first><last>Molloy</last></author>
      <author><first>Keelan</first><last>Evanini</last></author>
      <author><first>Klaus</first><last>Zechner</last></author>
      <pages>153–162</pages>
      <abstract>This study aims to model the discourse structure of spontaneous spoken responses within the context of an assessment of English speaking proficiency for non-native speakers. Rhetorical Structure Theory (RST) has been commonly used in the analysis of discourse organization of written texts; however, limited research has been conducted to date on RST annotation and parsing of spoken language, in particular, non-native spontaneous speech. Due to the fact that the measurement of discourse coherence is typically a key metric in human scoring rubrics for assessments of spoken language, we conducted research to obtain RST annotations on non-native spoken responses from a standardized assessment of academic English proficiency. Subsequently, automatic parsers were trained on these annotations to process non-native spontaneous speech. Finally, a set of features were extracted from automatically generated RST trees to evaluate the discourse structure of non-native spontaneous speech, which were then employed to further improve the validity of an automated speech scoring system.</abstract>
      <url>W19-2719</url>
      <attachment type="presentation">W19-2719.Presentation.pptx</attachment>
    </paper>
    <paper id="20">
      <title>Applying Rhetorical Structure Theory to Student Essays for Providing Automated Writing Feedback</title>
      <author><first>Shiyan</first><last>Jiang</last></author>
      <author><first>Kexin</first><last>Yang</last></author>
      <author><first>Chandrakumari</first><last>Suvarna</last></author>
      <author><first>Pooja</first><last>Casula</last></author>
      <author><first>Mingtong</first><last>Zhang</last></author>
      <author><first>Carolyn</first><last>Rosé</last></author>
      <pages>163–168</pages>
      <abstract>We present a package of annotation resources, including annotation guideline, flowchart, and an Intelligent Tutoring System for training human annotators. These resources can be used to apply Rhetorical Structure Theory (RST) to essays written by students in K-12 schools. Furthermore, we highlight the great potential of using RST to provide automated feedback for improving writing quality across genres.</abstract>
      <url>W19-2720</url>
      <attachment type="presentation">W19-2720.Presentation.pdf</attachment>
    </paper>
  </volume>
  <volume id="28">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Computational Models of Reference, Anaphora and Coreference</booktitle>
      <url>W19-28</url>
      <editor><first>Maciej</first><last>Ogrodniczuk</last></editor>
      <editor><first>Sameer</first><last>Pradhan</last></editor>
      <editor><first>Yulia</first><last>Grishina</last></editor>
      <editor><first>Vincent</first><last>Ng</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, USA</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-2800</url>
    </frontmatter>
    <paper id="1">
      <title>Evaluation of named entity coreference</title>
      <author><first>Oshin</first><last>Agarwal</last></author>
      <author><first>Sanjay</first><last>Subramanian</last></author>
      <author><first>Ani</first><last>Nenkova</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>1–7</pages>
      <abstract>In many NLP applications like search and information extraction for named entities, it is necessary to find all the mentions of a named entity, some of which appear as pronouns (she, his, etc.) or nominals (the professor, the German chancellor, etc.). It is therefore important that coreference resolution systems are able to link these different types of mentions to the correct entity name. We evaluate state-of-the-art coreference resolution systems for the task of resolving all mentions to named entities. Our analysis reveals that standard coreference metrics do not reflect adequately the requirements in this task: they do not penalize systems for not identifying any mentions by name to an entity and they reward systems even if systems find correctly mentions to the same entity but fail to link these to a proper name (she–the student–no name). We introduce new metrics for evaluating named entity coreference that address these discrepancies and show that for the comparisons of competitive systems, standard coreference evaluations could give misleading results for this task. We are, however, able to confirm that the state-of-the art system according to traditional evaluations also performs vastly better than other systems on the named entity coreference task.</abstract>
      <url>W19-2801</url>
      <attachment type="supplementary">W19-2801.Supplementary.pdf</attachment>
    </paper>
    <paper id="2">
      <title>Neural Coreference Resolution with Limited Lexical Context and Explicit Mention Detection for Oral <fixed-case>F</fixed-case>rench</title>
      <author><first>Loïc</first><last>Grobol</last></author>
      <pages>8–14</pages>
      <abstract>We propose an end-to-end coreference resolution system obtained by adapting neural models that have recently improved the state-of-the-art on the OntoNotes benchmark to make them applicable to other paradigms for this task. We report the performances of our system on ANCOR, a corpus of transcribed oral French, for which it constitutes a new baseline with proper evaluation.</abstract>
      <url>W19-2802</url>
      <attachment type="supplementary">W19-2802.Supplementary.tgz</attachment>
    </paper>
    <paper id="3">
      <title>Entity Decisions in Neural Language Modelling: Approaches and Problems</title>
      <author><first>Jenny</first><last>Kunz</last></author>
      <author><first>Christian</first><last>Hardmeier</last></author>
      <pages>15–19</pages>
      <abstract>We explore different approaches to explicit entity modelling in language models (LM). We independently replicate two existing models in a controlled setup, introduce a simplified variant of one of the models and analyze their performance in direct comparison. Our results suggest that today’s models are limited as several stochastic variables make learning difficult. We show that the most challenging point in the systems is the decision if the next token is an entity token. The low precision and recall for this variable will lead to severe cascading errors. Our own simplified approach dispenses with the need for latent variables and improves the performance in the entity yes/no decision. A standard well-tuned baseline RNN-LM with a larger number of hidden units outperforms all entity-enabled LMs in terms of perplexity.</abstract>
      <url>W19-2803</url>
    </paper>
    <paper id="4">
      <title>Cross-lingual <fixed-case>NIL</fixed-case> Entity Clustering for Low-resource Languages</title>
      <author><first>Kevin</first><last>Blissett</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <pages>20–25</pages>
      <abstract>Clustering unlinkable entity mentions across documents in multiple languages (cross-lingual NIL Clustering) is an important task as part of Entity Discovery and Linking (EDL). This task has been largely neglected by the EDL community because it is challenging to outperform simple edit distance or other heuristics based baselines. We propose a novel approach based on encoding the orthographic similarity of the mentions using a Recurrent Neural Network (RNN) architecture. Our model adapts a training procedure from the one-shot facial recognition literature in order to achieve this. We also perform several exploratory probing tasks on our name encodings in order to determine what specific types of information are likely to be encoded by our model. Experiments show our approach provides up to a 6.6% absolute CEAFm F-Score improvement over state-of-the-art methods and successfully captures phonological relations across languages.</abstract>
      <url>W19-2804</url>
    </paper>
    <paper id="5">
      <title>Cross-lingual Incongruences in the Annotation of Coreference</title>
      <author><first>Ekaterina</first><last>Lapshinova-Koltunski</last></author>
      <author><first>Sharid</first><last>Loáiciga</last></author>
      <author><first>Christian</first><last>Hardmeier</last></author>
      <author><first>Pauline</first><last>Krielke</last></author>
      <pages>26–34</pages>
      <abstract>In the present paper, we deal with incongruences in English-German multilingual coreference annotation and present automated methods to discover them. More specifically, we automatically detect full coreference chains in parallel texts and analyse discrepancies in their annotations. In doing so, we wish to find out whether the discrepancies rather derive from language typological constraints, from the translation or the actual annotation process. The results of our study contribute to the referential analysis of similarities and differences across languages and support evaluation of cross-lingual coreference annotation. They are also useful for cross-lingual coreference resolution systems and contrastive linguistic studies.</abstract>
      <url>W19-2805</url>
    </paper>
    <paper id="6">
      <title>Deep Cross-Lingual Coreference Resolution for Less-Resourced Languages: The Case of Basque</title>
      <author><first>Gorka</first><last>Urbizu</last></author>
      <author><first>Ander</first><last>Soraluze</last></author>
      <author><first>Olatz</first><last>Arregi</last></author>
      <pages>35–41</pages>
      <abstract>In this paper, we present a cross-lingual neural coreference resolution system for a less-resourced language such as Basque. To begin with, we build the first neural coreference resolution system for Basque, training it with the relatively small EPEC-KORREF corpus (45,000 words). Next, a cross-lingual coreference resolution system is designed. With this approach, the system learns from a bigger English corpus, using cross-lingual embeddings, to perform the coreference resolution for Basque. The cross-lingual system obtains slightly better results (40.93 F1 CoNLL) than the monolingual system (39.12 F1 CoNLL), without using any Basque language corpus to train it.</abstract>
      <url>W19-2806</url>
    </paper>
  </volume>
  <volume id="29">
    <meta>
      <booktitle>Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics</booktitle>
      <url>W19-29</url>
      <editor><first>Emmanuele</first><last>Chersoni</last></editor>
      <editor><first>Cassandra</first><last>Jacobs</last></editor>
      <editor><first>Alessandro</first><last>Lenci</last></editor>
      <editor><first>Tal</first><last>Linzen</last></editor>
      <editor><first>Laurent</first><last>Prévot</last></editor>
      <editor><first>Enrico</first><last>Santus</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-2900</url>
    </frontmatter>
    <paper id="1">
      <title>The Active-Filler Strategy in a Move-Eager Left-Corner Minimalist Grammar Parser</title>
      <author><first>Tim</first><last>Hunter</last></author>
      <author><first>Miloš</first><last>Stanojević</last></author>
      <author><first>Edward</first><last>Stabler</last></author>
      <pages>1–10</pages>
      <abstract>Recent psycholinguistic evidence suggests that human parsing of moved elements is ‘active’, and perhaps even ‘hyper-active’: it seems that a leftward-moved object is related to a verbal position rapidly, perhaps even before the transitivity information associated with the verb is available to the listener. This paper presents a formal, sound and complete parser for Minimalist Grammars whose search space contains branching points that we can identify as the locus of the decision to perform this kind of active gap-finding. This brings formal models of parsing into closer contact with recent psycholinguistic theorizing than was previously possible.</abstract>
      <url>W19-2901</url>
    </paper>
    <paper id="2">
      <title>Priming vs. Inhibition of Optional Infinitival “to”</title>
      <author><first>Robin</first><last>Melnick</last></author>
      <author><first>Thomas</first><last>Wasow</last></author>
      <pages>11–19</pages>
      <abstract>The word “to” that precedes verbs in English infinitives is optional in at least two environments: in what Wasow et al. (2015) previously called the “do-be” construction, and in the complement of “help”, which we explore in the present work. In the “do-be” construction, Wasow et al. found that a preceding infinitival “to” increases the use of following optional “to”, but the use of “to” in the complement of help is reduced following “to help”. We examine two hypotheses regarding why the same function word is primed by prior use in one construction and inhibited in another. We then test predictions made by the two hypotheses, finding support for one of them.</abstract>
      <url>W19-2902</url>
    </paper>
    <paper id="3">
      <title>Simulating <fixed-case>S</fixed-case>panish-<fixed-case>E</fixed-case>nglish Code-Switching: El Modelo Está Generating Code-Switches</title>
      <author><first>Chara</first><last>Tsoukala</last></author>
      <author><first>Stefan L.</first><last>Frank</last></author>
      <author><first>Antal</first><last>van den Bosch</last></author>
      <author><first>Jorge</first><last>Valdés Kroff</last></author>
      <author><first>Mirjam</first><last>Broersma</last></author>
      <pages>20–29</pages>
      <abstract>Multilingual speakers are able to switch from one language to the other (“code-switch”) between or within sentences. Because the underlying cognitive mechanisms are not well understood, in this study we use computational cognitive modeling to shed light on the process of code-switching. We employed the Bilingual Dual-path model, a Recurrent Neural Network of bilingual sentence production (Tsoukala et al., 2017), and simulated sentence production in simultaneous Spanish-English bilinguals. Our first goal was to investigate whether the model would code-switch without being exposed to code-switched training input. The model indeed produced code-switches even without any exposure to such input and the patterns of code-switches are in line with earlier linguistic work (Poplack,1980). The second goal of this study was to investigate an auxiliary phrase asymmetry that exists in Spanish-English code-switched production. Using this cognitive model, we examined a possible cause for this asymmetry. To our knowledge, this is the first computational cognitive model that aims to simulate code-switched sentence production.</abstract>
      <url>W19-2903</url>
    </paper>
    <paper id="4">
      <title>Surprisal and Interference Effects of Case Markers in <fixed-case>H</fixed-case>indi Word Order</title>
      <author><first>Sidharth</first><last>Ranjan</last></author>
      <author><first>Sumeet</first><last>Agarwal</last></author>
      <author><first>Rajakrishnan</first><last>Rajkumar</last></author>
      <pages>30–42</pages>
      <abstract>Based on the Production-Distribution-Comprehension (PDC) account of language processing, we formulate two distinct hypotheses about case marking, word order choices and processing in Hindi. Our first hypothesis is that Hindi tends to optimize for processing efficiency at both lexical and syntactic levels. We quantify the role of case markers in this process. For the task of predicting the reference sentence occurring in a corpus (amidst meaning-equivalent grammatical variants) using a machine learning model, surprisal estimates from an artificial version of the language (i.e., Hindi without any case markers) result in lower prediction accuracy compared to natural Hindi. Our second hypothesis is that Hindi tends to minimize interference due to case markers while ordering preverbal constituents. We show that Hindi tends to avoid placing next to each other constituents whose heads are marked by identical case inflections. Our findings adhere to PDC assumptions and we discuss their implications for language production, learning and universals.</abstract>
      <url>W19-2904</url>
    </paper>
    <paper id="5">
      <title>Modeling Hierarchical Syntactic Structures in Morphological Processing</title>
      <author><first>Yohei</first><last>Oseki</last></author>
      <author><first>Charles</first><last>Yang</last></author>
      <author><first>Alec</first><last>Marantz</last></author>
      <pages>43–52</pages>
      <abstract>Sentences are represented as hierarchical syntactic structures, which have been successfully modeled in sentence processing. In contrast, despite the theoretical agreement on hierarchical syntactic structures within words, words have been argued to be computationally less complex than sentences and implemented by finite-state models as linear strings of morphemes, and even the psychological reality of morphemes has been denied. In this paper, extending the computational models employed in sentence processing to morphological processing, we performed a computational simulation experiment where, given incremental surprisal as a linking hypothesis, five computational models with different representational assumptions were evaluated against human reaction times in visual lexical decision experiments available from the English Lexicon Project (ELP), a “shared task” in the morphological processing literature. The simulation experiment demonstrated that (i) “amorphous” models without morpheme units underperformed relative to “morphous” models, (ii) a computational model with hierarchical syntactic structures, Probabilistic Context-Free Grammar (PCFG), most accurately explained human reaction times, and (iii) this performance was achieved on top of surface frequency effects. These results strongly suggest that morphological processing tracks morphemes incrementally from left to right and parses them into hierarchical syntactic structures, contrary to “amorphous” and finite-state models of morphological processing.</abstract>
      <url>W19-2905</url>
    </paper>
    <paper id="6">
      <title>A Modeling Study of the Effects of Surprisal and Entropy in Perceptual Decision Making of an Adaptive Agent</title>
      <author><first>Pyeong Whan</first><last>Cho</last></author>
      <author><first>Richard</first><last>Lewis</last></author>
      <pages>53–61</pages>
      <abstract>Processing difficulty in online language comprehension has been explained in terms of surprisal and entropy reduction. Although both hypotheses have been supported by experimental data, we do not fully understand their relative contributions on processing difficulty. To develop a better understanding, we propose a mechanistic model of perceptual decision making that interacts with a simulated task environment with temporal dynamics. The proposed model collects noisy bottom-up evidence over multiple timesteps, integrates it with its top-down expectation, and makes perceptual decisions, producing processing time data directly without relying on any linking hypothesis. Temporal dynamics in the task environment was determined by a simple finite-state grammar, which was designed to create the situations where the surprisal and entropy reduction hypotheses predict different patterns. After the model was trained to maximize rewards, the model developed an adaptive policy and both surprisal and entropy effects were observed especially in a measure reflecting earlier processing.</abstract>
      <url>W19-2906</url>
    </paper>
    <paper id="7">
      <title>Modeling Long-Distance Cue Integration in Spoken Word Recognition</title>
      <author><first>Wednesday</first><last>Bushong</last></author>
      <author><first>T. Florian</first><last>Jaeger</last></author>
      <pages>62–70</pages>
      <abstract>Cues to linguistic categories are distributed across the speech signal. Optimal categorization thus requires that listeners maintain gradient representations of incoming input in order to integrate that information with later cues. There is now evidence that listeners can and do integrate cues that occur far apart in time. Computational models of this integration have however been lacking. We take a first step at addressing this gap by mathematically formalizing four models of how listeners may maintain and use cue information during spoken language understanding and test them on two perception experiments. In one experiment, we find support for rational integration of cues at long distances. In a second, more memory and attention-taxing experiment, we find evidence in favor of a switching model that avoids maintaining detailed representations of cues in memory. These results are a first step in understanding what kinds of mechanisms listeners use for cue integration under different memory and attentional constraints.</abstract>
      <url>W19-2907</url>
    </paper>
    <paper id="8">
      <title>Toward a Computational Multidimensional Lexical Similarity Measure for Modeling Word Association Tasks in Psycholinguistics</title>
      <author><first>Bruno</first><last>Gaume</last></author>
      <author><first>Lydia</first><last>Mai Ho-Dac</last></author>
      <author><first>Ludovic</first><last>Tanguy</last></author>
      <author><first>Cécile</first><last>Fabre</last></author>
      <author><first>Bénédicte</first><last>Pierrejean</last></author>
      <author><first>Nabil</first><last>Hathout</last></author>
      <author><first>Jérôme</first><last>Farinas</last></author>
      <author><first>Julien</first><last>Pinquier</last></author>
      <author><first>Lola</first><last>Danet</last></author>
      <author><first>Patrice</first><last>Péran</last></author>
      <author><first>Xavier</first><last>De Boissezon</last></author>
      <author><first>Mélanie</first><last>Jucla</last></author>
      <pages>71–76</pages>
      <abstract>This paper presents the first results of a multidisciplinary project, the “Evolex” project, gathering researchers in Psycholinguistics, Neuropsychology, Computer Science, Natural Language Processing and Linguistics. The Evolex project aims at proposing a new data-based inductive method for automatically characterising the relation between pairs of french words collected in psycholinguistics experiments on lexical access. This method takes advantage of several complementary computational measures of semantic similarity. We show that some measures are more correlated than others with the frequency of lexical associations, and that they also differ in the way they capture different semantic relations. This allows us to consider building a multidimensional lexical similarity to automate the classification of lexical associations.</abstract>
      <url>W19-2908</url>
    </paper>
    <paper id="9">
      <title>Dependency Parsing with your Eyes: Dependency Structure Predicts Eye Regressions During Reading</title>
      <author><first>Alessandro</first><last>Lopopolo</last></author>
      <author><first>Stefan L.</first><last>Frank</last></author>
      <author><first>Antal</first><last>van den Bosch</last></author>
      <author><first>Roel</first><last>Willems</last></author>
      <pages>77–85</pages>
      <abstract>Backward saccades during reading have been hypothesized to be involved in structural reanalysis, or to be related to the level of text difficulty. We test the hypothesis that backward saccades are involved in online syntactic analysis. If this is the case we expect that saccades will coincide, at least partially, with the edges of the relations computed by a dependency parser. In order to test this, we analyzed a large eye-tracking dataset collected while 102 participants read three short narrative texts. Our results show a relation between backward saccades and the syntactic structure of sentences.</abstract>
      <url>W19-2909</url>
    </paper>
    <paper id="10">
      <title>A Framework for Decoding Event-Related Potentials from Text</title>
      <author><first>Shaorong</first><last>Yan</last></author>
      <author><first>Aaron Steven</first><last>White</last></author>
      <pages>86–92</pages>
      <abstract>We propose a novel framework for modeling event-related potentials (ERPs) collected during reading that couples pre-trained convolutional decoders with a language model. Using this framework, we compare the abilities of a variety of existing and novel sentence processing models to reconstruct ERPs. We find that modern contextual word embeddings underperform surprisal-based models but that, combined, the two outperform either on its own.</abstract>
      <url>W19-2910</url>
    </paper>
    <paper id="11">
      <title>Testing a Minimalist Grammar Parser on <fixed-case>I</fixed-case>talian Relative Clause Asymmetries</title>
      <author><first>Aniello</first><last>De Santo</last></author>
      <pages>93–104</pages>
      <abstract>Stabler’s (2013) top-down parser for Minimalist grammars has been used to account for off-line processing preferences across a variety of seemingly unrelated phenomena cross- linguistically, via complexity metrics measuring “memory burden”. This paper extends the empirical coverage of the model by looking at the processing asymmetries of Italian relative clauses, as I discuss the relevance of these constructions in evaluating plausible structure- driven models of processing difficulty.</abstract>
      <url>W19-2911</url>
    </paper>
    <paper id="12">
      <title>Quantifiers in a Multimodal World: Hallucinating Vision with Language and Sound</title>
      <author><first>Alberto</first><last>Testoni</last></author>
      <author><first>Sandro</first><last>Pezzelle</last></author>
      <author><first>Raffaella</first><last>Bernardi</last></author>
      <pages>105–116</pages>
      <abstract>Inspired by the literature on multisensory integration, we develop a computational model to ground quantifiers in perception. The model learns to pick, out of nine quantifiers (‘few’, ‘many’, ‘all’, etc.), the one that is more likely to describe the percent of animals in a visual-auditory input containing both animals and artifacts. We show that relying on concurrent sensory inputs increases model performance on the quantification task. Moreover, we evaluate the model in a situation in which only the auditory modality is given, while the visual one is ‘hallucinanted’ either from the auditory input itself or from a linguistic caption describing the quantity of entities in the auditory input. This way, the model exploits prior associations between modalities. We show that the model profits from the prior knowledge and outperforms the auditory-only setting.</abstract>
      <url>W19-2912</url>
    </paper>
    <paper id="13">
      <title>Frequency vs. Association for Constraint Selection in Usage-Based Construction Grammar</title>
      <author><first>Jonathan</first><last>Dunn</last></author>
      <pages>117–128</pages>
      <abstract>A usage-based Construction Grammar (CxG) posits that slot-constraints generalize from common exemplar constructions. But what is the best model of constraint generalization? This paper evaluates competing frequency-based and association-based models across eight languages using a metric derived from the Minimum Description Length paradigm. The experiments show that association-based models produce better generalizations across all languages by a significant margin.</abstract>
      <url>W19-2913</url>
      <software>W19-2913.Software.zip</software>
    </paper>
    <paper id="14">
      <title>The Development of Abstract Concepts in Children’s Early Lexical Networks</title>
      <author><first>Abdellah</first><last>Fourtassi</last></author>
      <author><first>Isaac</first><last>Scheinfeld</last></author>
      <author><first>Michael</first><last>Frank</last></author>
      <pages>129–133</pages>
      <abstract>How do children learn abstract concepts such as animal vs. artifact? Previous research has suggested that such concepts can partly be derived using cues from the language children hear around them. Following this suggestion, we propose a model where we represent the children’ developing lexicon as an evolving network. The nodes of this network are based on vocabulary knowledge as reported by parents, and the edges between pairs of nodes are based on the probability of their co-occurrence in a corpus of child-directed speech. We found that several abstract categories can be identified as the dense regions in such networks. In addition, our simulations suggest that these categories develop simultaneously, rather than sequentially, thanks to the children’s word learning trajectory which favors the exploration of the global conceptual space.</abstract>
      <url>W19-2914</url>
    </paper>
    <paper id="15">
      <title>Verb-Second Effect on Quantifier Scope Interpretation</title>
      <author><first>Asad</first><last>Sayeed</last></author>
      <author><first>Matthias</first><last>Lindemann</last></author>
      <author><first>Vera</first><last>Demberg</last></author>
      <pages>134–139</pages>
      <abstract>Sentences like “Every child climbed a tree” have at least two interpretations depending on the precedence order of the universal quantifier and the indefinite. Previous experimental work explores the role that different mechanisms such as semantic reanalysis and world knowledge may have in enabling each interpretation. This paper discusses a web-based task that uses the verb-second characteristic of German main clauses to estimate the influence of word order variation over world knowledge.</abstract>
      <url>W19-2915</url>
    </paper>
    <paper id="16">
      <title>Neural Models of the Psychosemantics of ‘Most’</title>
      <author><first>Lewis</first><last>O’Sullivan</last></author>
      <author><first>Shane</first><last>Steinert-Threlkeld</last></author>
      <pages>140–151</pages>
      <abstract>How are the meanings of linguistic expressions related to their use in concrete cognitive tasks? Visual identification tasks show human speakers can exhibit considerable variation in their understanding, representation and verification of certain quantifiers. This paper initiates an investigation into neural models of these psycho-semantic tasks. We trained two types of network – a convolutional neural network (CNN) model and a recurrent model of visual attention (RAM) – on the “most” verification task from Pietroski2009, manipulating the visual scene and novel notions of task duration. Our results qualitatively mirror certain features of human performance (such as sensitivity to the ratio of set sizes, indicating a reliance on approximate number) while differing in interesting ways (such as exhibiting a subtly different pattern for the effect of image type). We conclude by discussing the prospects for using neural models as cognitive models of this and other psychosemantic tasks.</abstract>
      <url>W19-2916</url>
    </paper>
    <paper id="17">
      <title>The Role of Utterance Boundaries and Word Frequencies for Part-of-speech Learning in <fixed-case>B</fixed-case>razilian <fixed-case>P</fixed-case>ortuguese Through Distributional Analysis</title>
      <author><first>Pablo Picasso</first><last>Feliciano de Faria</last></author>
      <pages>152–159</pages>
      <abstract>In this study, we address the problem of part-of-speech (or syntactic category) learning during language acquisition through distributional analysis of utterances. A model based on Redington et al.’s (1998) distributional learner is used to investigate the informativeness of distributional information in Brazilian Portuguese (BP). The data provided to the learner comes from two publicly available corpora of child directed speech. We present preliminary results from two experiments. The first one investigates the effects of different assumptions about utterance boundaries when presenting the input data to the learner. The second experiment compares the learner’s performance when counting contextual words’ frequencies versus just acknowledging their co-occurrence with a given target word. In general, our results indicate that explicit boundaries are more informative, frequencies are important, and that distributional information is useful to the child as a source of categorial information. These results are in accordance with Redington et al.’s findings for English.</abstract>
      <url>W19-2917</url>
    </paper>
    <paper id="18">
      <title>Using Grounded Word Representations to Study Theories of Lexical Concepts</title>
      <author><first>Dylan</first><last>Ebert</last></author>
      <author><first>Ellie</first><last>Pavlick</last></author>
      <pages>160–169</pages>
      <abstract>The fields of cognitive science and philosophy have proposed many different theories for how humans represent “concepts”. Multiple such theories are compatible with state-of-the-art NLP methods, and could in principle be operationalized using neural networks. We focus on two particularly prominent theories–Classical Theory and Prototype Theory–in the context of visually-grounded lexical representations. We compare when and how the behavior of models based on these theories differs in terms of categorization and entailment tasks. Our preliminary results suggest that Classical-based representations perform better for entailment and Prototype-based representations perform better for categorization. We discuss plans for additional experiments needed to confirm these initial observations.</abstract>
      <url>W19-2918</url>
    </paper>
  </volume>
  <volume id="30">
    <meta>
      <booktitle>Proceedings of the Sixth Workshop on Computational Linguistics and Clinical Psychology</booktitle>
      <url>W19-30</url>
      <editor><first>Kate</first><last>Niederhoffer</last></editor>
      <editor><first>Kristy</first><last>Hollingshead</last></editor>
      <editor><first>Philip</first><last>Resnik</last></editor>
      <editor><first>Rebecca</first><last>Resnik</last></editor>
      <editor><first>Kate</first><last>Loveys</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Minneapolis, Minnesota</address>
      <month>June</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-3000</url>
    </frontmatter>
    <paper id="1">
      <title>Towards augmenting crisis counselor training by improving message retrieval</title>
      <author><first>Orianna</first><last>Demasi</last></author>
      <author><first>Marti A.</first><last>Hearst</last></author>
      <author><first>Benjamin</first><last>Recht</last></author>
      <pages>1–11</pages>
      <abstract>A fundamental challenge when training counselors is presenting novices with the opportunity to practice counseling distressed individuals without exacerbating a situation. Rather than replacing human empathy with an automated counselor, we propose simulating an individual in crisis so that human counselors in training can practice crisis counseling in a low-risk environment. Towards this end, we collect a dataset of suicide prevention counselor role-play transcripts and make initial steps towards constructing a CRISISbot for humans to counsel while in training. In this data-constrained setting, we evaluate the potential for message retrieval to construct a coherent chat agent in light of recent advances with text embedding methods. Our results show that embeddings can considerably improve retrieval approaches to make them competitive with generative models. By coherently retrieving messages, we can help counselors practice chatting in a low-risk environment.</abstract>
      <url>W19-3001</url>
    </paper>
    <paper id="2">
      <title>Identifying therapist conversational actions across diverse psychotherapeutic approaches</title>
      <author><first>Fei-Tzin</first><last>Lee</last></author>
      <author><first>Derrick</first><last>Hull</last></author>
      <author><first>Jacob</first><last>Levine</last></author>
      <author><first>Bonnie</first><last>Ray</last></author>
      <author><first>Kathy</first><last>McKeown</last></author>
      <pages>12–23</pages>
      <abstract>While conversation in therapy sessions can vary widely in both topic and style, an understanding of the underlying techniques used by therapists can provide valuable insights into how therapists best help clients of different types. Dialogue act classification aims to identify the conversational “action” each speaker takes at each utterance, such as sympathizing, problem-solving or assumption checking. We propose to apply dialogue act classification to therapy transcripts, using a therapy-specific labeling scheme, in order to gain a high-level understanding of the flow of conversation in therapy sessions. We present a novel annotation scheme that spans multiple psychotherapeutic approaches, apply it to a large and diverse corpus of psychotherapy transcripts, and present and discuss classification results obtained using both SVM and neural network-based models. The results indicate that identifying the structure and flow of therapeutic actions is an obtainable goal, opening up the opportunity in the future to provide therapeutic recommendations tailored to specific client situations.</abstract>
      <url>W19-3002</url>
    </paper>
    <paper id="3">
      <title><fixed-case>CLP</fixed-case>sych 2019 Shared Task: Predicting the Degree of Suicide Risk in <fixed-case>R</fixed-case>eddit Posts</title>
      <author><first>Ayah</first><last>Zirikly</last></author>
      <author><first>Philip</first><last>Resnik</last></author>
      <author><first>Özlem</first><last>Uzuner</last></author>
      <author><first>Kristy</first><last>Hollingshead</last></author>
      <pages>24–33</pages>
      <abstract>The shared task for the 2019 Workshop on Computational Linguistics and Clinical Psychology (CLPsych’19) introduced an assessment of suicide risk based on social media postings, using data from Reddit to identify users at no, low, moderate, or severe risk. Two variations of the task focused on users whose posts to the r/SuicideWatch subreddit indicated they might be at risk; a third task looked at screening users based only on their more everyday (non-SuicideWatch) posts. We received submissions from 15 different teams, and the results provide progress and insight into the value of language signal in helping to predict risk level.</abstract>
      <url>W19-3003</url>
    </paper>
    <paper id="4">
      <title><fixed-case>CL</fixed-case>a<fixed-case>C</fixed-case> at <fixed-case>CLP</fixed-case>sych 2019: Fusion of Neural Features and Predicted Class Probabilities for Suicide Risk Assessment Based on Online Posts</title>
      <author><first>Elham</first><last>Mohammadi</last></author>
      <author><first>Hessam</first><last>Amini</last></author>
      <author><first>Leila</first><last>Kosseim</last></author>
      <pages>34–38</pages>
      <abstract>This paper summarizes our participation to the CLPsych 2019 shared task, under the name CLaC. The goal of the shared task was to detect and assess suicide risk based on a collection of online posts. For our participation, we used an ensemble method which utilizes 8 neural sub-models to extract neural features and predict class probabilities, which are then used by an SVM classifier. Our team ranked first in 2 out of the 3 tasks (tasks A and C).</abstract>
      <url>W19-3004</url>
    </paper>
    <paper id="5">
      <title>Suicide Risk Assessment with Multi-level Dual-Context Language and <fixed-case>BERT</fixed-case></title>
      <author><first>Matthew</first><last>Matero</last></author>
      <author><first>Akash</first><last>Idnani</last></author>
      <author><first>Youngseo</first><last>Son</last></author>
      <author><first>Sal</first><last>Giorgi</last></author>
      <author><first>Huy</first><last>Vu</last></author>
      <author><first>Mohammad</first><last>Zamani</last></author>
      <author><first>Parth</first><last>Limbachiya</last></author>
      <author><first>Sharath Chandra</first><last>Guntuku</last></author>
      <author><first>H. Andrew</first><last>Schwartz</last></author>
      <pages>39–44</pages>
      <abstract>Mental health predictive systems typically model language as if from a single context (e.g. Twitter posts, status updates, or forum posts) and often limited to a single level of analysis (e.g. either the message-level or user-level). Here, we bring these pieces together to explore the use of open-vocabulary (BERT embeddings, topics) and theoretical features (emotional expression lexica, personality) for the task of suicide risk assessment on support forums (the CLPsych-2019 Shared Task). We used dual context based approaches (modeling content from suicide forums separate from other content), built over both traditional ML models as well as a novel dual RNN architecture with user-factor adaptation. We find that while affect from the suicide context distinguishes with no-risk from those with “any-risk”, personality factors from the non-suicide contexts provide distinction of the levels of risk: low, medium, and high risk. Within the shared task, our dual-context approach (listed as SBU-HLAB in the official results) achieved state-of-the-art performance predicting suicide risk using a combination of suicide-context and non-suicide posts (Task B), achieving an F1 score of 0.50 over hidden test set labels.</abstract>
      <url>W19-3005</url>
    </paper>
    <paper id="6">
      <title>Using natural conversations to classify autism with limited data: Age matters</title>
      <author><first>Michael</first><last>Hauser</last></author>
      <author><first>Evangelos</first><last>Sariyanidi</last></author>
      <author><first>Birkan</first><last>Tunc</last></author>
      <author><first>Casey</first><last>Zampella</last></author>
      <author><first>Edward</first><last>Brodkin</last></author>
      <author><first>Robert</first><last>Schultz</last></author>
      <author><first>Julia</first><last>Parish-Morris</last></author>
      <pages>45–54</pages>
      <abstract>Spoken language ability is highly heterogeneous in Autism Spectrum Disorder (ASD), which complicates efforts to identify linguistic markers for use in diagnostic classification, clinical characterization, and for research and clinical outcome measurement. Machine learning techniques that harness the power of multivariate statistics and non-linear data analysis hold promise for modeling this heterogeneity, but many models require enormous datasets, which are unavailable for most psychiatric conditions (including ASD). In lieu of such datasets, good models can still be built by leveraging domain knowledge. In this study, we compare two machine learning approaches: the first approach incorporates prior knowledge about language variation across middle childhood, adolescence, and adulthood to classify 6-minute naturalistic conversation samples from 140 age- and IQ-matched participants (81 with ASD), while the other approach treats all ages the same. We found that individual age-informed models were significantly more accurate than a single model tasked with building a common algorithm across age groups. Furthermore, predictive linguistic features differed significantly by age group, confirming the importance of considering age-related changes in language use when classifying ASD. Our results suggest that limitations imposed by heterogeneity inherent to ASD and from developmental change with age can be (at least partially) overcome using domain knowledge, such as understanding spoken language development from childhood through adulthood.</abstract>
      <url>W19-3006</url>
    </paper>
    <paper id="7">
      <title>The importance of sharing patient-generated clinical speech and language data</title>
      <author><first>Kathleen C.</first><last>Fraser</last></author>
      <author><first>Nicklas</first><last>Linz</last></author>
      <author><first>Hali</first><last>Lindsay</last></author>
      <author><first>Alexandra</first><last>König</last></author>
      <pages>55–61</pages>
      <abstract>Increased access to large datasets has driven progress in NLP. However, most computational studies of clinically-validated, patient-generated speech and language involve very few datapoints, as such data are difficult (and expensive) to collect. In this position paper, we argue that we must find ways to promote data sharing across research groups, in order to build datasets of a more appropriate size for NLP and machine learning analysis. We review the benefits and challenges of sharing clinical language data, and suggest several concrete actions by both clinical and NLP researchers to encourage multi-site and multi-disciplinary data sharing. We also propose the creation of a collaborative data sharing platform, to allow NLP researchers to take a more active responsibility for data transcription, annotation, and curation.</abstract>
      <url>W19-3007</url>
    </paper>
    <paper id="8">
      <title>Depressed Individuals Use Negative Self-Focused Language When Recalling Recent Interactions with Close Romantic Partners but Not Family or <fixed-case>F</fixed-case>riends</title>
      <author><first>Taleen</first><last>Nalabandian</last></author>
      <author><first>Molly</first><last>Ireland</last></author>
      <pages>62–73</pages>
      <abstract>Depression is characterized by a self-focused negative attentional bias, which is often reflected in everyday language use. In a prospective writing study, we explored whether the association between depressive symptoms and negative, self-focused language varies across social contexts. College students (N = 243) wrote about a recent interaction with a person they care deeply about. Depression symptoms positively correlated with negative emotion words and first-person singular pronouns (or negative self-focus) when writing about a recent interaction with romantic partners or, to a lesser extent, friends, but not family members. The pattern of results was more pronounced when participants perceived greater self-other overlap (i.e., interpersonal closeness) with their romantic partner. Findings regarding how the linguistic profile of depression differs by type of relationship may inform more effective methods of clinical diagnosis and treatment.</abstract>
      <url>W19-3008</url>
    </paper>
    <paper id="9">
      <title>Linguistic Analysis of Schizophrenia in <fixed-case>R</fixed-case>eddit Posts</title>
      <author><first>Jonathan</first><last>Zomick</last></author>
      <author><first>Sarah Ita</first><last>Levitan</last></author>
      <author><first>Mark</first><last>Serper</last></author>
      <pages>74–83</pages>
      <abstract>We explore linguistic indicators of schizophrenia in Reddit discussion forums. Schizophrenia (SZ) is a chronic mental disorder that affects a person’s thoughts and behaviors. Identifying and detecting signs of SZ is difficult given that SZ is relatively uncommon, affecting approximately 1% of the US population, and people suffering with SZ often believe that they do not have the disorder. Linguistic abnormalities are a hallmark of SZ and many of the illness’s symptoms are manifested through language. In this paper we leverage the vast amount of data available from social media and use statistical and machine learning approaches to study linguistic characteristics of SZ. We collected and analyzed a large corpus of Reddit posts from users claiming to have received a formal diagnosis of SZ and identified several linguistic features that differentiated these users from a control (CTL) group. We compared these results to other findings on social media linguistic analysis and SZ. We also developed a machine learning classifier to automatically identify self-identified users with SZ on Reddit.</abstract>
      <url>W19-3009</url>
    </paper>
    <paper id="10">
      <title>Semantic Characteristics of Schizophrenic Speech</title>
      <author><first>Kfir</first><last>Bar</last></author>
      <author><first>Vered</first><last>Zilberstein</last></author>
      <author><first>Ido</first><last>Ziv</last></author>
      <author><first>Heli</first><last>Baram</last></author>
      <author><first>Nachum</first><last>Dershowitz</last></author>
      <author><first>Samuel</first><last>Itzikowitz</last></author>
      <author><first>Eiran</first><last>Vadim Harel</last></author>
      <pages>84–93</pages>
      <abstract>Natural language processing tools are used to automatically detect disturbances in transcribed speech of schizophrenia inpatients who speak Hebrew. We measure topic mutation over time and show that controls maintain more cohesive speech than inpatients. We also examine differences in how inpatients and controls use adjectives and adverbs to describe content words and show that the ones used by controls are more common than the those of inpatients. We provide experimental results and show their potential for automatically detecting schizophrenia in patients by means only of their speech patterns.</abstract>
      <url>W19-3010</url>
    </paper>
    <paper id="11">
      <title>Computational Linguistics for Enhancing Scientific Reproducibility and Reducing Healthcare Inequities</title>
      <author><first>Julia</first><last>Parish-Morris</last></author>
      <pages>94–102</pages>
      <abstract>Computational linguistics holds promise for improving scientific integrity in clinical psychology, and for reducing longstanding inequities in healthcare access and quality. This paper describes how computational linguistics approaches could address the “reproducibility crisis” facing social science, particularly with regards to reliable diagnosis of neurodevelopmental and psychiatric conditions including autism spectrum disorder (ASD). It is argued that these improvements in scientific integrity are poised to naturally reduce persistent healthcare inequities in neglected subpopulations, such as verbally fluent girls and women with ASD, but that concerted attention to this issue is necessary to avoid reproducing biases built into training data. Finally, it is suggested that computational linguistics is just one component of an emergent digital phenotyping toolkit that could ultimately be used for clinical decision support, to improve clinical care via precision medicine (i.e., personalized intervention planning), granular treatment response monitoring (including remotely), and for gene-brain-behavior studies aiming to pinpoint the underlying biological etiology of otherwise behaviorally-defined conditions like ASD.</abstract>
      <url>W19-3011</url>
    </paper>
    <paper id="12">
      <title>Temporal Analysis of the Semantic Verbal Fluency Task in Persons with Subjective and Mild Cognitive Impairment</title>
      <author><first>Nicklas</first><last>Linz</last></author>
      <author><first>Kristina</first><last>Lundholm Fors</last></author>
      <author><first>Hali</first><last>Lindsay</last></author>
      <author><first>Marie</first><last>Eckerström</last></author>
      <author><first>Jan</first><last>Alexandersson</last></author>
      <author><first>Dimitrios</first><last>Kokkinakis</last></author>
      <pages>103–113</pages>
      <abstract>The Semantic Verbal Fluency (SVF) task is a classical neuropsychological assessment where persons are asked to produce words belonging to a semantic category (e.g., animals) in a given time. This paper introduces a novel method of temporal analysis for SVF tasks utilizing time intervals and applies it to a corpus of elderly Swedish subjects (mild cognitive impairment, subjective cognitive impairment and healthy controls). A general decline in word count and lexical frequency over the course of the task is revealed, as well as an increase in word transition times. Persons with subjective cognitive impairment had a higher word count during the last intervals, but produced words of the same lexical frequencies. Persons with MCI had a steeper decline in both word count and lexical frequencies during the third interval. Additional correlations with neuropsychological scores suggest these findings are linked to a person’s overall vocabulary size and processing speed, respectively. Classification results improved when adding the novel features (<tex-math>\mathit{AUC}=0.72</tex-math>), supporting their diagnostic value.</abstract>
      <url>W19-3012</url>
    </paper>
    <paper id="13">
      <title>Mental Health Surveillance over Social Media with Digital Cohorts</title>
      <author><first>Silvio</first><last>Amir</last></author>
      <author><first>Mark</first><last>Dredze</last></author>
      <author><first>John W.</first><last>Ayers</last></author>
      <pages>114–120</pages>
      <abstract>The ability to track mental health conditions via social media opened the doors for large-scale, automated, mental health surveillance. However, inferring accurate population-level trends requires representative samples of the underlying population, which can be challenging given the biases inherent in social media data. While previous work has adjusted samples based on demographic estimates, the populations were selected based on specific outcomes, e.g. specific mental health conditions. We depart from these methods, by conducting analyses over demographically representative digital cohorts of social media users. To validated this approach, we constructed a cohort of US based Twitter users to measure the prevalence of depression and PTSD, and investigate how these illnesses manifest across demographic subpopulations. The analysis demonstrates that cohort-based studies can help control for sampling biases, contextualize outcomes, and provide deeper insights into the data.</abstract>
      <url>W19-3013</url>
    </paper>
    <paper id="14">
      <title>Reviving a psychometric measure: Classification and prediction of the Operant Motive Test</title>
      <author><first>Dirk</first><last>Johannßen</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <author><first>David</first><last>Scheffer</last></author>
      <pages>121–125</pages>
      <abstract>Implicit motives allow for the characterization of behavior, subsequent success and long-term development. While this has been operationalized in the operant motive test, research on motives has declined mainly due to labor-intensive and costly human annotation. In this study, we analyze over 200,000 labeled data items from 40,000 participants and utilize them for engineering features for training a logistic model tree machine learning model. It captures manually assigned motives well with an F-score of 80%, coming close to the pairwise annotator intraclass correlation coefficient of r = .85. In addition, we found a significant correlation of r = .2 between subsequent academic success and data automatically labeled with our model in an extrinsic evaluation.</abstract>
      <url>W19-3014</url>
    </paper>
    <paper id="15">
      <title>Coherence models in schizophrenia</title>
      <author><first>Sandra</first><last>Just</last></author>
      <author><first>Erik</first><last>Haegert</last></author>
      <author><first>Nora</first><last>Kořánová</last></author>
      <author><first>Anna-Lena</first><last>Bröcker</last></author>
      <author><first>Ivan</first><last>Nenchev</last></author>
      <author><first>Jakob</first><last>Funcke</last></author>
      <author><first>Christiane</first><last>Montag</last></author>
      <author><first>Manfred</first><last>Stede</last></author>
      <pages>126–136</pages>
      <abstract>Incoherent discourse in schizophrenia has long been recognized as a dominant symptom of the mental disorder (Bleuler, 1911/1950). Recent studies have used modern sentence and word embeddings to compute coherence metrics for spontaneous speech in schizophrenia. While clinical ratings always have a subjective element, computational linguistic methodology allows quantification of speech abnormalities. Clinical and empirical knowledge from psychiatry provide the theoretical and conceptual basis for modelling. Our study is an interdisciplinary attempt at improving coherence models in schizophrenia. Speech samples were obtained from healthy controls and patients with a diagnosis of schizophrenia or schizoaffective disorder and different severity of positive formal thought disorder. Interviews were transcribed and coherence metrics derived from different embeddings. One model found higher coherence metrics for controls than patients. All other models remained non-significant. More detailed analysis of the data motivates different approaches to improving coherence models in schizophrenia, e.g. by assessing referential abnormalities.</abstract>
      <url>W19-3015</url>
    </paper>
    <paper id="16">
      <title>Overcoming the bottleneck in traditional assessments of verbal memory: Modeling human ratings and classifying clinical group membership</title>
      <author><first>Chelsea</first><last>Chandler</last></author>
      <author><first>Peter W.</first><last>Foltz</last></author>
      <author><first>Jian</first><last>Cheng</last></author>
      <author><first>Jared C.</first><last>Bernstein</last></author>
      <author><first>Elizabeth P.</first><last>Rosenfeld</last></author>
      <author><first>Alex S.</first><last>Cohen</last></author>
      <author><first>Terje B.</first><last>Holmlund</last></author>
      <author><first>Brita</first><last>Elvevåg</last></author>
      <pages>137–147</pages>
      <abstract>Verbal memory is affected by numerous clinical conditions and most neuropsychological and clinical examinations evaluate it. However, a bottleneck exists in such endeavors because traditional methods require expert human review, and usually only a couple of test versions exist, thus limiting the frequency of administration and clinical applications. The present study overcomes this bottleneck by automating the administration, transcription, analysis and scoring of story recall. A large group of healthy participants (n = 120) and patients with mental illness (n = 105) interacted with a mobile application that administered a wide range of assessments, including verbal memory. The resulting speech generated by participants when retelling stories from the memory task was transcribed using automatic speech recognition tools, which was compared with human transcriptions (overall word error rate = 21%). An assortment of surface-level and semantic language-based features were extracted from the verbal recalls. A final set of three features were used to both predict expert human ratings with a ridge regression model (r = 0.88) and to differentiate patients from healthy individuals with an ensemble of logistic regression classifiers (accuracy = 76%). This is the first ‘outside of the laboratory’ study to showcase the viability of the complete pipeline of automated assessment of verbal memory in naturalistic settings.</abstract>
      <url>W19-3016</url>
    </paper>
    <paper id="17">
      <title>Analyzing the use of existing systems for the <fixed-case>CLP</fixed-case>sych 2019 Shared Task</title>
      <author><first>Alejandro</first><last>González Hevia</last></author>
      <author><first>Rebeca</first><last>Cerezo Menéndez</last></author>
      <author><first>Daniel</first><last>Gayo-Avello</last></author>
      <pages>148–151</pages>
      <abstract>In this paper we describe the UniOvi-WESO classification systems proposed for the 2019 Computational Linguistics and Clinical Psychology (CLPsych) Shared Task. We explore the use of two systems trained with ReachOut data from the 2016 CLPsych task, and compare them to a baseline system trained with the data provided for this task. All the classifiers were trained with features extracted just from the text of each post, without using any other metadata. We found out that the baseline system performs slightly better than the pretrained systems, mainly due to the differences in labeling between the two tasks. However, they still work reasonably well and can detect if a user is at risk of suicide or not.</abstract>
      <url>W19-3017</url>
    </paper>
    <paper id="18">
      <title>Similar Minds Post Alike: Assessment of Suicide Risk Using a Hybrid Model</title>
      <author><first>Lushi</first><last>Chen</last></author>
      <author><first>Abeer</first><last>Aldayel</last></author>
      <author><first>Nikolay</first><last>Bogoychev</last></author>
      <author><first>Tao</first><last>Gong</last></author>
      <pages>152–157</pages>
      <abstract>This paper describes our system submission for the CLPsych 2019 shared task B on suicide risk assessment. We approached the problem with three separate models: a behaviour model; a language model and a hybrid model. For the behavioral model approach, we model each user’s behaviour and thoughts with four groups of features: posting behaviour, sentiment, motivation, and content of the user’s posting. We use these features as an input in a support vector machine (SVM). For the language model approach, we trained a language model for each risk level using all the posts from the users as the training corpora. Then, we computed the perplexity of each user’s posts to determine how likely his/her posts were to belong to each risk level. Finally, we built a hybrid model that combines both the language model and the behavioral model, which demonstrates the best performance in detecting the suicide risk level.</abstract>
      <url>W19-3018</url>
    </paper>
    <paper id="19">
      <title>Predicting Suicide Risk from Online Postings in <fixed-case>R</fixed-case>eddit The <fixed-case>UG</fixed-case>ent-<fixed-case>IDL</fixed-case>ab submission to the <fixed-case>CLP</fixed-case>ysch 2019 Shared Task A</title>
      <author><first>Semere Kiros</first><last>Bitew</last></author>
      <author><first>Giannis</first><last>Bekoulis</last></author>
      <author><first>Johannes</first><last>Deleu</last></author>
      <author><first>Lucas</first><last>Sterckx</last></author>
      <author><first>Klim</first><last>Zaporojets</last></author>
      <author><first>Thomas</first><last>Demeester</last></author>
      <author><first>Chris</first><last>Develder</last></author>
      <pages>158–161</pages>
      <abstract>This paper describes IDLab’s text classification systems submitted to Task A as part of the CLPsych 2019 shared task. The aim of this shared task was to develop automated systems that predict the degree of suicide risk of people based on their posts on Reddit. Bag-of-words features, emotion features and post level predictions are used to derive user-level predictions. Linear models and ensembles of these models are used to predict final scores. We find that predicting fine-grained risk levels is much more difficult than flagging potentially at-risk users. Furthermore, we do not find clear added value from building richer ensembles compared to simple baselines, given the available training data and the nature of the prediction task.</abstract>
      <url>W19-3019</url>
    </paper>
    <paper id="20">
      <title><fixed-case>CLP</fixed-case>sych2019 Shared Task: Predicting Suicide Risk Level from <fixed-case>R</fixed-case>eddit Posts on Multiple Forums</title>
      <author><first>Victor</first><last>Ruiz</last></author>
      <author><first>Lingyun</first><last>Shi</last></author>
      <author><first>Wei</first><last>Quan</last></author>
      <author><first>Neal</first><last>Ryan</last></author>
      <author><first>Candice</first><last>Biernesser</last></author>
      <author><first>David</first><last>Brent</last></author>
      <author><first>Rich</first><last>Tsui</last></author>
      <pages>162–166</pages>
      <abstract>We aimed to predict an individual suicide risk level from longitudinal posts on Reddit discussion forums. Through participating in a shared task competition hosted by CLPsych2019, we received two annotated datasets: a training dataset with 496 users (31,553 posts) and a test dataset with 125 users (9610 posts). We submitted results from our three best-performing machine-learning models: SVM, Naïve Bayes, and an ensemble model. Each model provided a user’s suicide risk level in four categories, i.e., no risk, low risk, moderate risk, and severe risk. Among the three models, the ensemble model had the best macro-averaged F1 score 0.379 when tested on the holdout test dataset. The NB model had the best performance in two additional binary-classification tasks, i.e., no risk vs. flagged risk (any risk level other than no risk) with F1 score 0.836 and no or low risk vs. urgent risk (moderate or severe risk) with F1 score 0.736. We conclude that the NB model may serve as a tool for identifying users with flagged or urgent suicide risk based on longitudinal posts on Reddit discussion forums.</abstract>
      <url>W19-3020</url>
    </paper>
    <paper id="21">
      <title>Suicide Risk Assessment on Social Media: <fixed-case>USI</fixed-case>-<fixed-case>UPF</fixed-case> at the <fixed-case>CLP</fixed-case>sych 2019 Shared Task</title>
      <author><first>Esteban</first><last>Ríssola</last></author>
      <author><first>Diana</first><last>Ramírez-Cifuentes</last></author>
      <author><first>Ana</first><last>Freire</last></author>
      <author><first>Fabio</first><last>Crestani</last></author>
      <pages>167–171</pages>
      <abstract>This paper describes the participation of the USI-UPF team at the shared task of the 2019 Computational Linguistics and Clinical Psychology Workshop (CLPsych2019). The goal is to assess the degree of suicide risk of social media users given a labelled dataset with their posts. An appropriate suicide risk assessment, with the usage of automated methods, can assist experts on the detection of people at risk and eventually contribute to prevent suicide. We propose a set of machine learning models with features based on lexicons, word embeddings, word level n-grams, and statistics extracted from users’ posts. The results show that the most effective models for the tasks are obtained integrating lexicon-based features, a selected set of n-grams, and statistical measures.</abstract>
      <url>W19-3021</url>
    </paper>
    <paper id="22">
      <title>Using Contextual Representations for Suicide Risk Assessment from <fixed-case>I</fixed-case>nternet Forums</title>
      <author><first>Ashwin Karthik</first><last>Ambalavanan</last></author>
      <author><first>Pranjali Dileep</first><last>Jagtap</last></author>
      <author><first>Soumya</first><last>Adhya</last></author>
      <author><first>Murthy</first><last>Devarakonda</last></author>
      <pages>172–176</pages>
      <abstract>Social media posts may yield clues to the subject’s (usually, the writer’s) suicide risk and intent, which can be used for timely intervention. This research, motivated by the CLPsych 2019 shared task, developed neural network-based methods for analyzing posts in one or more Reddit forums to assess the subject’s suicide risk. One of the technical challenges this task poses is the large amount of text from multiple posts of a single user. Our neural network models use the advanced multi-headed Attention-based autoencoder architecture, called Bidirectional Encoder Representations from Transformers (BERT). Our system achieved the 2nd best performance of 0.477 macro averaged F measure on Task A of the challenge. Among the three different alternatives we developed for the challenge, the single BERT model that processed all of a user’s posts performed the best on all three Tasks.</abstract>
      <url>W19-3022</url>
    </paper>
    <paper id="23">
      <title>An Investigation of Deep Learning Systems for Suicide Risk Assessment</title>
      <author><first>Michelle</first><last>Morales</last></author>
      <author><first>Prajjalita</first><last>Dey</last></author>
      <author><first>Thomas</first><last>Theisen</last></author>
      <author><first>Daniel</first><last>Belitz</last></author>
      <author><first>Natalia</first><last>Chernova</last></author>
      <pages>177–181</pages>
      <abstract>This work presents the systems explored as part of the CLPsych 2019 Shared Task. More specifically, this work explores the promise of deep learning systems for suicide risk assessment.</abstract>
      <url>W19-3023</url>
    </paper>
    <paper id="24">
      <title><fixed-case>C</fixed-case>onv<fixed-case>S</fixed-case>ent at <fixed-case>CLP</fixed-case>sych 2019 Task A: Using Post-level Sentiment Features for Suicide Risk Prediction on <fixed-case>R</fixed-case>eddit</title>
      <author><first>Kristen</first><last>Allen</last></author>
      <author><first>Shrey</first><last>Bagroy</last></author>
      <author><first>Alex</first><last>Davis</last></author>
      <author><first>Tamar</first><last>Krishnamurti</last></author>
      <pages>182–187</pages>
      <abstract>This work aims to infer mental health status from public text for early detection of suicide risk. It contributes to Shared Task A in the 2019 CLPsych workshop by predicting users’ suicide risk given posts in the Reddit subforum r/SuicideWatch. We use a convolutional neural network to incorporate LIWC information at the Reddit post level about topics discussed, first-person focus, emotional experience, grammatical choices, and thematic style. In sorting users into one of four risk categories, our best system’s macro-averaged F1 score was 0.50 on the withheld test set. The work demonstrates the predictive power of the Linguistic Inquiry and Word Count dictionary, in conjunction with a convolutional network and holistic consideration of each post and user.</abstract>
      <url>W19-3024</url>
    </paper>
    <paper id="25">
      <title>Dictionaries and Decision Trees for the 2019 <fixed-case>CLP</fixed-case>sych Shared Task</title>
      <author><first>Micah</first><last>Iserman</last></author>
      <author><first>Taleen</first><last>Nalabandian</last></author>
      <author><first>Molly</first><last>Ireland</last></author>
      <pages>188–194</pages>
      <abstract>In this summary, we discuss our approach to the CLPsych Shared Task and its initial results. For our predictions in each task, we used a recursive partitioning algorithm (decision trees) to select from our set of features, which were primarily dictionary scores and counts of individual words. We focused primarily on Task A, which aimed to predict suicide risk, as rated by a team of expert clinicians (Shing et al., 2018), based on language used in SuicideWatch posts on Reddit. Category-level findings highlight the potential importance of social and moral language categories. Word-level correlates of risk levels underline the value of fine-grained data-driven approaches, revealing both theory-consistent and potentially novel correlates of suicide risk that may motivate future research.</abstract>
      <url>W19-3025</url>
    </paper>
  </volume>
  <volume id="55">
    <meta>
      <booktitle>Proceedings of the First Workshop on Financial Technology and Natural Language Processing</booktitle>
      <url>W19-55</url>
      <editor><first>Chung-Chi</first><last>Chen</last></editor>
      <editor><first>Hen-Hsen</first><last>Huang</last></editor>
      <editor><first>Hiroya</first><last>Takamura</last></editor>
      <editor><first>Hsin-Hsi</first><last>Chen</last></editor>
      <address>Macao, China</address>
      <month>12 August</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-5500</url>
    </frontmatter>
    <paper id="1">
      <title>Business Taxonomy Construction Using Concept-Level Hierarchical Clustering</title>
      <author><first>Haodong</first><last>Bai</last></author>
      <author><first>Frank</first><last>Xing</last></author>
      <author><first>Erik</first><last>Cambria</last></author>
      <author><first>Win-Bin</first><last>Huang</last></author>
      <pages>1–7</pages>
      <url>W19-5501</url>
    </paper>
    <paper id="2">
      <title>Towards Disambiguating Contracts for their Successful Execution - A Case from Finance Domain</title>
      <author><first>Preethu Rose</first><last>Anish</last></author>
      <author><first>Abhishek</first><last>Sainani</last></author>
      <author><first>Nitin</first><last>Ramrakhiyani</last></author>
      <author><first>Sachin</first><last>Pawar</last></author>
      <author><first>Girish K</first><last>Palshikar</last></author>
      <author><first>Smita</first><last>Ghaisas</last></author>
      <pages>8–13</pages>
      <url>W19-5502</url>
    </paper>
    <paper id="3">
      <title>Rationale Classification for Educational Trading Platforms</title>
      <author><first>Annie</first><last>Ying</last></author>
      <author><first>Pablo</first><last>Duboue</last></author>
      <pages>14–20</pages>
      <url>W19-5503</url>
    </paper>
    <paper id="4">
      <title><fixed-case>C</fixed-case>o<fixed-case>F</fixed-case>i<fixed-case>F</fixed-case>: A Corpus of Financial Reports in <fixed-case>F</fixed-case>rench Language</title>
      <author><first>Tobias</first><last>Daudert</last></author>
      <author><first>Sina</first><last>Ahmadi</last></author>
      <pages>21–26</pages>
      <url>W19-5504</url>
    </paper>
    <paper id="5">
      <title>Step-wise Refinement Classification Approach for Enterprise Legal Litigation</title>
      <author><first>Ying</first><last>Mao</last></author>
      <author><first>Xian</first><last>Wang</last></author>
      <author><first>Jianbo</first><last>Tang</last></author>
      <author><first>Changliang</first><last>Li</last></author>
      <pages>27–33</pages>
      <url>W19-5505</url>
    </paper>
    <paper id="6">
      <title><fixed-case>C</fixed-case>o<fixed-case>SACT</fixed-case>: A Collaborative Tool for Fine-Grained Sentiment Annotation and Consolidation of Text</title>
      <author><first>Tobias</first><last>Daudert</last></author>
      <author><first>Manel</first><last>Zarrouk</last></author>
      <author><first>Brian</first><last>Davis</last></author>
      <pages>34–39</pages>
      <url>W19-5506</url>
    </paper>
    <paper id="7">
      <title>Financial Text Data Analytics Framework for Business Confidence Indices and Inter-Industry Relations</title>
      <author><first>Hiroki</first><last>Sakaji</last></author>
      <author><first>Ryota</first><last>Kuramoto</last></author>
      <author><first>Hiroyasu</first><last>Matsushima</last></author>
      <author><first>Kiyoshi</first><last>Izumi</last></author>
      <author><first>Takashi</first><last>Shimada</last></author>
      <author><first>Keita</first><last>Sunakawa</last></author>
      <pages>40–46</pages>
      <url>W19-5507</url>
    </paper>
    <paper id="8">
      <title>Learning to Learn Sales Prediction with Social Media Sentiment</title>
      <author><first>Zhaojiang</first><last>Lin</last></author>
      <author><first>Andrea</first><last>Madotto</last></author>
      <author><first>Genta Indra</first><last>Winata</last></author>
      <author><first>Zihan</first><last>Liu</last></author>
      <author><first>Yan</first><last>Xu</last></author>
      <author><first>Cong</first><last>Gao</last></author>
      <author><first>Pascale</first><last>Fung</last></author>
      <pages>47–53</pages>
      <url>W19-5508</url>
    </paper>
    <paper id="9">
      <title>Leveraging <fixed-case>BERT</fixed-case> to Improve the <fixed-case>FEARS</fixed-case> Index for Stock Forecasting</title>
      <author><first>Linyi</first><last>Yang</last></author>
      <author><first>Ruihai</first><last>Dong</last></author>
      <author><first>Tin Lok James</first><last>Ng</last></author>
      <author><first>Yang</first><last>Xu</last></author>
      <pages>54–60</pages>
      <url>W19-5509</url>
    </paper>
    <paper id="10">
      <title>Economic Causal-Chain Search using Text Mining Technology</title>
      <author><first>Kiyoshi</first><last>Izumi</last></author>
      <author><first>Hiroki</first><last>Sakaji</last></author>
      <pages>61–65</pages>
      <url>W19-5510</url>
    </paper>
    <paper id="11">
      <title>Transformer-Based Capsule Network For Stock Movement Prediction</title>
      <author><first>Jintao</first><last>Liu</last></author>
      <author><first>Hongfei</first><last>Lin</last></author>
      <author><first>Xikai</first><last>Liu</last></author>
      <author><first>Bo</first><last>Xu</last></author>
      <author><first>Yuqi</first><last>Ren</last></author>
      <author><first>Yufeng</first><last>Diao</last></author>
      <author><first>Liang</first><last>Yang</last></author>
      <pages>66–73</pages>
      <url>W19-5511</url>
    </paper>
    <paper id="12">
      <title>The <fixed-case>F</fixed-case>in<fixed-case>SBD</fixed-case>-2019 Shared Task: Sentence Boundary Detection in <fixed-case>PDF</fixed-case> Noisy Text in the Financial Domain</title>
      <author><first>Abderrahim Ait</first><last>Azzi</last></author>
      <author><first>Houda</first><last>Bouamor</last></author>
      <author><first>Sira</first><last>Ferradans</last></author>
      <pages>74–80</pages>
      <url>W19-5512</url>
    </paper>
    <paper id="13">
      <title><fixed-case>AIG</fixed-case> <fixed-case>I</fixed-case>nvestments.<fixed-case>AI</fixed-case> at the <fixed-case>F</fixed-case>in<fixed-case>SBD</fixed-case> Task: Sentence Boundary Detection through Sequence Labelling and <fixed-case>BERT</fixed-case> Fine-tuning</title>
      <author><first>Jinhua</first><last>Du</last></author>
      <author><first>Yan</first><last>Huang</last></author>
      <author><first>Karo</first><last>Moilanen</last></author>
      <pages>81–87</pages>
      <url>W19-5513</url>
    </paper>
    <paper id="14">
      <title>aiai at <fixed-case>F</fixed-case>in<fixed-case>SBD</fixed-case> task: Sentence Boundary Detection in Noisy Texts From Financial Documents Using Deep Attention Model</title>
      <author><first>Ke</first><last>Tian</last></author>
      <author><first>Zi Jun</first><last>Peng</last></author>
      <pages>88–92</pages>
      <url>W19-5514</url>
    </paper>
    <paper id="15">
      <title><fixed-case>P</fixed-case>luto: A Deep Learning Based Watchdog for Anti Money Laundering</title>
      <author><first>Hao-Yuan</first><last>Chen</last></author>
      <author><first>Shang-Xuan</first><last>Zou</last></author>
      <author><first>Cheng-Lung</first><last>Sung</last></author>
      <pages>93–95</pages>
      <url>W19-5515</url>
    </paper>
    <paper id="16">
      <title>From Creditworthiness to Trustworthiness with Alternative <fixed-case>NLP</fixed-case>/<fixed-case>NLU</fixed-case> Approaches</title>
      <author><first>Charles</first><last>Crouspeyre</last></author>
      <author><first>Eleonore</first><last>Alesi</last></author>
      <author><first>Karine</first><last>Lespinasse</last></author>
      <pages>96–98</pages>
      <url>W19-5516</url>
    </paper>
    <paper id="17">
      <title>On a Chatbot Conducting a Virtual Dialogue in Financial Domain</title>
      <author><first>Boris</first><last>Galitsky</last></author>
      <author><first>Dmitry</first><last>Ilvovsky</last></author>
      <pages>99–101</pages>
      <url>W19-5517</url>
    </paper>
    <paper id="18">
      <title>mhirano at the <fixed-case>F</fixed-case>in<fixed-case>SBD</fixed-case> Task: Pointwise Prediction Based on Multi-layer Perceptron for Sentence Boundary Detection</title>
      <author><first>Masanori</first><last>Hirano</last></author>
      <author><first>Hiroki</first><last>Sakaji</last></author>
      <author><first>Kiyoshi</first><last>Izumi</last></author>
      <author><first>Hiroyasu</first><last>Matsushima</last></author>
      <pages>102–107</pages>
      <url>W19-5518</url>
    </paper>
    <paper id="19">
      <title><fixed-case>NUIG</fixed-case> at the <fixed-case>F</fixed-case>in<fixed-case>SBD</fixed-case> Task: Sentence Boundary Detection for Noisy Financial <fixed-case>PDF</fixed-case>s in <fixed-case>E</fixed-case>nglish and <fixed-case>F</fixed-case>rench</title>
      <author><first>Tobias</first><last>Daudert</last></author>
      <author><first>Sina</first><last>Ahmadi</last></author>
      <pages>108–114</pages>
      <url>W19-5519</url>
    </paper>
    <paper id="20">
      <title><fixed-case>HITS</fixed-case>-<fixed-case>SBD</fixed-case> at the <fixed-case>F</fixed-case>in<fixed-case>SBD</fixed-case> Task: Machine Learning vs. Rule-based Sentence Boundary Detection</title>
      <author><first>Mehwish</first><last>Fatima</last></author>
      <author><first>Mark-Christoph</first><last>Mueller</last></author>
      <pages>115–121</pages>
      <url>W19-5520</url>
    </paper>
    <paper id="21">
      <title><fixed-case>P</fixed-case>oly<fixed-case>U</fixed-case>_<fixed-case>CBS</fixed-case>-<fixed-case>CFA</fixed-case> at the <fixed-case>F</fixed-case>in<fixed-case>SBD</fixed-case> Task: Sentence Boundary Detection of Financial Data with Domain Knowledge Enhancement and Bilingual Training</title>
      <author><first>Mingyu</first><last>Wan</last></author>
      <author><first>Rong</first><last>Xiang</last></author>
      <author><first>Emmanuele</first><last>Chersoni</last></author>
      <author><first>Natalia</first><last>Klyueva</last></author>
      <author><first>Kathleen</first><last>Ahrens</last></author>
      <author><first>Bin</first><last>Miao</last></author>
      <author><first>David</first><last>Broadstock</last></author>
      <author><first>Jian</first><last>Kang</last></author>
      <author><first>Amos</first><last>Yung</last></author>
      <author><first>Chu-Ren</first><last>Huang</last></author>
      <pages>122–129</pages>
      <url>W19-5521</url>
    </paper>
    <paper id="22">
      <title><fixed-case>AI</fixed-case>_<fixed-case>B</fixed-case>lues at <fixed-case>F</fixed-case>in<fixed-case>SBD</fixed-case> Shared Task: <fixed-case>CRF</fixed-case>-based Sentence Boundary Detection in <fixed-case>PDF</fixed-case> Noisy Text in the Financial Domain</title>
      <author><first>Ditty</first><last>Mathew</last></author>
      <author><first>Chinnappa</first><last>Guggilla</last></author>
      <pages>130–136</pages>
      <url>W19-5522</url>
    </paper>
  </volume>
  <volume id="56">
    <meta>
      <booktitle>Proceedings of the 3rd Workshop on Arabic Corpus Linguistics</booktitle>
      <url>W19-56</url>
      <editor><first>Mahmoud</first><last>El-Haj</last></editor>
      <editor><first>Paul</first><last>Rayson</last></editor>
      <editor><first>Eric</first><last>Atwell</last></editor>
      <editor><first>Lama</first><last>Alsudias</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Cardiff, United Kingdom</address>
      <month>22 July</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-5600</url>
    </frontmatter>
    <paper id="1">
      <title>Computer Stylometric Comparison of Writings by Qassim Amin and Mohammed Abdu on Women’s Rights</title>
      <author><first>Ahmed</first><last>Omer</last></author>
      <author><first>Michael</first><last>Oakes</last></author>
      <pages>1–6</pages>
      <url>W19-5601</url>
    </paper>
    <paper id="2">
      <title>Compiling and Analysing a Corpus of Transcribed Spoken Gulf Pidgin <fixed-case>A</fixed-case>rabic Based on Length of Stay in the Gulf</title>
      <author><first>Najah</first><last>Albaqawi</last></author>
      <author><first>Michael</first><last>Oakes</last></author>
      <pages>7–15</pages>
      <url>W19-5602</url>
    </paper>
    <paper id="3">
      <title>Writing Styles of Salwa and Al-Qarni</title>
      <author><first>Ahmed</first><last>Omer</last></author>
      <author><first>Michael</first><last>Oakes</last></author>
      <pages>16–21</pages>
      <url>W19-5603</url>
    </paper>
    <paper id="4">
      <title>Classifying Information Sources in <fixed-case>A</fixed-case>rabic Twitter to Support Online Monitoring of Infectious Diseases</title>
      <author><first>Lama</first><last>Alsudias</last></author>
      <author><first>Paul</first><last>Rayson</last></author>
      <pages>22–30</pages>
      <url>W19-5604</url>
    </paper>
    <paper id="5">
      <title>Text Segmentation Using N-grams to Annotate Hadith Corpus</title>
      <author><first>Shatha</first><last>Altammami</last></author>
      <author><first>Eric</first><last>Atwell</last></author>
      <author><first>Ammar</first><last>Alsalka</last></author>
      <pages>31–39</pages>
      <url>W19-5605</url>
    </paper>
    <paper id="6">
      <title>Can Modern Standard <fixed-case>A</fixed-case>rabic Approaches be used for <fixed-case>A</fixed-case>rabic Dialects? Sentiment Analysis as a Case Study</title>
      <author><first>Chatrine</first><last>Qwaider</last></author>
      <author><first>Stergios</first><last>Chatzikyriakidis</last></author>
      <author><first>Simon</first><last>Dobnik</last></author>
      <pages>40–50</pages>
      <url>W19-5606</url>
    </paper>
    <paper id="7">
      <title>Classifying <fixed-case>A</fixed-case>rabic dialect text in the Social Media <fixed-case>A</fixed-case>rabic Dialect Corpus (<fixed-case>SMADC</fixed-case>)</title>
      <author><first>Areej</first><last>Alshutayri</last></author>
      <author><first>Eric</first><last>Atwell</last></author>
      <pages>51–59</pages>
      <url>W19-5607</url>
    </paper>
    <paper id="8">
      <title>Verbs in <fixed-case>E</fixed-case>gyptian <fixed-case>A</fixed-case>rabic: a case for register variation</title>
      <author><first>Michael Grant</first><last>White</last></author>
      <author><first>Deryle W.</first><last>Lonsdale</last></author>
      <pages>60–71</pages>
      <url>W19-5608</url>
    </paper>
    <paper id="9">
      <title>Crisis Detection from <fixed-case>A</fixed-case>rabic Tweets</title>
      <author><first>Alaa</first><last>Alharbi</last></author>
      <author><first>Mark</first><last>Lee</last></author>
      <pages>72–79</pages>
      <url>W19-5609</url>
    </paper>
    <paper id="10">
      <title>The Design of the <fixed-case>S</fixed-case>au<fixed-case>LTC</fixed-case> application for the <fixed-case>E</fixed-case>nglish-<fixed-case>A</fixed-case>rabic Learner Translation Corpus</title>
      <author><first>Maha</first><last>Al-Harthi</last></author>
      <author><first>Amal</first><last>Alsaif</last></author>
      <pages>80–88</pages>
      <url>W19-5610</url>
    </paper>
    <paper id="11">
      <title>Distance-Based Authorship Verification Across Modern Standard <fixed-case>A</fixed-case>rabic Genres</title>
      <author><first>Hossam</first><last>Ahmed</last></author>
      <pages>89–96</pages>
      <url>W19-5611</url>
    </paper>
  </volume>
  <volume id="57">
    <meta>
      <booktitle>Proceedings of the 16th Meeting on the Mathematics of Language</booktitle>
      <url>W19-57</url>
      <editor><first>Philippe</first><last>de Groote</last></editor>
      <editor><first>Frank</first><last>Drewes</last></editor>
      <editor><first>Gerald</first><last>Penn</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Toronto, Canada</address>
      <month>18–19 July</month>
      <year>2019</year>
    </meta>
    <frontmatter>
      <url>W19-5700</url>
    </frontmatter>
    <paper id="1">
      <title>Parsing Weighted Order-Preserving Hyperedge Replacement Grammars</title>
      <author><first>Henrik</first><last>Björklund</last></author>
      <author><first>Frank</first><last>Drewes</last></author>
      <author><first>Petter</first><last>Ericson</last></author>
      <pages>1–11</pages>
      <url>W19-5701</url>
    </paper>
    <paper id="2">
      <title><fixed-case>S</fixed-case>ensing Tree Automata as a Model of Syntactic Dependencies</title>
      <author><first>Thomas</first><last>Graf</last></author>
      <author><first>Aniello De</first><last>Santo</last></author>
      <pages>12–26</pages>
      <url>W19-5702</url>
    </paper>
    <paper id="3">
      <title>Presupposition Projection and Repair Strategies in Trivalent Semantics</title>
      <author><first>Yoad</first><last>Winter</last></author>
      <pages>27–39</pages>
      <url>W19-5703</url>
    </paper>
    <paper id="4">
      <title>Dependently-Typed <fixed-case>M</fixed-case>ontague Semantics in the Proof Assistant Agda-flat</title>
      <author><first>Colin</first><last>Zwanziger</last></author>
      <pages>40–49</pages>
      <url>W19-5704</url>
    </paper>
    <paper id="5">
      <title>Quantifier-free least fixed point functions for phonology</title>
      <author><first>Jane</first><last>Chandlee</last></author>
      <author><first>Adam</first><last>Jardine</last></author>
      <pages>50–62</pages>
      <url>W19-5705</url>
    </paper>
    <paper id="6">
      <title>Some classes of sets of structures definable without quantifiers</title>
      <author><first>James</first><last>Rogers</last></author>
      <author><first>Dakotah</first><last>Lambert</last></author>
      <pages>63–77</pages>
      <url>W19-5706</url>
    </paper>
    <paper id="7">
      <title>Efficient learning of Output Tier-based Strictly 2-Local functions</title>
      <author><first>Phillip</first><last>Burness</last></author>
      <author><first>Kevin</first><last>McMullin</last></author>
      <pages>78–90</pages>
      <url>W19-5707</url>
    </paper>
    <paper id="8">
      <title>Learning with Partially Ordered Representations</title>
      <author><first>Jane</first><last>Chandlee</last></author>
      <author><first>Remi</first><last>Eyraud</last></author>
      <author><first>Jeffrey</first><last>Heinz</last></author>
      <author><first>Adam</first><last>Jardine</last></author>
      <author><first>Jonathan</first><last>Rawski</last></author>
      <pages>91–101</pages>
      <url>W19-5708</url>
    </paper>
    <paper id="9">
      <title>Maximum Likelihood Estimation of Factored Regular Deterministic Stochastic Languages</title>
      <author><first>Jeffrey</first><last>Heinz</last></author>
      <author><first>Chihiro</first><last>Shibata</last></author>
      <pages>102–113</pages>
      <url>W19-5709</url>
    </paper>
    <paper id="10">
      <title>Sentence Length</title>
      <author><first>Gábor</first><last>Borbély</last></author>
      <author><first>András</first><last>Kornai</last></author>
      <pages>114–125</pages>
      <url>W19-5710</url>
    </paper>
  </volume>
</collection>
